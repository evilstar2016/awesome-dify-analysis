# å¯¹è¯ç®¡ç†è¯¦ç»†è¯´æ˜ (Chat/Dialog Management)

## æ–‡æ¡£è¯´æ˜

æœ¬æ–‡æ¡£è¯¦ç»†æè¿° RAGFlow å¯¹è¯ç®¡ç†æ¨¡å—çš„ä¸šåŠ¡æµç¨‹ã€æŠ€æœ¯å®ç°ã€API æ¥å£å’Œé…ç½®è¯´æ˜ã€‚

---

## ç›®å½•

- [1. åŠŸèƒ½æ¦‚è¿°](#1-åŠŸèƒ½æ¦‚è¿°)
- [2. æ ¸å¿ƒä¸šåŠ¡æµç¨‹](#2-æ ¸å¿ƒä¸šåŠ¡æµç¨‹)
- [3. æ•°æ®æ¨¡å‹è¯¦è§£](#3-æ•°æ®æ¨¡å‹è¯¦è§£)
- [4. API æ¥å£å®ç°](#4-api-æ¥å£å®ç°)
- [5. å¯¹è¯é…ç½®è¯¦è§£](#5-å¯¹è¯é…ç½®è¯¦è§£)
- [6. æ£€ç´¢é›†æˆæœºåˆ¶](#6-æ£€ç´¢é›†æˆæœºåˆ¶)
- [7. æµå¼è¾“å‡ºå®ç°](#7-æµå¼è¾“å‡ºå®ç°)
- [8. é”™è¯¯å¤„ç†](#8-é”™è¯¯å¤„ç†)

---

## 1. åŠŸèƒ½æ¦‚è¿°

### 1.1 æ¨¡å—å®šä½

å¯¹è¯ç®¡ç†æ¨¡å—æ˜¯ RAGFlow çš„æ ¸å¿ƒäº¤äº’æ¨¡å—ï¼Œè´Ÿè´£ï¼š
- ğŸ’¬ **å¯¹è¯ç”Ÿå‘½å‘¨æœŸç®¡ç†**: åˆ›å»ºã€é…ç½®ã€æ›´æ–°ã€åˆ é™¤å¯¹è¯
- ğŸ“ **æ¶ˆæ¯ç®¡ç†**: å‘é€ã€æ¥æ”¶ã€å­˜å‚¨ã€æ£€ç´¢å¯¹è¯æ¶ˆæ¯
- ğŸ” **RAG æ£€ç´¢**: é›†æˆçŸ¥è¯†åº“æ£€ç´¢ï¼Œç”Ÿæˆå¢å¼ºç­”æ¡ˆ
- ğŸŒŠ **æµå¼è¾“å‡º**: SSE æµå¼å“åº”ï¼Œæå‡ç”¨æˆ·ä½“éªŒ
- ğŸ¯ **å¼•ç”¨æº¯æº**: æ ‡æ³¨ç­”æ¡ˆæ¥æºï¼Œæ”¯æŒå¼•ç”¨éªŒè¯
- ğŸ”§ **å·¥å…·è°ƒç”¨**: Function Calling é›†æˆå¤–éƒ¨å·¥å…·

### 1.2 ä¸»è¦åŠŸèƒ½æ¨¡å—

```mermaid
graph TB
    Chat[å¯¹è¯ç®¡ç†]
    Chat --> DM[å¯¹è¯ç®¡ç†]
    Chat --> MM[æ¶ˆæ¯ç®¡ç†]
    Chat --> RI[æ£€ç´¢é›†æˆ]
    Chat --> LLM[LLM é›†æˆ]
    
    DM --> CREATE[åˆ›å»ºå¯¹è¯]
    DM --> CONFIG[é…ç½®ç®¡ç†]
    DM --> LIST[å¯¹è¯åˆ—è¡¨]
    DM --> DELETE[åˆ é™¤å¯¹è¯]
    
    MM --> SEND[å‘é€æ¶ˆæ¯]
    MM --> HISTORY[æ¶ˆæ¯å†å²]
    MM --> FEEDBACK[æ¶ˆæ¯åé¦ˆ]
    
    RI --> VECTOR[å‘é‡æ£€ç´¢]
    RI --> RERANK[é‡æ’åº]
    RI --> CITATION[å¼•ç”¨æ ‡æ³¨]
    
    LLM --> SYNC[åŒæ­¥å¯¹è¯]
    LLM --> STREAM[æµå¼å¯¹è¯]
    LLM --> TOOL[å·¥å…·è°ƒç”¨]
```

### 1.3 æŠ€æœ¯ç‰¹æ€§

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **å¼‚æ­¥æ¶æ„** | åŸºäº Quart çš„å¼‚æ­¥ API |
| **æµå¼è¾“å‡º** | SSE (Server-Sent Events) |
| **å¤šæ¨¡å‹æ”¯æŒ** | æ”¯æŒå¤šç§ LLMã€åµŒå…¥ã€é‡æ’æ¨¡å‹ |
| **RAG é›†æˆ** | å‘é‡æ£€ç´¢ + å…¨æ–‡æ£€ç´¢ + å›¾è°±æ£€ç´¢ |
| **å¼•ç”¨æº¯æº** | è‡ªåŠ¨æ’å…¥å¼•ç”¨æ ‡æ³¨ |
| **ä¸Šä¸‹æ–‡ç®¡ç†** | å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡è·Ÿè¸ª |
| **å·¥å…·è°ƒç”¨** | Function Calling æ”¯æŒ |
| **æ€§èƒ½ç›‘æ§** | Langfuse é›†æˆ |

---

## 2. æ ¸å¿ƒä¸šåŠ¡æµç¨‹

### 2.1 å¯¹è¯åˆ›å»ºæµç¨‹

#### æµç¨‹å›¾

![å¯¹è¯åˆ›å»ºæµç¨‹](./01-create-dialog-sequence.puml)

#### è¯¦ç»†æ­¥éª¤

**æ­¥éª¤ 1: è¯·æ±‚æ¥æ”¶ä¸éªŒè¯**

- **API ç«¯ç‚¹**: [api/apps/dialog_app.py](../../api/apps/dialog_app.py#L29-L122)
- **å‡½æ•°**: `set_dialog()`
- **HTTP æ–¹æ³•**: POST `/api/v1/dialog/set`

**éªŒè¯é¡¹**:
```python
# 1. åç§°éªŒè¯
- ç±»å‹æ£€æŸ¥: å¿…é¡»æ˜¯å­—ç¬¦ä¸²
- éç©ºæ£€æŸ¥: ä¸èƒ½ä¸ºç©ºå­—ç¬¦ä¸²
- é•¿åº¦æ£€æŸ¥: ä¸è¶…è¿‡ 255 å­—èŠ‚

# 2. çŸ¥è¯†åº“éªŒè¯
- æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦å­˜åœ¨
- éªŒè¯åµŒå…¥æ¨¡å‹ä¸€è‡´æ€§ï¼ˆæ‰€æœ‰çŸ¥è¯†åº“å¿…é¡»ä½¿ç”¨ç›¸åŒçš„åµŒå…¥æ¨¡å‹ï¼‰

# 3. æç¤ºè¯éªŒè¯
- å¿…éœ€å‚æ•°æ£€æŸ¥
- ç³»ç»Ÿæç¤ºè¯ä¸­çš„å˜é‡å ä½ç¬¦éªŒè¯
```

**æ­¥éª¤ 2: åç§°å»é‡å¤„ç†**

- **å·¥å…·å‡½æ•°**: `common.utils.duplicate_name()`
- **é€»è¾‘**: å¦‚æœåç§°å·²å­˜åœ¨ï¼Œè‡ªåŠ¨æ·»åŠ æ•°å­—åç¼€
  - ä¾‹å¦‚: "æŠ€æœ¯æ”¯æŒ" â†’ "æŠ€æœ¯æ”¯æŒ(1)" â†’ "æŠ€æœ¯æ”¯æŒ(2)"

**æ­¥éª¤ 3: æ•°æ®æŒä¹…åŒ–**

- **æœåŠ¡å±‚**: [api/db/services/dialog_service.py](../../api/db/services/dialog_service.py)
- **ç±»**: `DialogService`
- **æ–¹æ³•**: `save()`

**åˆ›å»ºçš„æ•°æ®ç»“æ„**:
```json
{
  "id": "dialog_uuid",
  "tenant_id": "user_id",
  "name": "æŠ€æœ¯æ”¯æŒå¯¹è¯",
  "kb_ids": ["kb_uuid1", "kb_uuid2"],
  "llm_id": "gpt-4o-mini",
  "llm_setting": {
    "temperature": 0.1,
    "top_p": 0.3,
    "max_tokens": 512
  },
  "prompt_config": {
    "system": "You are a helpful assistant...",
    "prologue": "Hi! How can I help you?",
    "parameters": []
  },
  "similarity_threshold": 0.2,
  "vector_similarity_weight": 0.3,
  "top_n": 6,
  "top_k": 1024
}
```

#### å…³é”®ä»£ç ä½ç½®

| ç»„ä»¶ | æ–‡ä»¶è·¯å¾„ | å‡½æ•°/ç±» | è¯´æ˜ |
|------|---------|---------|------|
| API ç«¯ç‚¹ | api/apps/dialog_app.py | `set_dialog()` | åˆ›å»º/æ›´æ–°å¯¹è¯ |
| æœåŠ¡å±‚ | api/db/services/dialog_service.py | `DialogService` | å¯¹è¯ä¸šåŠ¡é€»è¾‘ |
| æ•°æ®æ¨¡å‹ | api/db/db_models.py | `Dialog` | å¯¹è¯æ•°æ®æ¨¡å‹ |

---

### 2.2 åŒæ­¥å¯¹è¯æµç¨‹

#### æµç¨‹å›¾

![åŒæ­¥å¯¹è¯æµç¨‹](./02-sync-chat-sequence.puml)

#### è¯¦ç»†æ­¥éª¤

**æ­¥éª¤ 1: æ¶ˆæ¯å‘é€**

- **API ç«¯ç‚¹**: [api/apps/conversation_app.py](../../api/apps/conversation_app.py#L167-L250)
- **å‡½æ•°**: `completion()`
- **HTTP æ–¹æ³•**: POST `/api/v1/conversation/completion`

**è¯·æ±‚å‚æ•°**:
```json
{
  "conversation_id": "conv_uuid",
  "messages": [
    {"role": "user", "content": "ä»€ä¹ˆæ˜¯ RAGï¼Ÿ"}
  ],
  "stream": false
}
```

**æ­¥éª¤ 2: å¯¹è¯å¤„ç†**

- **æ ¸å¿ƒå‡½æ•°**: [api/db/services/dialog_service.py](../../api/db/services/dialog_service.py#L280-L563)
- **å‡½æ•°**: `async_chat(dialog, messages, stream, **kwargs)`

**å¤„ç†æµç¨‹**:
```python
# 1. æ¨¡å‹åŠ è½½
- åŠ è½½ LLMã€åµŒå…¥æ¨¡å‹ã€é‡æ’æ¨¡å‹
- æ£€æŸ¥ Langfuse ç›‘æ§é…ç½®

# 2. é—®é¢˜ç²¾ç‚¼
- å¤šè½®å¯¹è¯é—®é¢˜åˆå¹¶ (refine_multiturn)
- è·¨è¯­è¨€ç¿»è¯‘ (cross_languages)
- å…³é”®è¯æå– (keyword extraction)

# 3. çŸ¥è¯†æ£€ç´¢
- å‘é‡æ£€ç´¢ (vector search)
- é‡æ’åº (rerank)
- ç›®å½•å¢å¼º (toc_enhance)
- å­åˆ†å—æ£€ç´¢ (children chunks)
- çŸ¥è¯†å›¾è°±æ£€ç´¢ (knowledge graph)

# 4. æç¤ºè¯æ„å»º
- ç»„è£…ç³»ç»Ÿæç¤ºè¯
- æ’å…¥æ£€ç´¢ç»“æœ
- æ·»åŠ å¼•ç”¨æç¤º

# 5. LLM ç”Ÿæˆ
- è°ƒç”¨ LLM ç”Ÿæˆç­”æ¡ˆ
- æ’å…¥å¼•ç”¨æ ‡æ³¨
- è¿”å›ç»“æœ
```

**æ­¥éª¤ 3: ç­”æ¡ˆå¤„ç†**

- **å‡½æ•°**: `decorate_answer(answer)`
- **å¤„ç†å†…å®¹**:
  - å¼•ç”¨æ ‡æ³¨æå–: `[ID:1]`, `[ID:2]`
  - å¼•ç”¨ä¿®å¤: `repair_bad_citation_formats()`
  - å¼•ç”¨æ’å…¥: `retriever.insert_citations()`
  - æ€§èƒ½ç»Ÿè®¡: æ—¶é—´ã€Token æ•°é‡

#### å…³é”®ä»£ç ä½ç½®

| ç»„ä»¶ | æ–‡ä»¶è·¯å¾„ | å‡½æ•°/ç±» | è¯´æ˜ |
|------|---------|---------|------|
| API ç«¯ç‚¹ | api/apps/conversation_app.py | `completion()` | å¯¹è¯å®Œæˆæ¥å£ |
| å¯¹è¯å¼•æ“ | api/db/services/dialog_service.py | `async_chat()` | RAG å¯¹è¯æ ¸å¿ƒé€»è¾‘ |
| æ£€ç´¢æœåŠ¡ | rag/app/retrieval.py | `retriever.retrieval()` | çŸ¥è¯†æ£€ç´¢ |
| LLM è°ƒç”¨ | rag/llm/chat_model.py | `async_chat()` | LLM å¼‚æ­¥è°ƒç”¨ |

---

### 2.3 æµå¼å¯¹è¯æµç¨‹

#### æµç¨‹å›¾

![æµå¼å¯¹è¯æµç¨‹](./03-stream-chat-sequence.puml)

#### è¯¦ç»†æ­¥éª¤

**æ­¥éª¤ 1: å¼€å¯æµå¼å“åº”**

- **API ç«¯ç‚¹**: åŒ `completion()`
- **å‚æ•°**: `"stream": true`
- **å“åº”ç±»å‹**: `text/event-stream`

**SSE å“åº”æ ¼å¼**:
```
data: {"code": 0, "message": "", "data": {"answer": "RAG", "reference": {}}}

data: {"code": 0, "message": "", "data": {"answer": "RAG æ˜¯æ£€ç´¢", "reference": {}}}

data: {"code": 0, "message": "", "data": {"answer": "RAG æ˜¯æ£€ç´¢å¢å¼ºç”Ÿæˆ", "reference": {...}}}

data: {"code": 0, "message": "", "data": true}
```

**æ­¥éª¤ 2: æµå¼ç”Ÿæˆ**

- **å‡½æ•°**: [api/db/services/dialog_service.py](../../api/db/services/dialog_service.py)
- **å¼‚æ­¥è¿­ä»£å™¨**: `async for ans in chat_mdl.async_chat_streamly(...)`

**æµå¼è¾“å‡ºç­–ç•¥**:
```python
# 1. å¢é‡è¾“å‡º
- ä»…è¾“å‡ºæ–°å¢å†…å®¹ (delta)
- ç´¯ç§¯å®Œæ•´ç­”æ¡ˆ (full answer)

# 2. Token ç¼“å†²
- æ¯ 16 ä¸ª Token è¾“å‡ºä¸€æ¬¡
- é¿å…è¿‡äºé¢‘ç¹çš„ç½‘ç»œä¼ è¾“

# 3. éŸ³é¢‘åˆæˆ
- å¯¹ delta å†…å®¹è¿›è¡Œ TTS è½¬æ¢
- è¿”å›éŸ³é¢‘äºŒè¿›åˆ¶æ•°æ®
```

**æ­¥éª¤ 3: å¼•ç”¨å¤„ç†**

- **å‡½æ•°**: `decorate_answer()`
- **æ—¶æœº**: æµå¼è¾“å‡ºå®Œæˆå
- **å¤„ç†**: æ’å…¥å¼•ç”¨æ ‡æ³¨ã€èšåˆæ–‡æ¡£å¼•ç”¨

#### å…³é”®ä»£ç ä½ç½®

| ç»„ä»¶ | æ–‡ä»¶è·¯å¾„ | å‡½æ•°/ç±» | è¯´æ˜ |
|------|---------|---------|------|
| æµå¼ç”Ÿæˆ | api/db/services/dialog_service.py | `async_chat()` | æµå¼å¯¹è¯é€»è¾‘ |
| LLM æµå¼ | rag/llm/chat_model.py | `async_chat_streamly()` | LLM æµå¼è°ƒç”¨ |
| SSE å°è£… | api/apps/conversation_app.py | `stream()` | SSE å“åº”åŒ…è£… |

---

### 2.4 æ¶ˆæ¯åé¦ˆæµç¨‹

#### æµç¨‹å›¾

æ–°å¢æ—¶åºå›¾ï¼š[04-message-feedback-sequence.puml](./04-message-feedback-sequence.puml)

**åŠŸèƒ½è¯´æ˜**:
- **ç‚¹èµ/ç‚¹è¸©**: ç”¨æˆ·å¯¹ç­”æ¡ˆçš„è¯„ä»·
- **åé¦ˆè®°å½•**: å­˜å‚¨ç”¨æˆ·åé¦ˆæ•°æ®
- **è´¨é‡æ”¹è¿›**: ç”¨äºæ¨¡å‹ä¼˜åŒ–

**API ç«¯ç‚¹**:
- **ç‚¹èµ**: POST `/api/v1/conversation/thumbup`
- **å‡½æ•°**: [api/apps/conversation_app.py](../../api/apps/conversation_app.py) `thumbup()`

**è¯·æ±‚å‚æ•°**:
```json
{
  "conversation_id": "conv_uuid",
  "message_id": "msg_uuid",
  "feedback": "thumbup"  // æˆ– "thumbdown"
}
```

---

### 2.5 ç›¸å…³é—®é¢˜æ¨èæµç¨‹

**åŠŸèƒ½è¯´æ˜**:
- **æ™ºèƒ½æ¨è**: åŸºäºå½“å‰å¯¹è¯æ¨èç›¸å…³é—®é¢˜
- **å¼•å¯¼ç”¨æˆ·**: å¸®åŠ©ç”¨æˆ·æ·±å…¥æ¢ç´¢è¯é¢˜

**API ç«¯ç‚¹**:
- **å‡½æ•°**: [api/apps/conversation_app.py](../../api/apps/conversation_app.py) `related_questions()`
- **HTTP æ–¹æ³•**: POST `/api/v1/conversation/related_questions`

**æ¨èé€»è¾‘**:
```python
# 1. æå–ä¸Šä¸‹æ–‡
- è·å–æœ€è¿‘çš„å¯¹è¯å†å²
- æå–å…³é”®ä¸»é¢˜

# 2. ç”Ÿæˆé—®é¢˜
- ä½¿ç”¨ LLM ç”Ÿæˆç›¸å…³é—®é¢˜
- åŸºäºçŸ¥è¯†åº“å†…å®¹æ¨è

# 3. è¿”å›ç»“æœ
- 3-5 ä¸ªç›¸å…³é—®é¢˜
- æŒ‰ç›¸å…³æ€§æ’åº
```

---

## 3. æ•°æ®æ¨¡å‹è¯¦è§£

### 3.1 Dialog æ¨¡å‹

**æ–‡ä»¶ä½ç½®**: [api/db/db_models.py](../../api/db/db_models.py#L842-L875)

#### å­—æ®µè¯´æ˜

| å­—æ®µ | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| **id** | VARCHAR(32) | UUID | å¯¹è¯å”¯ä¸€æ ‡è¯† |
| **tenant_id** | VARCHAR(32) | - | ç§Ÿæˆ· IDï¼ˆç”¨æˆ· IDï¼‰ |
| **name** | VARCHAR(255) | - | å¯¹è¯åç§° |
| **description** | TEXT | NULL | å¯¹è¯æè¿° |
| **icon** | TEXT | NULL | å›¾æ ‡ Base64 |
| **language** | VARCHAR(32) | Chinese | è¯­è¨€ï¼ˆChinese/Englishï¼‰ |
| **llm_id** | VARCHAR(128) | - | LLM æ¨¡å‹ ID |
| **llm_setting** | JSON | {...} | LLM é…ç½® |
| **prompt_type** | VARCHAR(16) | simple | æç¤ºè¯ç±»å‹ï¼ˆsimple/advancedï¼‰ |
| **prompt_config** | JSON | {...} | æç¤ºè¯é…ç½® |
| **meta_data_filter** | JSON | {} | å…ƒæ•°æ®è¿‡æ»¤å™¨ |
| **similarity_threshold** | FLOAT | 0.2 | ç›¸ä¼¼åº¦é˜ˆå€¼ |
| **vector_similarity_weight** | FLOAT | 0.3 | å‘é‡ç›¸ä¼¼åº¦æƒé‡ |
| **top_n** | INT | 6 | æœ€ç»ˆè¿”å›åˆ†å—æ•° |
| **top_k** | INT | 1024 | åˆå§‹æ£€ç´¢åˆ†å—æ•° |
| **do_refer** | CHAR(1) | "1" | æ˜¯å¦æ’å…¥å¼•ç”¨ |
| **rerank_id** | VARCHAR(128) | - | é‡æ’æ¨¡å‹ ID |
| **kb_ids** | JSON | [] | å…³è”çŸ¥è¯†åº“ ID åˆ—è¡¨ |
| **status** | CHAR(1) | "1" | çŠ¶æ€ï¼ˆ0:å·²åˆ é™¤, 1:æœ‰æ•ˆï¼‰ |

#### LLM Setting é…ç½®

```json
{
  "temperature": 0.1,        // æ¸©åº¦ï¼š0.0-2.0ï¼Œæ§åˆ¶éšæœºæ€§
  "top_p": 0.3,              // æ ¸é‡‡æ ·ï¼š0.0-1.0
  "frequency_penalty": 0.7,  // é¢‘ç‡æƒ©ç½šï¼š-2.0-2.0
  "presence_penalty": 0.4,   // å­˜åœ¨æƒ©ç½šï¼š-2.0-2.0
  "max_tokens": 512          // æœ€å¤§ Token æ•°
}
```

#### Prompt Config é…ç½®

```json
{
  "system": "You are a helpful assistant...",
  "prologue": "Hi! I'm your assistant. What can I do for you?",
  "parameters": [
    {
      "key": "knowledge",
      "optional": false
    }
  ],
  "empty_response": "Sorry! No relevant content was found!",
  "quote": true,                    // æ˜¯å¦å¼•ç”¨
  "tavily_api_key": "",             // Tavily æœç´¢ API Key
  "refine_multiturn": false,        // å¤šè½®é—®é¢˜ç²¾ç‚¼
  "cross_languages": "",            // è·¨è¯­è¨€ç¿»è¯‘
  "keyword": false,                 // å…³é”®è¯æå–
  "reasoning": false,               // æ·±åº¦æ¨ç†
  "toc_enhance": false,             // ç›®å½•å¢å¼º
  "use_kg": false                   // ä½¿ç”¨çŸ¥è¯†å›¾è°±
}
```

---

### 3.2 Conversation æ¨¡å‹

**æ–‡ä»¶ä½ç½®**: [api/db/db_models.py](../../api/db/db_models.py#L877-L886)

#### å­—æ®µè¯´æ˜

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| **id** | VARCHAR(32) | å¯¹è¯è½®æ¬¡ UUID |
| **dialog_id** | VARCHAR(32) | æ‰€å±å¯¹è¯ ID |
| **name** | VARCHAR(255) | è½®æ¬¡åç§° |
| **message** | JSON | æ¶ˆæ¯åˆ—è¡¨ |
| **reference** | JSON | å¼•ç”¨åˆ—è¡¨ |
| **user_id** | VARCHAR(255) | ç”¨æˆ· ID |

#### Message ç»“æ„

```json
{
  "message": [
    {
      "role": "user",
      "content": "ä»€ä¹ˆæ˜¯ RAGï¼Ÿ",
      "id": "msg_user_uuid"
    },
    {
      "role": "assistant",
      "content": "RAG æ˜¯æ£€ç´¢å¢å¼ºç”Ÿæˆ...",
      "id": "msg_assistant_uuid"
    }
  ]
}
```

#### Reference ç»“æ„

```json
{
  "reference": [
    {
      "chunks": [
        {
          "id": "chunk_uuid",
          "content": "åˆ†å—å†…å®¹...",
          "doc_id": "doc_uuid",
          "kb_id": "kb_uuid",
          "similarity": 0.85
        }
      ],
      "doc_aggs": [
        {
          "doc_id": "doc_uuid",
          "doc_name": "æ–‡æ¡£åç§°.pdf",
          "count": 3
        }
      ]
    }
  ]
}
```

---

## 4. API æ¥å£å®ç°

### 4.1 RESTful API è®¾è®¡

#### å¯¹è¯ç®¡ç† API

| æ–¹æ³• | è·¯å¾„ | åŠŸèƒ½ | æƒé™ |
|------|------|------|------|
| POST | `/api/v1/dialog/set` | åˆ›å»º/æ›´æ–°å¯¹è¯ | ç™»å½•ç”¨æˆ· |
| GET | `/api/v1/dialog/get` | è·å–å¯¹è¯è¯¦æƒ… | æœ‰æƒé™ç”¨æˆ· |
| POST | `/api/v1/dialog/list` | æŸ¥è¯¢å¯¹è¯åˆ—è¡¨ | ç™»å½•ç”¨æˆ· |
| POST | `/api/v1/dialog/rm` | åˆ é™¤å¯¹è¯ | åˆ›å»ºè€… |

**æ–‡ä»¶ä½ç½®**: [api/apps/dialog_app.py](../../api/apps/dialog_app.py)

#### æ¶ˆæ¯ç®¡ç† API

| æ–¹æ³• | è·¯å¾„ | åŠŸèƒ½ | æƒé™ |
|------|------|------|------|
| POST | `/api/v1/conversation/set` | åˆ›å»ºå¯¹è¯è½®æ¬¡ | æœ‰æƒé™ç”¨æˆ· |
| GET | `/api/v1/conversation/get` | è·å–å¯¹è¯è½®æ¬¡ | æœ‰æƒé™ç”¨æˆ· |
| POST | `/api/v1/conversation/completion` | å‘é€æ¶ˆæ¯ï¼ˆåŒæ­¥/æµå¼ï¼‰ | æœ‰æƒé™ç”¨æˆ· |
| POST | `/api/v1/conversation/list` | è·å–æ¶ˆæ¯åˆ—è¡¨ | æœ‰æƒé™ç”¨æˆ· |
| POST | `/api/v1/conversation/rm` | åˆ é™¤å¯¹è¯è½®æ¬¡ | æœ‰æƒé™ç”¨æˆ· |
| POST | `/api/v1/conversation/thumbup` | æ¶ˆæ¯åé¦ˆ | æœ‰æƒé™ç”¨æˆ· |
| POST | `/api/v1/conversation/related_questions` | æ¨èç›¸å…³é—®é¢˜ | æœ‰æƒé™ç”¨æˆ· |

**æ–‡ä»¶ä½ç½®**: [api/apps/conversation_app.py](../../api/apps/conversation_app.py)

### 4.2 ç»Ÿä¸€å“åº”æ ¼å¼

```json
{
  "code": 0,           // çŠ¶æ€ç : 0=æˆåŠŸ, å…¶ä»–=é”™è¯¯
  "data": {...},       // å“åº”æ•°æ®
  "message": "OK"      // æ¶ˆæ¯
}
```

### 4.3 é”™è¯¯ç å®šä¹‰

```python
class RetCode:
    SUCCESS = 0                    # æˆåŠŸ
    ARGUMENT_ERROR = 101           # å‚æ•°é”™è¯¯
    DATA_ERROR = 102               # æ•°æ®é”™è¯¯
    OPERATING_ERROR = 103          # æ“ä½œé”™è¯¯
    AUTHENTICATION_ERROR = 104     # è®¤è¯é”™è¯¯
    AUTHORIZATION_ERROR = 105      # æˆæƒé”™è¯¯
    SERVER_ERROR = 500             # æœåŠ¡å™¨é”™è¯¯
```

---

## 5. å¯¹è¯é…ç½®è¯¦è§£

### 5.1 LLM é…ç½®å‚æ•°

#### Temperature (æ¸©åº¦)

- **èŒƒå›´**: 0.0 - 2.0
- **é»˜è®¤**: 0.1
- **è¯´æ˜**: æ§åˆ¶è¾“å‡ºçš„éšæœºæ€§
  - `0.0`: ç¡®å®šæ€§æœ€é«˜ï¼Œè¾“å‡ºç¨³å®š
  - `0.1-0.5`: é€‚åˆæŠ€æœ¯é—®ç­”ã€å®¢æœ
  - `0.7-1.0`: é€‚åˆåˆ›æ„å†™ä½œ
  - `>1.0`: æåº¦éšæœº

#### Top P (æ ¸é‡‡æ ·)

- **èŒƒå›´**: 0.0 - 1.0
- **é»˜è®¤**: 0.3
- **è¯´æ˜**: æ§åˆ¶é‡‡æ ·èŒƒå›´
  - `0.1-0.3`: ä¿å®ˆï¼Œè¾“å‡ºç¨³å®š
  - `0.5-0.7`: å¹³è¡¡
  - `0.9-1.0`: å¤šæ ·åŒ–

#### Frequency Penalty (é¢‘ç‡æƒ©ç½š)

- **èŒƒå›´**: -2.0 - 2.0
- **é»˜è®¤**: 0.7
- **è¯´æ˜**: æƒ©ç½šé‡å¤å†…å®¹
  - `0.0`: ä¸æƒ©ç½š
  - `0.7`: ä¸­ç­‰æƒ©ç½šï¼Œå‡å°‘é‡å¤
  - `2.0`: å¼ºçƒˆæƒ©ç½šï¼Œé¿å…é‡å¤

#### Presence Penalty (å­˜åœ¨æƒ©ç½š)

- **èŒƒå›´**: -2.0 - 2.0
- **é»˜è®¤**: 0.4
- **è¯´æ˜**: é¼“åŠ±æ–°ä¸»é¢˜
  - `0.0`: ä¸æƒ©ç½š
  - `0.4`: é€‚åº¦é¼“åŠ±æ–°è¯é¢˜
  - `2.0`: å¼ºçƒˆé¼“åŠ±å¤šæ ·æ€§

#### Max Tokens (æœ€å¤§ Token æ•°)

- **èŒƒå›´**: 1 - æ¨¡å‹ä¸Šé™
- **é»˜è®¤**: 512
- **è¯´æ˜**: é™åˆ¶è¾“å‡ºé•¿åº¦
  - `128-256`: ç®€çŸ­å›ç­”
  - `512-1024`: ä¸­ç­‰é•¿åº¦
  - `2048+`: é•¿ç¯‡å†…å®¹

### 5.2 æ£€ç´¢é…ç½®å‚æ•°

#### Similarity Threshold (ç›¸ä¼¼åº¦é˜ˆå€¼)

- **èŒƒå›´**: 0.0 - 1.0
- **é»˜è®¤**: 0.2
- **è¯´æ˜**: è¿‡æ»¤ä½ç›¸å…³æ€§ç»“æœ
  - `0.1-0.3`: å®½æ¾ï¼Œå¬å›ç‡é«˜
  - `0.4-0.6`: å¹³è¡¡
  - `0.7+`: ä¸¥æ ¼ï¼Œç²¾ç¡®åº¦é«˜

#### Vector Similarity Weight (å‘é‡æƒé‡)

- **èŒƒå›´**: 0.0 - 1.0
- **é»˜è®¤**: 0.3
- **è¯´æ˜**: å‘é‡æ£€ç´¢çš„æƒé‡
  - `0.0-0.3`: åå‘å…¨æ–‡æ£€ç´¢
  - `0.5`: å¹³è¡¡
  - `0.7-1.0`: åå‘è¯­ä¹‰æ£€ç´¢

#### Top K (åˆå§‹æ£€ç´¢æ•°)

- **èŒƒå›´**: 1 - 10000
- **é»˜è®¤**: 1024
- **è¯´æ˜**: å‘é‡æ£€ç´¢è¿”å›çš„å€™é€‰æ•°
  - `100-500`: å¿«é€Ÿå“åº”
  - `1024`: å¹³è¡¡
  - `5000+`: é«˜å¬å›ç‡

#### Top N (æœ€ç»ˆè¿”å›æ•°)

- **èŒƒå›´**: 1 - 100
- **é»˜è®¤**: 6
- **è¯´æ˜**: é‡æ’åè¿”å›çš„åˆ†å—æ•°
  - `3-6`: ç®€æ´ç­”æ¡ˆ
  - `8-12`: è¯¦ç»†ç­”æ¡ˆ
  - `20+`: å…¨é¢åˆ†æ

### 5.3 æç¤ºè¯é…ç½®

#### ç³»ç»Ÿæç¤ºè¯ (System Prompt)

**å˜é‡å ä½ç¬¦**:
- `{knowledge}`: æ£€ç´¢åˆ°çš„çŸ¥è¯†å†…å®¹
- è‡ªå®šä¹‰å‚æ•°: `{param_name}`

**ç¤ºä¾‹**:
```
You are a helpful technical support assistant.

Use the following knowledge to answer user questions:
{knowledge}

Requirements:
- Answer accurately based on the knowledge base
- If unsure, say "I don't know"
- Provide code examples when applicable
```

#### å¼€åœºç™½ (Prologue)

**ç¤ºä¾‹**:
```
Hi! I'm your technical support assistant. 
I can help you with:
- API documentation
- Troubleshooting issues
- Best practices

What can I do for you today?
```

#### ç©ºå“åº” (Empty Response)

**è¯´æ˜**: å½“æ²¡æœ‰æ£€ç´¢åˆ°ç›¸å…³å†…å®¹æ—¶çš„å›å¤

**ç¤ºä¾‹**:
```
Sorry! I couldn't find relevant information in the knowledge base.
Please try rephrasing your question or contact support.
```

---

## 6. æ£€ç´¢é›†æˆæœºåˆ¶

### 6.1 æ£€ç´¢æµç¨‹

```mermaid
graph LR
    Q[ç”¨æˆ·é—®é¢˜] --> Refine[é—®é¢˜ç²¾ç‚¼]
    Refine --> Vector[å‘é‡æ£€ç´¢]
    Vector --> Rerank[é‡æ’åº]
    Rerank --> Children[å­åˆ†å—]
    Children --> TOC[ç›®å½•å¢å¼º]
    TOC --> KG[çŸ¥è¯†å›¾è°±]
    KG --> Prompt[æç¤ºè¯ç»„è£…]
```

### 6.2 æ£€ç´¢æ¨¡å—

#### å‘é‡æ£€ç´¢ (Vector Retrieval)

- **æ–‡ä»¶**: `rag/app/retrieval.py`
- **å‡½æ•°**: `retriever.retrieval()`
- **è¾“å…¥**: 
  - é—®é¢˜æ–‡æœ¬
  - åµŒå…¥æ¨¡å‹
  - çŸ¥è¯†åº“ ID
  - æ£€ç´¢å‚æ•° (top_k, threshold, weight)
- **è¾“å‡º**: 
  - åˆ†å—åˆ—è¡¨ (chunks)
  - æ–‡æ¡£èšåˆ (doc_aggs)

**æ£€ç´¢ç­–ç•¥**:
```python
# 1. å‘é‡æ£€ç´¢
- ä½¿ç”¨åµŒå…¥æ¨¡å‹å°†é—®é¢˜ç¼–ç ä¸ºå‘é‡
- åœ¨ ES/Infinity ä¸­è¿›è¡Œç›¸ä¼¼åº¦æœç´¢
- è¿”å› top_k ä¸ªå€™é€‰

# 2. å…¨æ–‡æ£€ç´¢
- ä½¿ç”¨ BM25 ç®—æ³•è¿›è¡Œå…³é”®è¯åŒ¹é…
- ä¸å‘é‡æ£€ç´¢ç»“æœæ··åˆ

# 3. æ··åˆæ£€ç´¢
- å‘é‡å¾—åˆ† Ã— vector_similarity_weight
- å…¨æ–‡å¾—åˆ† Ã— (1 - vector_similarity_weight)
- æŒ‰æ··åˆå¾—åˆ†æ’åº
```

#### é‡æ’åº (Rerank)

- **æ¨¡å‹**: BGE-reranker, Cohere, Jina
- **å‡½æ•°**: `rerank_mdl.similarity()`
- **ä½œç”¨**: é‡æ–°è®¡ç®—é—®é¢˜ä¸åˆ†å—çš„ç›¸å…³æ€§

**é‡æ’é€»è¾‘**:
```python
# 1. è¾“å…¥: top_k ä¸ªå€™é€‰åˆ†å—
# 2. ä½¿ç”¨é‡æ’æ¨¡å‹è®¡ç®—ç›¸ä¼¼åº¦
# 3. æŒ‰æ–°å¾—åˆ†æ’åº
# 4. è¿”å› top_n ä¸ªæœ€ç›¸å…³åˆ†å—
```

#### å­åˆ†å—æ£€ç´¢ (Children Chunks)

- **å‡½æ•°**: `retriever.retrieval_by_children()`
- **ä½œç”¨**: æ‰©å±•åˆ†å—ä¸Šä¸‹æ–‡

**é€»è¾‘**:
```python
# å¯¹äºæ¯ä¸ªæ£€ç´¢åˆ°çš„åˆ†å—:
# 1. æŸ¥æ‰¾å…¶çˆ¶åˆ†å—
# 2. æŸ¥æ‰¾å…¶å­åˆ†å—
# 3. æŸ¥æ‰¾ç›¸é‚»åˆ†å—
# 4. ç»„åˆå½¢æˆæ›´å®Œæ•´çš„ä¸Šä¸‹æ–‡
```

#### ç›®å½•å¢å¼º (TOC Enhance)

- **å‡½æ•°**: `retriever.retrieval_by_toc()`
- **ä½œç”¨**: åŸºäºæ–‡æ¡£ç›®å½•ç»“æ„å¢å¼ºæ£€ç´¢

**é€»è¾‘**:
```python
# 1. æå–æ–‡æ¡£ç›®å½•ç»“æ„
# 2. åŒ¹é…é—®é¢˜ä¸ç›®å½•é¡¹
# 3. æ£€ç´¢ç›®å½•é¡¹å¯¹åº”çš„å†…å®¹
# 4. è¡¥å……åˆ°æ£€ç´¢ç»“æœ
```

#### çŸ¥è¯†å›¾è°±æ£€ç´¢ (Knowledge Graph)

- **å¼€å…³**: `prompt_config.use_kg`
- **å‡½æ•°**: `kg_retriever.retrieval()`
- **ä½œç”¨**: ä»çŸ¥è¯†å›¾è°±ä¸­æ£€ç´¢å®ä½“å’Œå…³ç³»

### 6.3 å¼•ç”¨æ ‡æ³¨

#### è‡ªåŠ¨æ’å…¥å¼•ç”¨

- **å‡½æ•°**: [api/db/services/dialog_service.py](../../api/db/services/dialog_service.py)
- **æ–¹æ³•**: `retriever.insert_citations()`

**æ’å…¥é€»è¾‘**:
```python
# 1. åˆ†å¥å¤„ç†
- å°†ç­”æ¡ˆåˆ†è§£ä¸ºå¥å­

# 2. ç›¸ä¼¼åº¦è®¡ç®—
- è®¡ç®—æ¯ä¸ªå¥å­ä¸æ£€ç´¢åˆ†å—çš„ç›¸ä¼¼åº¦
- æ··åˆ Token ç›¸ä¼¼åº¦å’Œå‘é‡ç›¸ä¼¼åº¦

# 3. æ’å…¥æ ‡æ³¨
- åœ¨å¥æœ«æ’å…¥ [ID:i]
- i ä¸ºåˆ†å—ç´¢å¼•

# ç¤ºä¾‹:
# "RAG æ˜¯æ£€ç´¢å¢å¼ºç”Ÿæˆ[ID:0]ã€‚å®ƒç»“åˆäº†æ£€ç´¢å’Œç”Ÿæˆä¸¤ç§æŠ€æœ¯[ID:1]ã€‚"
```

#### å¼•ç”¨æ ¼å¼ä¿®å¤

- **å‡½æ•°**: `repair_bad_citation_formats()`
- **ä½œç”¨**: ä¿®å¤é”™è¯¯çš„å¼•ç”¨æ ¼å¼

**ä¿®å¤è§„åˆ™**:
```python
# é”™è¯¯æ ¼å¼:
- [1], [2]
- [[1]]
- (1)

# æ­£ç¡®æ ¼å¼:
- [ID:1]
- [ID:2]
```

---

## 7. æµå¼è¾“å‡ºå®ç°

### 7.1 SSE åè®®

**å“åº”å¤´**:
```http
Content-Type: text/event-stream; charset=utf-8
Cache-Control: no-cache
Connection: keep-alive
X-Accel-Buffering: no
```

**æ•°æ®æ ¼å¼**:
```
data: {"code": 0, "message": "", "data": {...}}

data: {"code": 0, "message": "", "data": {...}}

```

### 7.2 æµå¼ç”Ÿæˆ

**æ ¸å¿ƒå‡½æ•°**: [api/db/services/dialog_service.py](../../api/db/services/dialog_service.py)

**å¼‚æ­¥ç”Ÿæˆå™¨**:
```python
async def stream():
    async for ans in async_chat(dialog, messages, True, **req):
        # ç»“æ„åŒ–ç­”æ¡ˆ
        ans = structure_answer(conv, ans, message_id, conv.id)
        
        # å‘é€ SSE äº‹ä»¶
        yield "data:" + json.dumps({
            "code": 0,
            "message": "",
            "data": ans
        }, ensure_ascii=False) + "\n\n"
    
    # ç»“æŸæ ‡è®°
    yield "data:" + json.dumps({
        "code": 0,
        "message": "",
        "data": True
    }, ensure_ascii=False) + "\n\n"
```

### 7.3 Token ç¼“å†²ç­–ç•¥

**ä¼˜åŒ–ç­–ç•¥**:
```python
# 1. é¿å…é¢‘ç¹å‘é€
- ç´¯ç§¯è‡³å°‘ 16 ä¸ª Token
- å‡å°‘ç½‘ç»œå¼€é”€

# 2. å¢é‡è¾“å‡º
last_ans = ""
for new_ans in llm_stream:
    delta = new_ans[len(last_ans):]
    if len(tokenize(delta)) >= 16:
        yield delta
        last_ans = new_ans

# 3. æœ€åè¾“å‡º
if last_ans != new_ans:
    yield new_ans[len(last_ans):]
```

### 7.4 éŸ³é¢‘é›†æˆ (TTS)

**å‡½æ•°**: [api/db/services/dialog_service.py](../../api/db/services/dialog_service.py)
- `tts(tts_mdl, text)`: æ–‡æœ¬è½¬è¯­éŸ³
- `clean_tts_text(text)`: æ¸…ç†æ–‡æœ¬ï¼ˆç§»é™¤ Markdown ç­‰ï¼‰

**æµå¼éŸ³é¢‘**:
```python
async for delta in llm_stream:
    # å¯¹ delta è¿›è¡Œ TTS
    audio_binary = tts(tts_mdl, delta)
    
    yield {
        "answer": delta,
        "audio_binary": audio_binary
    }
```

---

## 8. é”™è¯¯å¤„ç†

### 8.1 å¸¸è§é”™è¯¯ç±»å‹

#### 1. å‚æ•°é”™è¯¯

```json
// ç¼ºå°‘å¿…éœ€å‚æ•°
{
  "code": 101,
  "message": "Missing required field: conversation_id",
  "data": false
}

// å‚æ•°ç±»å‹é”™è¯¯
{
  "code": 101,
  "message": "Dialog name must be string",
  "data": false
}

// å‚æ•°é•¿åº¦è¶…é™
{
  "code": 101,
  "message": "Dialog name length exceeds 255 bytes",
  "data": false
}
```

#### 2. æƒé™é”™è¯¯

```json
// æ— æƒé™è®¿é—®
{
  "code": 105,
  "message": "No authorization",
  "data": false
}

// å¯¹è¯ä¸å­˜åœ¨
{
  "code": 102,
  "message": "Dialog not found",
  "data": false
}
```

#### 3. æ¨¡å‹é”™è¯¯

```json
// LLM ä¸å¯ç”¨
{
  "code": 500,
  "message": "Cannot use specified model gpt-4o",
  "data": false
}

// API Key æ— æ•ˆ
{
  "code": 500,
  "message": "Invalid API key",
  "data": false
}
```

#### 4. æ£€ç´¢é”™è¯¯

```json
// çŸ¥è¯†åº“ä¸ºç©º
{
  "code": 0,
  "message": "",
  "data": {
    "answer": "Sorry! No relevant content was found!",
    "reference": {"chunks": [], "doc_aggs": []}
  }
}

// åµŒå…¥æ¨¡å‹ä¸ä¸€è‡´
{
  "code": 102,
  "message": "Datasets use different embedding models",
  "data": false
}
```

### 8.2 å¼‚å¸¸å¤„ç†

**å…¨å±€å¼‚å¸¸æ•è·**:
```python
# åœ¨ API å±‚æ•è·
try:
    result = await process_request()
    return get_json_result(data=result)
except Exception as e:
    logging.exception(e)
    return server_error_response(e)
```

**æµå¼é”™è¯¯å¤„ç†**:
```python
async def stream():
    try:
        async for ans in async_chat(...):
            yield success_event(ans)
    except Exception as e:
        # å‘é€é”™è¯¯äº‹ä»¶
        yield error_event(str(e))
    finally:
        # å‘é€ç»“æŸäº‹ä»¶
        yield end_event()
```

---

## 9. é«˜çº§åŠŸèƒ½

### 9.1 æ·±åº¦æ¨ç† (Deep Reasoning)

**åŠŸèƒ½è¯´æ˜**: å¯¹å¤æ‚é—®é¢˜è¿›è¡Œå¤šæ­¥æ¨ç†ï¼Œç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Š

**é…ç½®å¼€å…³**: `prompt_config.reasoning = true`

**æ ¸å¿ƒç»„ä»¶**: `agentic_reasoning/deep_research.py`

**å·¥ä½œæµç¨‹**:
```mermaid
graph TB
    Q[å¤æ‚é—®é¢˜] --> Decompose[é—®é¢˜åˆ†è§£]
    Decompose --> Sub1[å­é—®é¢˜1]
    Decompose --> Sub2[å­é—®é¢˜2]
    Decompose --> Sub3[å­é—®é¢˜3]
    
    Sub1 --> R1[æ£€ç´¢+åˆ†æ]
    Sub2 --> R2[æ£€ç´¢+åˆ†æ]
    Sub3 --> R3[æ£€ç´¢+åˆ†æ]
    
    R1 --> Synthesize[ç»¼åˆæ¨ç†]
    R2 --> Synthesize
    R3 --> Synthesize
    
    Synthesize --> Report[æ·±åº¦æŠ¥å‘Š]
```

**å®ç°æœºåˆ¶**:
```python
# 1. åˆ›å»ºæ¨ç†å™¨
reasoner = DeepResearcher(
    chat_mdl,
    prompt_config,
    retrieval_func
)

# 2. å¼€å§‹æ¨ç†
async for think in reasoner.thinking(kbinfos, question):
    if isinstance(think, str):
        # æ¨ç†è¿‡ç¨‹
        thought = think
    else:
        # æµå¼è¾“å‡º
        yield think
```

**é€‚ç”¨åœºæ™¯**:
- ç ”ç©¶æŠ¥å‘Šç”Ÿæˆ
- å¸‚åœºåˆ†æ
- æŠ€æœ¯è°ƒç ”
- å­¦æœ¯è®ºæ–‡è¾…åŠ©

---

### 9.2 å·¥å…·è°ƒç”¨ (Function Calling)

**åŠŸèƒ½è¯´æ˜**: é›†æˆå¤–éƒ¨å·¥å…·ï¼Œæ‰©å±• LLM èƒ½åŠ›

**æ”¯æŒçš„å·¥å…·ç±»å‹**:
- **æœç´¢å·¥å…·**: Tavily Web Search
- **æ•°æ®åº“æŸ¥è¯¢**: SQL ç”Ÿæˆå’Œæ‰§è¡Œ
- **API è°ƒç”¨**: è‡ªå®šä¹‰ API é›†æˆ
- **è®¡ç®—å·¥å…·**: æ•°å­¦è®¡ç®—ã€ä»£ç æ‰§è¡Œ

#### Tavily ç½‘ç»œæœç´¢

**é…ç½®**: `prompt_config.tavily_api_key`

**å®ç°ä½ç½®**: [api/db/services/dialog_service.py](../../api/db/services/dialog_service.py)

**å·¥ä½œæµç¨‹**:
```python
# 1. æ£€æŸ¥é…ç½®
if prompt_config.get("tavily_api_key"):
    # 2. åˆ›å»º Tavily å®¢æˆ·ç«¯
    tav = Tavily(prompt_config["tavily_api_key"])
    
    # 3. æ‰§è¡Œæœç´¢
    tav_res = tav.retrieve_chunks(question)
    
    # 4. åˆå¹¶åˆ°çŸ¥è¯†åº“æ£€ç´¢ç»“æœ
    kbinfos["chunks"].extend(tav_res["chunks"])
    kbinfos["doc_aggs"].extend(tav_res["doc_aggs"])
```

**ä½¿ç”¨åœºæ™¯**:
- å®æ—¶ä¿¡æ¯æŸ¥è¯¢ï¼ˆæ–°é—»ã€å¤©æ°”ï¼‰
- çŸ¥è¯†åº“å¤–çš„è¡¥å……ä¿¡æ¯
- äº‹å®æ ¸æŸ¥

#### SQL å·¥å…·

**åŠŸèƒ½**: è‡ªåŠ¨ç”Ÿæˆ SQL æŸ¥è¯¢ç»“æ„åŒ–æ•°æ®

**å‡½æ•°**: [api/db/services/dialog_service.py](../../api/db/services/dialog_service.py) `use_sql()`

**å·¥ä½œæµç¨‹**:
```python
# 1. æ£€æŸ¥å­—æ®µæ˜ å°„
field_map = KnowledgebaseService.get_field_map(dialog.kb_ids)

if field_map:
    # 2. ç”Ÿæˆ SQL
    ans = await use_sql(
        question,
        field_map,
        tenant_id,
        chat_mdl,
        quote=True,
        kb_ids=dialog.kb_ids
    )
    
    # 3. æ‰§è¡ŒæŸ¥è¯¢å¹¶è¿”å›ç»“æœ
    if ans:
        yield ans
        return
```

**é€‚ç”¨åœºæ™¯**:
- ç»“æ„åŒ–æ•°æ®æŸ¥è¯¢
- æŠ¥è¡¨ç”Ÿæˆ
- æ•°æ®åˆ†æ

#### è‡ªå®šä¹‰å·¥å…·ç»‘å®š

**API å‚æ•°**: `tools`, `toolcall_session`

**å®ç°**:
```python
# ç»‘å®šå·¥å…·
if toolcall_session and tools:
    chat_mdl.bind_tools(toolcall_session, tools)

# LLM å¯ä»¥è°ƒç”¨è¿™äº›å·¥å…·
```

---

### 9.3 å¤šæ¨¡æ€æ”¯æŒ

#### å›¾ç‰‡ç†è§£

**æ¨¡å‹ç±»å‹**: `image2text`

**æ£€æµ‹é€»è¾‘**:
```python
if TenantLLMService.llm_id2llm_type(dialog.llm_id) == "image2text":
    llm_model_config = TenantLLMService.get_model_config(
        dialog.tenant_id, 
        LLMType.IMAGE2TEXT, 
        dialog.llm_id
    )
```

**æ”¯æŒçš„åœºæ™¯**:
- å›¾ç‰‡å†…å®¹åˆ†æ
- OCR æ–‡å­—æå–
- å›¾è¡¨ç†è§£

#### è¯­éŸ³åˆæˆ (TTS)

**å‡½æ•°**: [api/db/services/dialog_service.py](../../api/db/services/dialog_service.py) `tts()`

**API ç«¯ç‚¹**: POST `/api/v1/conversation/tts`

**å®ç°**:
```python
# æµå¼è¾“å‡ºæ—¶åˆæˆéŸ³é¢‘
async for delta in llm_stream:
    audio_binary = tts(tts_mdl, delta)
    yield {
        "answer": delta,
        "audio_binary": audio_binary
    }
```

**éŸ³é¢‘æ ¼å¼**: MP3/WAV

---

### 9.4 æ€ç»´å¯¼å›¾ç”Ÿæˆ

**åŠŸèƒ½**: è‡ªåŠ¨ç”Ÿæˆå¯¹è¯å†…å®¹çš„æ€ç»´å¯¼å›¾

**API ç«¯ç‚¹**: POST `/api/v1/conversation/mindmap`

**å‡½æ•°**: [api/db/services/dialog_service.py](../../api/db/services/dialog_service.py) `gen_mindmap()`

**ç”Ÿæˆæ ¼å¼**: Markdown æˆ– Mermaid

**ä½¿ç”¨åœºæ™¯**:
- çŸ¥è¯†ç»“æ„å¯è§†åŒ–
- å¯¹è¯å†…å®¹æ€»ç»“
- å­¦ä¹ ç¬”è®°æ•´ç†

---

## 10. æœåŠ¡å±‚æ¶æ„

### 10.1 DialogService æœåŠ¡

**æ–‡ä»¶ä½ç½®**: [api/db/services/dialog_service.py](../../api/db/services/dialog_service.py)

**ç±»**: `DialogService`

**ç»§æ‰¿å…³ç³»**:
```python
CommonService (åŸºç±»)
    â†“
DialogService (å¯¹è¯æœåŠ¡)
```

#### æ ¸å¿ƒæ–¹æ³•

| æ–¹æ³• | åŠŸèƒ½ | è¯´æ˜ |
|------|------|------|
| `save()` | ä¿å­˜å¯¹è¯ | åˆ›å»ºæ–°å¯¹è¯ |
| `get_by_id()` | è·å–å¯¹è¯ | æŒ‰ ID æŸ¥è¯¢ |
| `query()` | æŸ¥è¯¢å¯¹è¯ | å¤šæ¡ä»¶æŸ¥è¯¢ |
| `update_by_id()` | æ›´æ–°å¯¹è¯ | æ›´æ–°é…ç½® |
| `delete_by_id()` | åˆ é™¤å¯¹è¯ | è½¯åˆ é™¤ |
| `get_models()` | è·å–æ¨¡å‹ | åŠ è½½ LLM/åµŒå…¥/é‡æ’æ¨¡å‹ |
| `async_chat()` | å¼‚æ­¥å¯¹è¯ | RAG å¯¹è¯æ ¸å¿ƒ |
| `async_chat_solo()` | çº¯ LLM å¯¹è¯ | ä¸ä½¿ç”¨çŸ¥è¯†åº“ |
| `async_ask()` | æ™ºèƒ½é—®ç­” | API SDK ä½¿ç”¨ |

---

### 10.2 ConversationService æœåŠ¡

**æ–‡ä»¶ä½ç½®**: [api/db/services/conversation_service.py](../../api/db/services/conversation_service.py)

**ç±»**: `ConversationService`

#### æ ¸å¿ƒæ–¹æ³•

| æ–¹æ³• | åŠŸèƒ½ | è¯´æ˜ |
|------|------|------|
| `save()` | ä¿å­˜è½®æ¬¡ | åˆ›å»ºå¯¹è¯è½®æ¬¡ |
| `get_by_id()` | è·å–è½®æ¬¡ | æŒ‰ ID æŸ¥è¯¢ |
| `query()` | æŸ¥è¯¢è½®æ¬¡ | å¤šæ¡ä»¶æŸ¥è¯¢ |
| `update_by_id()` | æ›´æ–°è½®æ¬¡ | æ›´æ–°æ¶ˆæ¯ |
| `structure_answer()` | ç»“æ„åŒ–ç­”æ¡ˆ | æ ¼å¼åŒ–è¾“å‡º |
| `async_completion()` | å¼‚æ­¥å®Œæˆ | å¯¹è¯å®Œæˆæ¥å£ |

---

### 10.3 æ£€ç´¢æœåŠ¡

**æ–‡ä»¶ä½ç½®**: `rag/app/retrieval.py`

**ç±»**: `Retriever`

#### æ ¸å¿ƒæ–¹æ³•

| æ–¹æ³• | åŠŸèƒ½ | è¯´æ˜ |
|------|------|------|
| `retrieval()` | ä¸»æ£€ç´¢æ¥å£ | å‘é‡+å…¨æ–‡æ··åˆæ£€ç´¢ |
| `retrieval_by_children()` | å­åˆ†å—æ£€ç´¢ | æ‰©å±•ä¸Šä¸‹æ–‡ |
| `retrieval_by_toc()` | ç›®å½•æ£€ç´¢ | åŸºäºç›®å½•ç»“æ„ |
| `insert_citations()` | æ’å…¥å¼•ç”¨ | è‡ªåŠ¨æ ‡æ³¨æ¥æº |

---

## 11. æ€§èƒ½ä¼˜åŒ–

### 11.1 å¼‚æ­¥å¤„ç†

**æ ¸å¿ƒä¼˜åŠ¿**:
- éé˜»å¡ I/O
- é«˜å¹¶å‘å¤„ç†
- èµ„æºåˆ©ç”¨ç‡é«˜

**å®ç°ç¤ºä¾‹**:
```python
# å¼‚æ­¥å‡½æ•°
async def async_chat(dialog, messages, stream=True, **kwargs):
    # å¼‚æ­¥è¿­ä»£
    async for ans in chat_mdl.async_chat_streamly(...):
        yield ans
```

**å…³é”®ç»„ä»¶**:
- **Quart**: å¼‚æ­¥ Web æ¡†æ¶
- **asyncio**: Python å¼‚æ­¥åº“
- **aiohttp**: å¼‚æ­¥ HTTP å®¢æˆ·ç«¯

---

### 11.2 ç¼“å­˜ç­–ç•¥

#### åµŒå…¥å‘é‡ç¼“å­˜

**ç­–ç•¥**: ç¼“å­˜å¸¸è§é—®é¢˜çš„å‘é‡

**å®ç°**:
```python
# Redis ç¼“å­˜
cache_key = f"embd:{question_hash}"
vector = redis.get(cache_key)

if not vector:
    vector = embd_mdl.encode(question)
    redis.set(cache_key, vector, ex=3600)
```

#### æ£€ç´¢ç»“æœç¼“å­˜

**ç­–ç•¥**: ç¼“å­˜é«˜é¢‘é—®é¢˜çš„æ£€ç´¢ç»“æœ

**ç¼“å­˜æ—¶é—´**: 
- çƒ­ç‚¹é—®é¢˜: 1å°æ—¶
- ä¸€èˆ¬é—®é¢˜: 10åˆ†é’Ÿ

---

### 11.3 æµå¼ä¼˜åŒ–

#### Token ç¼“å†²

**ç›®çš„**: å‡å°‘ç½‘ç»œä¼ è¾“æ¬¡æ•°

**å®ç°**:
```python
last_ans = ""
for new_ans in llm_stream:
    delta = new_ans[len(last_ans):]
    
    # ç´¯ç§¯è‡³å°‘ 16 ä¸ª Token
    if num_tokens_from_string(delta) >= 16:
        yield delta
        last_ans = new_ans

# è¾“å‡ºå‰©ä½™å†…å®¹
if last_ans != new_ans:
    yield new_ans[len(last_ans):]
```

#### å‹ç¼©ä¼ è¾“

**å“åº”å¤´**:
```http
Content-Encoding: gzip
```

**å‹ç¼©ç‡**: é€šå¸¸å¯å‡å°‘ 60-80% çš„ä¼ è¾“é‡

---

### 11.4 æ•°æ®åº“ä¼˜åŒ–

#### ç´¢å¼•è®¾è®¡

```sql
-- å¯¹è¯æŸ¥è¯¢ç´¢å¼•
CREATE INDEX idx_dialog_tenant_status 
ON dialog(tenant_id, status);

-- æ¶ˆæ¯æŸ¥è¯¢ç´¢å¼•
CREATE INDEX idx_conversation_dialog_user 
ON conversation(dialog_id, user_id);

-- æ—¶é—´æ’åºç´¢å¼•
CREATE INDEX idx_conversation_create_time 
ON conversation(create_time DESC);
```

#### æŸ¥è¯¢ä¼˜åŒ–

**é¿å… N+1 æŸ¥è¯¢**:
```python
# âŒ ä¸å¥½çš„åšæ³•
for dialog in dialogs:
    kb_names = get_kb_names(dialog.kb_ids)

# âœ… å¥½çš„åšæ³•
kb_id_to_name = get_all_kb_names(all_kb_ids)
for dialog in dialogs:
    dialog.kb_names = [kb_id_to_name[id] for id in dialog.kb_ids]
```

---

### 11.5 ç›‘æ§å’Œè¿½è¸ª

#### Langfuse é›†æˆ

**é…ç½®**: [api/db/services/tenant_langfuse_service.py](../../api/db/services/tenant_langfuse_service.py)

**è¿½è¸ªå†…å®¹**:
- LLM è°ƒç”¨
- Token ä½¿ç”¨é‡
- å“åº”æ—¶é—´
- é”™è¯¯ç‡

**å®ç°**:
```python
# åˆ›å»ºè¿½è¸ª
langfuse_tracer = Langfuse(
    public_key=keys.public_key,
    secret_key=keys.secret_key,
    host=keys.host
)

# å¼€å§‹ç”Ÿæˆè¿½è¸ª
langfuse_generation = langfuse_tracer.start_generation(
    trace_context=trace_context,
    name="chat",
    model=llm_model_config["llm_name"],
    input={"prompt": prompt, "messages": msg}
)

# ç»“æŸè¿½è¸ª
langfuse_generation.update(output=output)
langfuse_generation.end()
```

**æ€§èƒ½æŒ‡æ ‡**:
```python
# æ—¶é—´ç»Ÿè®¡
- æ€»è€—æ—¶: 1500ms
- æ£€æŸ¥ LLM: 10ms
- ç»‘å®šæ¨¡å‹: 50ms
- é—®é¢˜ç²¾ç‚¼: 200ms
- æ£€ç´¢: 800ms
- ç”Ÿæˆç­”æ¡ˆ: 440ms

# Token ç»Ÿè®¡
- ç”Ÿæˆ Token: 256
- Token é€Ÿåº¦: 582 token/s
```

---

## 12. æœ€ä½³å®è·µ

### 12.1 å¯¹è¯è®¾è®¡

#### 1. å‘½åè§„èŒƒ

```python
# âœ… å¥½çš„å‘½å
"å®¢æˆ·æŠ€æœ¯æ”¯æŒå¯¹è¯"
"äº§å“åŠŸèƒ½å’¨è¯¢åŠ©æ‰‹"
"å†…éƒ¨æ–‡æ¡£é—®ç­”ç³»ç»Ÿ"

# âŒ ä¸å¥½çš„å‘½å
"æµ‹è¯•å¯¹è¯"
"æ–°å»ºå¯¹è¯1"
"aaa"
```

#### 2. æç¤ºè¯è®¾è®¡

**ç³»ç»Ÿæç¤ºè¯æ¨¡æ¿**:
```
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„{é¢†åŸŸ}åŠ©æ‰‹ã€‚

ä½ çš„èŒè´£:
1. {èŒè´£1}
2. {èŒè´£2}
3. {èŒè´£3}

ä½¿ç”¨ä»¥ä¸‹çŸ¥è¯†åº“å†…å®¹å›ç­”é—®é¢˜:
{knowledge}

å›ç­”è¦æ±‚:
- å‡†ç¡®: åŸºäºçŸ¥è¯†åº“å†…å®¹
- ç®€æ´: é¿å…å†—é•¿
- å‹å¥½: ä½¿ç”¨ç¤¼è²Œç”¨è¯­
- å¼•ç”¨: æ ‡æ³¨ä¿¡æ¯æ¥æº
```

**å¼€åœºç™½è®¾è®¡**:
```
æ‚¨å¥½ï¼æˆ‘æ˜¯{ç³»ç»Ÿåç§°}åŠ©æ‰‹ã€‚

æˆ‘å¯ä»¥å¸®æ‚¨:
âœ“ {åŠŸèƒ½1}
âœ“ {åŠŸèƒ½2}
âœ“ {åŠŸèƒ½3}

è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„ï¼Ÿ
```

#### 3. çŸ¥è¯†åº“é€‰æ‹©

**å•çŸ¥è¯†åº“**: é€‚åˆä¸“ä¸šé¢†åŸŸ
```json
{
  "kb_ids": ["technical_docs_kb"]
}
```

**å¤šçŸ¥è¯†åº“**: é€‚åˆç»¼åˆé—®ç­”
```json
{
  "kb_ids": [
    "product_docs_kb",
    "faq_kb",
    "api_reference_kb"
  ]
}
```

**æ³¨æ„**: æ‰€æœ‰çŸ¥è¯†åº“å¿…é¡»ä½¿ç”¨ç›¸åŒçš„åµŒå…¥æ¨¡å‹

---

### 12.2 å‚æ•°è°ƒä¼˜

#### åœºæ™¯ 1: å®¢æœé—®ç­”

```json
{
  "llm_setting": {
    "temperature": 0.1,
    "top_p": 0.3,
    "max_tokens": 512
  },
  "similarity_threshold": 0.3,
  "vector_similarity_weight": 0.5,
  "top_n": 6
}
```

**ç‰¹ç‚¹**: ç¨³å®šã€å‡†ç¡®ã€åŸºäºçŸ¥è¯†åº“

---

#### åœºæ™¯ 2: åˆ›æ„å†™ä½œ

```json
{
  "llm_setting": {
    "temperature": 0.9,
    "top_p": 0.8,
    "max_tokens": 2048
  },
  "similarity_threshold": 0.2,
  "vector_similarity_weight": 0.3,
  "top_n": 3
}
```

**ç‰¹ç‚¹**: å¤šæ ·åŒ–ã€åˆ›é€ æ€§ã€çµæ´»

---

#### åœºæ™¯ 3: æŠ€æœ¯æ–‡æ¡£

```json
{
  "llm_setting": {
    "temperature": 0.2,
    "top_p": 0.4,
    "max_tokens": 1024
  },
  "similarity_threshold": 0.4,
  "vector_similarity_weight": 0.7,
  "top_n": 8,
  "prompt_config": {
    "toc_enhance": true,
    "quote": true
  }
}
```

**ç‰¹ç‚¹**: ç²¾ç¡®ã€è¯¦ç»†ã€æœ‰å¼•ç”¨

---

### 12.3 é”™è¯¯å¤„ç†

#### 1. ä¼˜é›…é™çº§

```python
try:
    # å°è¯• RAG å¯¹è¯
    async for ans in async_chat(dialog, messages):
        yield ans
except Exception as e:
    # é™çº§ä¸ºçº¯ LLM å¯¹è¯
    logging.error(f"RAG failed: {e}")
    async for ans in async_chat_solo(dialog, messages):
        yield ans
```

#### 2. ç©ºç»“æœå¤„ç†

```python
# è®¾ç½®ç©ºå“åº”æç¤º
{
  "prompt_config": {
    "empty_response": "æŠ±æ­‰ï¼Œæˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚\n\næ‚¨å¯ä»¥:\n1. æ¢ä¸ªæ–¹å¼æé—®\n2. è”ç³»äººå·¥å®¢æœ\n3. æŸ¥çœ‹å¸®åŠ©æ–‡æ¡£"
  }
}
```

#### 3. è¶…æ—¶å¤„ç†

```python
# è®¾ç½®è¶…æ—¶æ—¶é—´
timeout = 30  # ç§’

try:
    async with asyncio.timeout(timeout):
        result = await async_chat(...)
except asyncio.TimeoutError:
    return {
        "answer": "è¯·æ±‚å¤„ç†è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•",
        "reference": {}
    }
```

---

### 12.4 å®‰å…¨å®è·µ

#### 1. è¾“å…¥éªŒè¯

```python
# é•¿åº¦é™åˆ¶
MAX_MESSAGE_LENGTH = 10000

if len(message) > MAX_MESSAGE_LENGTH:
    raise ValueError("Message too long")

# å†…å®¹è¿‡æ»¤
if contains_harmful_content(message):
    raise ValueError("Harmful content detected")
```

#### 2. æƒé™æ§åˆ¶

```python
# æ£€æŸ¥å¯¹è¯è®¿é—®æƒé™
if not check_dialog_access(dialog_id, user_id):
    raise PermissionError("No access to this dialog")

# æ£€æŸ¥çŸ¥è¯†åº“æƒé™
for kb_id in dialog.kb_ids:
    if not check_kb_access(kb_id, user_id):
        raise PermissionError(f"No access to KB {kb_id}")
```

#### 3. API Key ä¿æŠ¤

```python
# ä¸åœ¨æ—¥å¿—ä¸­æš´éœ² API Key
logging.info(f"Using model: {model_name}")  # âœ…
logging.info(f"API Key: {api_key}")         # âŒ
```

---

### 12.5 ç”¨æˆ·ä½“éªŒä¼˜åŒ–

#### 1. æµå¼è¾“å‡º

**æ¨è**: å¯¹äº >100 Token çš„å›ç­”ä½¿ç”¨æµå¼

```python
{
  "stream": true  # å¯ç”¨æµå¼
}
```

#### 2. åŠ è½½æç¤º

**å‰ç«¯å®ç°**:
```javascript
// æ˜¾ç¤ºåŠ è½½åŠ¨ç”»
showLoading("æ­£åœ¨æ€è€ƒ...");

// å¼€å§‹æ¥æ”¶æµå¼æ•°æ®
eventSource.onmessage = (event) => {
  const data = JSON.parse(event.data);
  updateAnswer(data.answer);
};
```

#### 3. å¼•ç”¨å±•ç¤º

**å‰ç«¯å®ç°**:
```javascript
// é«˜äº®å¼•ç”¨æ ‡æ³¨
answer = answer.replace(
  /\[ID:(\d+)\]/g,
  '<sup class="citation" data-id="$1">[$1]</sup>'
);

// ç‚¹å‡»å¼•ç”¨æ˜¾ç¤ºæ¥æº
$('.citation').click(function() {
  const chunkId = $(this).data('id');
  showChunkDetail(chunkId);
});
```

---

## 13. æ•…éšœæ’æŸ¥

### 13.1 å¸¸è§é—®é¢˜

#### é—®é¢˜ 1: å¯¹è¯æ— å“åº”

**ç—‡çŠ¶**: è¯·æ±‚å‘é€åé•¿æ—¶é—´æ— å“åº”

**æ’æŸ¥æ­¥éª¤**:
```python
# 1. æ£€æŸ¥ LLM é…ç½®
check_llm_api_key(dialog.llm_id)

# 2. æ£€æŸ¥çŸ¥è¯†åº“çŠ¶æ€
check_kb_status(dialog.kb_ids)

# 3. æ£€æŸ¥æ—¥å¿—
tail -f logs/ragflow_server.log
```

**å¯èƒ½åŸå› **:
- LLM API Key æ— æ•ˆ
- çŸ¥è¯†åº“ä¸ºç©º
- ç½‘ç»œè¶…æ—¶

---

#### é—®é¢˜ 2: æ£€ç´¢ç»“æœä¸ç›¸å…³

**ç—‡çŠ¶**: è¿”å›çš„åˆ†å—ä¸é—®é¢˜æ— å…³

**æ’æŸ¥æ­¥éª¤**:
```python
# 1. æ£€æŸ¥ç›¸ä¼¼åº¦é˜ˆå€¼
if similarity_threshold > 0.5:
    # é˜ˆå€¼è¿‡é«˜ï¼Œé™ä½åˆ° 0.2-0.4

# 2. æ£€æŸ¥åµŒå…¥æ¨¡å‹
check_embedding_model_version()

# 3. æµ‹è¯•æ£€ç´¢
test_retrieval(question, kb_ids)
```

**è§£å†³æ–¹æ¡ˆ**:
- é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼
- å¢åŠ æ£€ç´¢æ•°é‡ (top_k)
- ä½¿ç”¨é‡æ’åºæ¨¡å‹

---

#### é—®é¢˜ 3: ç­”æ¡ˆæ— å¼•ç”¨

**ç—‡çŠ¶**: ç­”æ¡ˆä¸­æ²¡æœ‰ `[ID:n]` æ ‡æ³¨

**æ’æŸ¥æ­¥éª¤**:
```python
# 1. æ£€æŸ¥å¼•ç”¨é…ç½®
if not prompt_config.get("quote", True):
    # å¼•ç”¨è¢«ç¦ç”¨

# 2. æ£€æŸ¥ do_refer å­—æ®µ
if dialog.do_refer != "1":
    # å¼•ç”¨è¢«å…³é—­

# 3. æ£€æŸ¥åµŒå…¥æ¨¡å‹
if not embd_mdl:
    # æ— æ³•æ’å…¥å¼•ç”¨
```

**è§£å†³æ–¹æ¡ˆ**:
```json
{
  "do_refer": "1",
  "prompt_config": {
    "quote": true
  }
}
```

---

### 13.2 æ€§èƒ½é—®é¢˜

#### é—®é¢˜: å“åº”é€Ÿåº¦æ…¢

**æ’æŸ¥æŒ‡æ ‡**:
```python
# æŸ¥çœ‹æ€§èƒ½ç»Ÿè®¡
{
  "prompt": "...\n\n## Time elapsed:\n  - Total: 3500ms\n  - Retrieval: 2800ms\n  - Generate: 700ms"
}
```

**ä¼˜åŒ–æ–¹æ¡ˆ**:

**1. æ£€ç´¢ä¼˜åŒ–**
```python
# å‡å°‘æ£€ç´¢æ•°é‡
"top_k": 500,  # ä» 1024 é™ä½
"top_n": 4,    # ä» 8 é™ä½
```

**2. ä½¿ç”¨ç¼“å­˜**
```python
# å¯ç”¨ç»“æœç¼“å­˜
cache_retrieval_results = True
```

**3. å¹¶è¡Œå¤„ç†**
```python
# å¹¶è¡Œè°ƒç”¨å¤šä¸ªçŸ¥è¯†åº“
results = await asyncio.gather(*[
    retrieve_from_kb(kb_id) for kb_id in kb_ids
])
```

---

## 14. API SDK ä½¿ç”¨

### 14.1 Python SDK

**å®‰è£…**:
```bash
pip install ragflow-sdk
```

**ç¤ºä¾‹ä»£ç **:
```python
from ragflow import RAGFlow

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = RAGFlow(
    api_key="your_api_key",
    base_url="http://localhost:9380"
)

# åˆ›å»ºå¯¹è¯
dialog = client.create_dialog(
    name="æŠ€æœ¯æ”¯æŒ",
    kb_ids=["kb_uuid"],
    llm_id="gpt-4o-mini"
)

# å‘é€æ¶ˆæ¯
response = dialog.chat(
    question="ä»€ä¹ˆæ˜¯ RAGï¼Ÿ",
    stream=True
)

# æµå¼æ¥æ”¶
for chunk in response:
    print(chunk.answer, end="", flush=True)
```

---

### 14.2 HTTP API

**ç¤ºä¾‹**: cURL è¯·æ±‚

```bash
# åˆ›å»ºå¯¹è¯
curl -X POST http://localhost:9380/api/v1/dialog/set \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "æŠ€æœ¯æ”¯æŒ",
    "kb_ids": ["kb_uuid"],
    "llm_id": "gpt-4o-mini"
  }'

# å‘é€æ¶ˆæ¯
curl -X POST http://localhost:9380/api/v1/conversation/completion \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "conversation_id": "conv_uuid",
    "messages": [
      {"role": "user", "content": "ä»€ä¹ˆæ˜¯ RAGï¼Ÿ"}
    ],
    "stream": false
  }'
```

---

## ç›¸å…³æ–‡æ¡£

- [å¯¹è¯æ¨¡å— README](./README.md)
- [åˆ›å»ºå¯¹è¯æ—¶åºå›¾](./01-create-dialog-sequence.puml)
- [åŒæ­¥å¯¹è¯æ—¶åºå›¾](./02-sync-chat-sequence.puml)
- [æµå¼å¯¹è¯æ—¶åºå›¾](./03-stream-chat-sequence.puml)
- [æ¶ˆæ¯åé¦ˆæ—¶åºå›¾](./04-message-feedback-sequence.puml)
- [æ£€ç´¢é›†æˆæ—¶åºå›¾](./05-retrieval-integration-sequence.puml)
