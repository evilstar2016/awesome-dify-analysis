@startuml
!theme plain
skinparam backgroundColor #FFFFFF
skinparam sequenceArrowColor #1976D2
skinparam sequenceActorBorderColor #426450ff
skinparam sequenceParticipantBorderColor #6C757D
skinparam SequenceParticipantBorderThickness 2
skinparam sequenceLifeLineBorderColor #9bd0f5ff
skinparam noteBackgroundColor #FFF3E0
skinparam noteBorderColor #F57C00
skinparam style strictuml
skinparam Padding 6
skinparam ParticipantPadding 30

title 混合检索流程 (Hybrid Search with Weighted Fusion)

participant "检索器\nDealer" as Dealer
participant "嵌入服务\nEmbedding" as Embed
participant "查询处理器\nQueryer" as Queryer
participant "数据存储\nES/Infinity/OB" as DataStore
participant "重排序器\nReranker" as Rerank

Dealer -> Dealer: retrieval(\n  question="如何使用 RAGFlow?",\n  kb_ids=["kb1", "kb2"],\n  top=1024,\n  page_size=8,\n  vector_similarity_weight=0.3\n)
activate Dealer

== 1. 构建检索请求 ==

Dealer -> Dealer: 准备检索参数\nreq = {\n  "kb_ids": kb_ids,\n  "size": RERANK_LIMIT,  # 64\n  "question": question,\n  "vector": True,\n  "topk": 1024,\n  "similarity": 0.2\n}

Dealer -> Dealer: search(\n  req, index_names,\n  kb_ids, embd_mdl\n)
activate Dealer #LightBlue

== 2. 查询处理 ==

Dealer -> Queryer: question(\n  qst=question,\n  min_match=0.3\n)
activate Queryer

Queryer -> Queryer: 分词与关键词提取\nkeywords = rag_tokenizer.tokenize(query)\nmatchText = build_match_query(keywords)

note over Queryer
提取关键词并构建全文查询
例如: ["使用", "RAGFlow"]
end note

Queryer --> Dealer: matchText, keywords
deactivate Queryer

Dealer -> Embed: get_vector(\n  qst=question,\n  emb_mdl=embd_mdl\n)
activate Embed

Embed -> Embed: 调用嵌入模型\nvector = model.encode(\n  question,\n  normalize=True\n)

Embed --> Dealer: embedding_data\n[0.12, 0.34, ..., 0.56]\n(1536维)
deactivate Embed

Dealer -> Dealer: 构建查询表达式\nmatchDense = MatchDenseExpr(\n  vector_column=f"q_{dim}_vec",\n  embedding_data=vector,\n  topn=topk,\n  similarity=0.1\n)

== 3. 构建加权融合表达式 ==

Dealer -> Dealer: 构建融合策略\nfusionExpr = FusionExpr(\n  method="weighted_sum",\n  topn=topk,\n  fusion_params={\n    "weights": "0.05,0.95"\n  }\n)

note over Dealer
默认融合权重：
- 全文检索: 0.05 (5%)
- 向量检索: 0.95 (95%)

用户通过 vector_similarity_weight
参数调整实际应用时的权重
end note

Dealer -> Dealer: 组装匹配表达式\nmatchExprs = [\n  matchText,      # 全文检索\n  matchDense,     # 向量检索\n  fusionExpr      # 融合策略\n]

== 4. 执行混合检索 ==

Dealer -> DataStore: search(\n  fields=src,\n  filters=filters,\n  matchExprs=matchExprs,\n  offset=0,\n  limit=RERANK_LIMIT\n)
activate DataStore

note over DataStore
数据库引擎自动执行：
1. 全文检索 (BM25/IK分词)
2. 向量检索 (HNSW/IVF)
3. 加权融合 (weighted_sum)

一次查询完成，无需手动RRF
end note

alt Elasticsearch

    DataStore -> DataStore: 构建混合查询\n{\n  "query": {\n    "bool": {\n      "must": [\n        {"match": {"content_ltks": keywords}}\n      ],\n      "filter": [\n        {"terms": {"kb_id": kb_ids}},\n        {"term": {"available_int": 1}}\n      ]\n    },\n    "boost": 0.05\n  },\n  "knn": {\n    "field": "q_1536_vec",\n    "query_vector": vector,\n    "k": 1024,\n    "boost": 0.95\n  }\n}

    note over DataStore
    ES 使用 knn + query 混合
    通过 boost 控制权重
    end note

else Infinity

    DataStore -> DataStore: 构建原生融合查询\nSEARCH ...\n  MATCH TEXT 'content_ltks' ...\n    WEIGHT 0.05\n  MATCH DENSE 'q_1536_vec' ...\n    WEIGHT 0.95\n  FUSION 'weighted_sum'\n  LIMIT 1024

    note over DataStore
    Infinity 原生支持融合
    自动标准化并加权
    无需手动计算
    end note

else OceanBase

    DataStore -> DataStore: 构建混合 SQL\nWITH fulltext AS (\n  SELECT id, MATCH(...) AS score\n  FROM table WHERE ...\n  LIMIT 1024\n),\nvector AS (\n  SELECT id, (1 - cosine_distance(...)) AS score\n  FROM table WHERE ...\n  LIMIT 1024\n)\nSELECT *,\n  (f.score * 0.05 + v.score * 0.95) AS _score\nFROM fulltext f\nFULL OUTER JOIN vector v ON f.id = v.id\nORDER BY _score DESC

    note over DataStore
    OceanBase 使用 SQL 融合
    支持全文索引和向量索引
    通过 HybridSearch 优化
    end note

end

DataStore -> DataStore: 执行检索与融合\n- 全文检索: BM25 算法\n- 向量检索: HNSW/IVF 索引\n- 加权融合: weighted_sum

DataStore --> Dealer: 返回融合结果\nsres = SearchResult(\n  total=156,\n  ids=[chunk_ids],\n  field={chunk_data},\n  query_vector=vector,\n  keywords=keywords\n)
deactivate DataStore

deactivate Dealer

note over Dealer
一次查询完成混合检索
数据库内部完成融合
无需额外 RRF 步骤
end note

== 5. 重排序 ==

alt 配置了重排模型

    Dealer -> Rerank: rerank_by_model(\n  rerank_mdl=rerank_mdl,\n  sres=sres,\n  query=question,\n  tkweight=0.7,  # 1 - vector_weight\n  vtweight=0.3   # vector_weight\n)
    activate Rerank

    note over Rerank
    使用 Cross-Encoder 重排
    (详见 02-reranking-sequence.puml)
    end note

    Rerank --> Dealer: sim, tsim, vsim
    deactivate Rerank

else Infinity (自动标准化)

    Dealer -> Dealer: 直接使用融合分数\nsim = [doc.get("_score", 0.0) for doc in sres]\ntsim = sim\nvsim = sim

    note over Dealer
    Infinity 已标准化分数
    无需额外重排
    end note

else Elasticsearch (需手动重排)

    Dealer -> Dealer: rerank(\n  sres, question,\n  tkweight=0.7,\n  vtweight=0.3\n)
    activate Dealer #LightGreen

    note over Dealer
    ES 未标准化分数
    需重新计算混合相似度
    (详见 02-reranking-sequence.puml)
    end note

    Dealer -> Dealer: hybrid_similarity(\n  query_vector,\n  doc_vectors,\n  query_keywords,\n  doc_tokens,\n  tkweight, vtweight\n)

    Dealer -> Dealer: 添加 Rank Feature\nsim = sim + rank_fea

    deactivate Dealer

end

== 6. 排序与过滤 ==

Dealer -> Dealer: 按分数排序\nsorted_idx = np.argsort(sim * -1)

Dealer -> Dealer: 过滤低分文档\nvalid_idx = [\n  i for i in sorted_idx\n  if sim[i] >= similarity_threshold\n]

note over Dealer
默认阈值: 0.2
过滤掉低相关性文档
end note

Dealer -> Dealer: 分页截取\npage_idx = valid_idx[\n  page_index * page_size :\n  page_index * page_size + page_size\n]

note over Dealer
示例: page=1, page_size=8
返回第 1-8 个结果
end note

== 7. 构建返回结果 ==

loop 遍历 page_idx

    Dealer -> Dealer: 构建 chunk 数据\nchunk = {\n  "chunk_id": id,\n  "content_with_weight": content,\n  "similarity": float(sim[i]),\n  "vector_similarity": float(vsim[i]),\n  "term_similarity": float(tsim[i]),\n  "doc_id": doc_id,\n  "docnm_kwd": doc_name,\n  "kb_id": kb_id,\n  "positions": position_int,\n  ...\n}

    Dealer -> Dealer: chunks.append(chunk)

end

== 8. 文档聚合 ==

Dealer -> Dealer: 按文档聚合\ndoc_aggs = {}\nfor chunk in all_valid_chunks:\n  doc_name = chunk["docnm_kwd"]\n  if doc_name not in doc_aggs:\n    doc_aggs[doc_name] = {\n      "doc_id": chunk["doc_id"],\n      "count": 0\n    }\n  doc_aggs[doc_name]["count"] += 1

Dealer -> Dealer: 排序聚合结果\nsorted_aggs = sorted(\n  doc_aggs.items(),\n  key=lambda x: x[1]["count"],\n  reverse=True\n)

== 9. 返回结果 ==

Dealer -> Dealer: 返回检索结果\nreturn {\n  "total": len(valid_idx),\n  "chunks": chunks,\n  "doc_aggs": sorted_aggs\n}

deactivate Dealer

note right of DataStore
  数据库索引配置：
  
  Elasticsearch:
  {
    "mappings": {
      "properties": {
        "q_1536_vec": {
          "type": "dense_vector",
          "dims": 1536,
          "index": true,
          "similarity": "cosine"
        },
        "content_ltks": {
          "type": "text",
          "analyzer": "ik_smart"
        },
        "content_with_weight": {
          "type": "text",
          "analyzer": "ik_max_word"
        }
      }
    }
  }
  
  Infinity:
  - 原生向量索引 (HNSW)
  - 全文索引 (IK 分词)
  - 原生 weighted_sum 融合
  
  OceanBase:
  - 向量索引 (HNSW/VSAG)
  - 全文索引 (IK Parser)
  - HybridSearch 支持
end note

note right of Dealer
  加权融合说明：
  
  weights = "0.05,0.95"
  - 全文检索权重: 5%
  - 向量检索权重: 95%
  
  用户参数 vector_similarity_weight
  控制重排序时的权重（默认 0.3）
  
  融合公式：
  score = text_score * 0.05 + 
          vector_score * 0.95
  
  与 RRF 的区别：
  - weighted_sum: 加权平均分数
  - RRF: 倒数排名融合
  - RAGFlow 使用 weighted_sum
  - 需要数据库原生支持
end note

note left of Rerank
  重排模型选择：
  
  1. BGE Reranker
     - 开源模型
     - 中英文支持
     - 效果优秀
  
  2. Cohere Rerank
     - 商业 API 服务
     - 多语言支持
     - 调用方便
  
  3. LLM Rerank
     - 使用 GPT-4 等
     - 准确度最高
     - 成本较高
end note

@enduml
