@startuml
!theme plain
skinparam backgroundColor #FFFFFF
skinparam sequenceArrowColor #1976D2
skinparam sequenceActorBorderColor #426450ff
skinparam sequenceParticipantBorderColor #6C757D
skinparam SequenceParticipantBorderThickness 2
skinparam sequenceLifeLineBorderColor #9bd0f5ff
skinparam noteBackgroundColor #FFF3E0
skinparam noteBorderColor #F57C00
skinparam style strictuml
skinparam Padding 6
skinparam ParticipantPadding 30

title 重排序流程 (Reranking)

participant "检索器\nDealer" as Dealer
participant "查询处理器\nQueryer" as Queryer
participant "重排模型\nReranker" as Reranker
participant "Token 分词器\nTokenizer" as Tokenizer
participant "检索结果\nSearchResults" as Results

Dealer -> Dealer: retrieval(\n  question="如何使用 RAGFlow?",\n  rerank_mdl=reranker_model,\n  vector_similarity_weight=0.3\n)
activate Dealer

note over Dealer
收到初步检索结果：
- total: 100+ 个候选文档
- 需要重排序选出 Top 8
end note

== 1. 决定重排策略 ==

alt 配置了重排模型

    note over Dealer
    使用 Cross-Encoder 重排
    (BGE Reranker / Cohere)
    end note

    Dealer -> Dealer: rerank_by_model(\n  rerank_mdl=rerank_mdl,\n  sres=search_results,\n  query=question,\n  tkweight=0.7,  # 1 - vector_weight\n  vtweight=0.3   # vector_weight\n)
    activate Dealer #LightBlue

    == 1.1 查询处理 ==

    Dealer -> Queryer: question(query)
    activate Queryer

    Queryer -> Queryer: 分词与关键词提取\nkeywords = rag_tokenizer.tokenize(query)\nkeywords = remove_stopwords(keywords)

    note over Queryer
    提取查询关键词：
    ["使用", "RAGFlow"]
    end note

    Queryer --> Dealer: keywords
    deactivate Queryer

    == 1.2 候选文档处理 ==

    loop 遍历每个候选文档 in search_results

        Dealer -> Results: 获取文档字段\ncontent_ltks = doc["content_ltks"]\ntitle_tks = doc["title_tks"]\nimportant_kwd = doc["important_kwd"]
        activate Results

        Results --> Dealer: 文档 Tokens
        deactivate Results

        Dealer -> Dealer: 组合 Tokens\ntks = content_ltks + \n      title_tks + \n      important_kwd

        note over Dealer
        增强关键词权重：
        - 标题 tokens: 1x
        - 重要关键词: 1x
        - 内容 tokens: 1x
        end note

        Dealer -> Dealer: doc_texts.append(\n  " ".join(tks)\n)

    end

    == 1.3 Token 相似度计算 ==

    Dealer -> Queryer: token_similarity(\n  keywords=keywords,\n  doc_tokens=doc_texts\n)
    activate Queryer

    Queryer -> Queryer: 计算词频匹配\nfor each doc:\n  score = 0\n  for keyword in keywords:\n    if keyword in doc_tokens:\n      score += tf * idf

    note over Queryer
    使用 BM25 类似算法
    计算关键词匹配分数
    end note

    Queryer --> Dealer: tksim (Token 相似度数组)\n[0.65, 0.42, 0.58, ...]
    deactivate Queryer

    == 1.4 Cross-Encoder 重排 ==

    Dealer -> Reranker: similarity(\n  query=query,\n  documents=doc_texts\n)
    activate Reranker

    note over Reranker
    Cross-Encoder 模型：
    - BGE Reranker Large
    - 或 Cohere Rerank API
    end note

    Reranker -> Reranker: 批量编码\nfor (query, doc) in pairs:\n  score = model.encode(\n    f"[CLS] {query} [SEP] {doc} [SEP]"\n  )\n  scores.append(score)

    note over Reranker
    Cross-Encoder 直接计算
    query-document 匹配分数
    (比向量相似度更准确)
    end note

    Reranker --> Dealer: vtsim (向量相似度数组)\n[0.82, 0.56, 0.71, ...],\nconfidences
    deactivate Reranker

    == 1.5 融合分数计算 ==

    Dealer -> Dealer: 计算 Rank Feature 分数\nrank_fea = []
    activate Dealer #LightGreen

    loop 每个文档

        Dealer -> Dealer: 计算 PageRank 分数\npagerank = doc.get("pagerank_fea", 0)\npagerank_score = pagerank / 100

        Dealer -> Dealer: 计算标签特征分数\ntag_fea = doc.get("tag_feas", {})\ntag_score = 0
        activate Dealer #LightYellow

        loop 每个查询标签

            alt 文档包含该标签

                Dealer -> Dealer: tag_score += \n  query_tag_weight * doc_tag_score

            end

        end

        deactivate Dealer

        Dealer -> Dealer: rank_fea.append(\n  pagerank_score + tag_score\n)

    end

    deactivate Dealer

    Dealer -> Dealer: 融合最终分数\nfinal_scores = \n  tkweight * tksim + \n  vtweight * vtsim + \n  rank_fea

    note over Dealer
    示例 (tkweight=0.7, vtweight=0.3):\n- Token 相似度: 0.65 * 0.7 = 0.455\n- 向量相似度: 0.82 * 0.3 = 0.246\n- Rank 特征:   0.05\n- 总分: 0.751
    end note

    Dealer -> Dealer: return final_scores, tksim, vtsim

    deactivate Dealer

else 未配置重排模型

    note over Dealer
    使用内置混合相似度计算
    end note

    alt 使用 Infinity (标准化融合)

        Dealer -> Results: 获取 Elasticsearch 分数\nsim = [doc.get("_score", 0.0) for doc in results]
        activate Results

        Results --> Dealer: sim (已标准化分数)
        deactivate Results

        note over Dealer
        Infinity 自动标准化向量和全文分数
        可直接使用融合后的分数
        end note

    else 使用 Elasticsearch (需手动融合)

        Dealer -> Dealer: rerank(\n  sres=search_results,\n  query=question,\n  tkweight=0.7,\n  vtweight=0.3\n)
        activate Dealer #LightBlue

        == 重新计算混合相似度 ==

        Dealer -> Queryer: question(query)
        activate Queryer
        Queryer --> Dealer: keywords
        deactivate Queryer

        Dealer -> Results: 获取文档向量\nvectors = [\n  doc.get("q_1536_vec", zero_vector)\n  for doc in results\n]
        activate Results
        Results --> Dealer: vectors
        deactivate Results

        Dealer -> Queryer: hybrid_similarity(\n  query_vector=query_vec,\n  doc_vectors=vectors,\n  query_keywords=keywords,\n  doc_tokens=doc_tokens,\n  tkweight=0.7,\n  vtweight=0.3\n)
        activate Queryer

        Queryer -> Queryer: 计算向量相似度\nvtsim = cosine_similarity(\n  query_vector,\n  doc_vectors\n)

        Queryer -> Queryer: 计算词频相似度\ntksim = bm25_similarity(\n  query_keywords,\n  doc_tokens\n)

        Queryer -> Queryer: 融合分数\nsim = tkweight * tksim + \n      vtweight * vtsim

        Queryer --> Dealer: sim, tksim, vtsim
        deactivate Queryer

        Dealer -> Dealer: 添加 Rank Feature\nsim = sim + rank_fea

        deactivate Dealer

    end

end

== 2. 排序与截断 ==

Dealer -> Dealer: 排序结果\nsorted_idx = np.argsort(sim * -1)

note over Dealer
按分数降序排序
end note

Dealer -> Dealer: 过滤低分结果\nvalid_idx = [\n  i for i in sorted_idx\n  if sim[i] >= similarity_threshold\n]

note over Dealer
默认阈值: 0.2
过滤掉低相关性文档
end note

Dealer -> Dealer: 分页截断\npage_idx = valid_idx[begin:end]

note over Dealer
示例: page=1, page_size=8
返回前 8 个最相关文档
end note

== 3. 构建返回结果 ==

loop 遍历 page_idx

    Dealer -> Results: 获取文档完整信息
    activate Results

    Results --> Dealer: 文档数据\n{\n  "chunk_id": "uuid",\n  "content_with_weight": "...",\n  "similarity": 0.82,\n  "vector_similarity": 0.75,\n  "term_similarity": 0.65,\n  ...\n}
    deactivate Results

    Dealer -> Dealer: chunks.append(doc)

end

Dealer -> Dealer: 聚合文档统计\ndoc_aggs = {\n  "doc_name": {"doc_id": "...", "count": 3},\n  ...\n}

note over Dealer
统计每个源文档的
chunk 数量
end note

Dealer -> Dealer: 返回重排结果\nreturn {\n  "total": filtered_count,\n  "chunks": chunks,\n  "doc_aggs": doc_aggs\n}

deactivate Dealer

note over Dealer
重排后的结果：
- 按相关性排序
- 包含多种相似度分数
- 带文档聚合统计
end note

@enduml
