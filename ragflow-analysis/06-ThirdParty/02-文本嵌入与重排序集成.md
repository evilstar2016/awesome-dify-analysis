# 文本嵌入与重排序集成

## 概述

RAGFlow 支持 30+ 文本嵌入模型提供商和多种重排序服务，为检索增强生成（RAG）系统提供高质量的语义向量化和结果重排序能力。

## 架构设计

### 嵌入模型基类

```python
class Base:
    """嵌入模型基类"""
    
    def encode(self, texts: list[str], batch_size: int = 32) -> np.ndarray:
        """文本编码为向量"""
        raise NotImplementedError
        
    def encode_queries(self, texts: list[str]) -> np.ndarray:
        """查询文本编码（部分模型支持查询优化）"""
        return self.encode(texts)
```

**代码位置**：[rag/llm/embedding_model.py](../../rag/llm/embedding_model.py)

### 重排序基类

```python
class Base:
    """重排序模型基类"""
    
    def similarity(self, query: str, documents: list[str]) -> np.ndarray:
        """计算查询与文档的相似度分数"""
        raise NotImplementedError
```

**代码位置**：[rag/llm/rerank_model.py](../../rag/llm/rerank_model.py)

## 文本嵌入提供商

### 1. OpenAI Embeddings

#### 支持的模型

| 模型名称 | 维度 | 最大 Token | 价格 |
|---------|------|-----------|------|
| text-embedding-3-large | 3072 | 8191 | $$ |
| text-embedding-3-small | 1536 | 8191 | $ |
| text-embedding-ada-002 | 1536 | 8191 | $ |

#### 配置示例

```yaml
OPENAI_API_KEY=sk-xxxxxxxxxxxxx

embedding:
  factory: OpenAI
  model_name: text-embedding-3-large
```

#### 代码实现

```python
class OpenAIEmbed(Base):
    def __init__(self, key, model_name="text-embedding-3-large", **kwargs):
        self.client = OpenAI(api_key=key)
        self.model_name = model_name
        
    def encode(self, texts, batch_size=32):
        embeddings = []
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i+batch_size]
            response = self.client.embeddings.create(
                input=batch,
                model=self.model_name
            )
            embeddings.extend([item.embedding for item in response.data])
        return np.array(embeddings)
```

**实现类**：`OpenAIEmbed` ([rag/llm/embedding_model.py](../../rag/llm/embedding_model.py))

### 2. Cohere Embeddings

#### 支持的模型

- `embed-english-v3.0` - 1024维，英文优化
- `embed-multilingual-v3.0` - 1024维，100+ 语言
- `embed-english-light-v3.0` - 384维，轻量级

#### 配置示例

```yaml
COHERE_API_KEY=xxxxxxxxxxxxx

embedding:
  factory: Cohere
  model_name: embed-multilingual-v3.0
```

**依赖**：`cohere==5.6.2`
**实现类**：`CoHereEmbed`

### 3. Voyage AI

高质量检索优化嵌入模型：

```yaml
VOYAGE_API_KEY=pa-xxxxxxxxxxxxx

embedding:
  factory: Voyage
  model_name: voyage-3
```

#### 支持的模型

- `voyage-3` - 最新版本，1024维
- `voyage-3-lite` - 轻量版本，512维
- `voyage-code-3` - 代码优化，1024维
- `voyage-finance-2` - 金融领域，1024维

**依赖**：`voyageai==0.2.3`
**实现类**：`VoyageEmbed`

### 4. Jina AI

多模态嵌入模型：

```yaml
JINA_API_KEY=jina_xxxxxxxxxxxxx

embedding:
  factory: Jina
  model_name: jina-embeddings-v3
```

**特性**：
- 支持文本和图像嵌入
- 8192 token 上下文
- 多语言支持

**实现类**：`JinaMultiVecEmbed`

### 5. 本地嵌入模型

#### 5.1 BuiltinEmbed（内置模型）

使用 ONNX Runtime 本地运行：

```yaml
embedding:
  factory: Youdao
  model_name: maidalun1020/bce-embedding-base_v1
```

**特性**：
- 无需 API 调用
- 支持 CPU/GPU
- 适合离线部署

**依赖**：
```toml
onnxruntime==1.23.2  # CPU
onnxruntime-gpu==1.23.2  # GPU
```

**实现类**：`BuiltinEmbed`

#### 5.2 Ollama Embeddings

```yaml
OLLAMA_HOST=http://localhost:11434

embedding:
  factory: Ollama
  model_name: nomic-embed-text
```

**支持的模型**：
- `nomic-embed-text` - 768维
- `mxbai-embed-large` - 1024维
- `all-minilm` - 384维

**依赖**：`ollama>=0.5.0`
**实现类**：`OllamaEmbed`

#### 5.3 LocalAI

```yaml
LOCAL_AI_BASE_URL=http://localhost:8080

embedding:
  factory: LocalAI
  model_name: bert-base-uncased
```

**实现类**：`LocalAIEmbed`

#### 5.4 Xinference

分布式推理框架：

```yaml
XINFERENCE_BASE_URL=http://localhost:9997

embedding:
  factory: Xinference
  model_name: bge-large-zh-v1.5
```

**实现类**：`XinferenceEmbed`

### 6. 国内嵌入模型

#### 6.1 通义千问

```yaml
DASHSCOPE_API_KEY=sk-xxxxxxxxxxxxx

embedding:
  factory: Tongyi-Qianwen
  model_name: text-embedding-v3
```

**实现类**：`QWenEmbed`

#### 6.2 智谱 AI

```yaml
ZHIPUAI_API_KEY=xxxxxxxxxxxxx

embedding:
  factory: ZHIPU-AI
  model_name: embedding-3
```

**实现类**：`ZhipuEmbed`

#### 6.3 百度文心

```yaml
BAIDU_API_KEY=xxxxxxxxxxxxx
BAIDU_SECRET_KEY=xxxxxxxxxxxxx

embedding:
  factory: ERNIE-Bot
  model_name: ernie-text-embedding
```

**实现类**：`BaiduYiyanEmbed`

#### 6.4 火山引擎

```yaml
VOLC_ACCESS_KEY=xxxxxxxxxxxxx
VOLC_SECRET_KEY=xxxxxxxxxxxxx

embedding:
  factory: Volcano
  model_name: doubao-embedding
```

**实现类**：`VolcEngineEmbed`

### 7. 其他提供商

#### Azure OpenAI

```yaml
AZURE_OPENAI_KEY=xxxxxxxxxxxxx
AZURE_OPENAI_ENDPOINT=https://xxx.openai.azure.com/

embedding:
  factory: Azure-OpenAI
  model_name: text-embedding-ada-002
```

**依赖**：`azure-identity==1.17.1`
**实现类**：`AzureEmbed`

#### Google Gemini

```yaml
GOOGLE_API_KEY=xxxxxxxxxxxxx

embedding:
  factory: Google
  model_name: text-embedding-004
```

**实现类**：`GeminiEmbed`

#### HuggingFace

```yaml
HUGGINGFACE_API_KEY=hf_xxxxxxxxxxxxx

embedding:
  factory: HuggingFace
  model_name: sentence-transformers/all-MiniLM-L6-v2
```

**实现类**：`HuggingFaceEmbed`

## 重排序服务

### 1. Cohere Rerank

行业领先的重排序模型：

```yaml
COHERE_API_KEY=xxxxxxxxxxxxx

rerank:
  factory: Cohere
  model_name: rerank-english-v3.0
```

#### 支持的模型

- `rerank-english-v3.0` - 英文优化
- `rerank-multilingual-v3.0` - 多语言支持

#### 使用示例

```python
from rag.llm.rerank_model import CoHereRerank

reranker = CoHereRerank(
    key=os.getenv("COHERE_API_KEY"),
    model_name="rerank-english-v3.0"
)

query = "什么是 RAG？"
documents = [
    "RAG 是检索增强生成的缩写",
    "Python 是一种编程语言",
    "RAG 结合了检索和生成能力"
]

scores = reranker.similarity(query, documents)
# 返回每个文档的相关性分数
```

**实现类**：`CoHereRerank` ([rag/llm/rerank_model.py](../../rag/llm/rerank_model.py))

### 2. Jina Rerank

```yaml
JINA_API_KEY=jina_xxxxxxxxxxxxx

rerank:
  factory: Jina
  model_name: jina-reranker-v2-base-multilingual
```

**实现类**：`JinaRerank`

### 3. Voyage Rerank

```yaml
VOYAGE_API_KEY=pa-xxxxxxxxxxxxx

rerank:
  factory: Voyage
  model_name: rerank-2
```

**实现类**：`VoyageRerank`

### 4. 本地重排序

#### 4.1 LocalAI Rerank

```yaml
LOCAL_AI_BASE_URL=http://localhost:8080

rerank:
  factory: LocalAI
  model_name: bge-reranker-large
```

**实现类**：`LocalAIRerank`

#### 4.2 Xinference Rerank

```yaml
XINFERENCE_BASE_URL=http://localhost:9997

rerank:
  factory: Xinference
  model_name: bge-reranker-v2-m3
```

**实现类**：`XInferenceRerank`

### 5. 国内重排序服务

#### 通义千问

```yaml
DASHSCOPE_API_KEY=sk-xxxxxxxxxxxxx

rerank:
  factory: Tongyi-Qianwen
  model_name: gte-rerank
```

**实现类**：`QWenRerank`

#### 百度文心

```yaml
BAIDU_API_KEY=xxxxxxxxxxxxx

rerank:
  factory: ERNIE-Bot
  model_name: bce-reranker-base_v1
```

**实现类**：`BaiduYiyanRerank`

## 高级特性

### 1. 批量处理

```python
# 批量编码大量文本
texts = ["文档1", "文档2", ..., "文档10000"]
embeddings = embed_model.encode(texts, batch_size=128)
```

### 2. 查询优化

部分模型支持查询专用编码：

```python
# 文档编码
doc_embeddings = embed_model.encode(documents)

# 查询编码（可能使用不同策略）
query_embeddings = embed_model.encode_queries(queries)
```

### 3. 多语言支持

```python
# 多语言嵌入
texts = ["Hello world", "你好世界", "Bonjour le monde"]
embeddings = multilingual_embed.encode(texts)
```

### 4. 维度归约

部分模型支持输出维度调整：

```python
# OpenAI 支持维度截断
embeddings = openai_embed.encode(texts, dimensions=1024)
```

## 性能优化

### 1. 批处理策略

```python
def batch_encode(texts, batch_size=32):
    embeddings = []
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]
        batch_embeddings = embed_model.encode(batch)
        embeddings.append(batch_embeddings)
    return np.vstack(embeddings)
```

### 2. 缓存机制

```python
import hashlib
from functools import lru_cache

@lru_cache(maxsize=10000)
def cached_encode(text):
    return embed_model.encode([text])[0]
```

### 3. 异步处理

```python
import asyncio

async def async_encode_batch(texts):
    tasks = [embed_model.encode_async([text]) for text in texts]
    return await asyncio.gather(*tasks)
```

## 使用示例

### 基础嵌入

```python
from rag.llm.embedding_model import OpenAIEmbed

# 初始化嵌入模型
embed_model = OpenAIEmbed(
    key=os.getenv("OPENAI_API_KEY"),
    model_name="text-embedding-3-large"
)

# 编码文本
texts = ["RAG 是什么？", "如何使用 RAGFlow？"]
embeddings = embed_model.encode(texts)

# embeddings shape: (2, 3072)
print(f"Embeddings shape: {embeddings.shape}")
```

### 语义相似度计算

```python
from sklearn.metrics.pairwise import cosine_similarity

# 编码查询和文档
query_embedding = embed_model.encode(["什么是 RAG？"])
doc_embeddings = embed_model.encode([
    "RAG 是检索增强生成",
    "Python 是编程语言",
    "机器学习很有趣"
])

# 计算余弦相似度
similarities = cosine_similarity(query_embedding, doc_embeddings)[0]

# 排序
ranked_docs = sorted(
    zip(range(len(similarities)), similarities),
    key=lambda x: x[1],
    reverse=True
)

for idx, score in ranked_docs:
    print(f"文档 {idx}: {score:.4f}")
```

### 结合重排序

```python
from rag.llm.rerank_model import CoHereRerank

# 第一阶段：向量检索
query = "什么是 RAG？"
candidates = vector_search(query, top_k=100)

# 第二阶段：重排序
reranker = CoHereRerank(
    key=os.getenv("COHERE_API_KEY"),
    model_name="rerank-multilingual-v3.0"
)

rerank_scores = reranker.similarity(query, candidates)

# 获取最终排序
final_results = sorted(
    zip(candidates, rerank_scores),
    key=lambda x: x[1],
    reverse=True
)[:10]
```

## 成本优化

### 1. 模型选择

| 场景 | 推荐模型 | 原因 |
|------|---------|------|
| 原型开发 | BuiltinEmbed | 免费，本地运行 |
| 英文应用 | text-embedding-3-small | 性价比高 |
| 多语言应用 | embed-multilingual-v3.0 | 多语言效果好 |
| 高精度需求 | text-embedding-3-large | 最佳性能 |
| 生产环境 | 自托管 Ollama | 长期成本低 |

### 2. 缓存策略

```python
# 使用 Redis 缓存嵌入结果
import redis
import pickle

redis_client = redis.Redis()

def get_cached_embedding(text):
    key = f"embed:{hashlib.md5(text.encode()).hexdigest()}"
    cached = redis_client.get(key)
    if cached:
        return pickle.loads(cached)
    
    embedding = embed_model.encode([text])[0]
    redis_client.setex(key, 3600, pickle.dumps(embedding))
    return embedding
```

### 3. 批处理

```python
# 批量处理降低 API 调用次数
# 单次 100 个文本 vs 100 次单个调用
embeddings = embed_model.encode(texts, batch_size=100)
```

## 评估指标

### 1. 检索评估

```python
from ranx import Qrels, Run, evaluate

# 评估检索效果
qrels = Qrels.from_dict({
    "q1": {"d1": 1, "d2": 0, "d3": 1}
})

run = Run.from_dict({
    "q1": {"d1": 0.9, "d2": 0.7, "d3": 0.8}
})

metrics = evaluate(qrels, run, ["ndcg@10", "mrr", "precision@10"])
print(metrics)
```

### 2. 嵌入质量

```python
# 评估嵌入质量
from sklearn.metrics import silhouette_score

labels = [0, 0, 1, 1, 2, 2]  # 文档类别
embeddings = embed_model.encode(documents)

score = silhouette_score(embeddings, labels)
print(f"Silhouette Score: {score}")
```

## 故障排查

### 问题 1：嵌入维度不匹配

```python
# 确保嵌入维度一致
expected_dim = 1536
actual_dim = embeddings.shape[1]

if actual_dim != expected_dim:
    logger.error(f"Dimension mismatch: {actual_dim} != {expected_dim}")
```

### 问题 2：批处理内存溢出

```python
# 动态调整批大小
import psutil

def adaptive_batch_size(texts, max_memory_gb=8):
    available_memory = psutil.virtual_memory().available / (1024**3)
    if available_memory < max_memory_gb:
        return 16  # 小批量
    return 128  # 大批量
```

### 问题 3：API 限流

```python
from ratelimit import limits, sleep_and_retry

@sleep_and_retry
@limits(calls=100, period=60)
def rate_limited_encode(texts):
    return embed_model.encode(texts)
```

## 测试

```bash
# 运行嵌入模型测试
uv run pytest test/test_embedding.py -v

# 测试特定提供商
uv run pytest test/test_embedding.py::test_openai_embed
```

## 参考文档

- [OpenAI Embeddings 文档](https://platform.openai.com/docs/guides/embeddings)
- [Cohere Embed 文档](https://docs.cohere.com/docs/embeddings)
- [Voyage AI 文档](https://docs.voyageai.com/)
- [Jina AI 文档](https://jina.ai/embeddings/)
- [sentence-transformers 文档](https://www.sbert.net/)

## 许可证

遵循项目主许可证 [Apache 2.0](../../LICENSE)
