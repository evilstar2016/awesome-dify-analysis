@startuml PDF文档导入详细时序图

!theme plain
skinparam backgroundColor #FFFFFF
skinparam sequenceArrowColor #1976D2
skinparam sequenceActorBorderColor #6C757D
skinparam sequenceParticipantBorderColor #6C757D
skinparam sequenceLifeLineBorderColor #E3F2FD
skinparam noteBackgroundColor #FFF3E0
skinparam noteBorderColor #F57C00

title **Dify PDF文档导入详细时序图**

actor "用户" as User
participant "文件上传API" as FileAPI
participant "数据集服务" as DatasetService
participant "上传文件存储" as UploadFile
participant "索引运行器" as IndexingRunner
participant "索引处理器工厂" as IndexProcessorFactory
participant "段落索引处理器" as ParagraphIndexProcessor
participant "提取处理器" as ExtractProcessor
participant "PDF提取器" as PdfExtractor
participant "pypdfium2" as PyPdfium2
participant "Unstructured API" as UnstructuredAPI
participant "缓存系统" as Cache
participant "向量数据库" as VectorDB
database "PostgreSQL" as Database

== 1. 文件上传阶段 ==
User -> FileAPI: POST /files (上传PDF文件)
activate FileAPI
FileAPI -> FileAPI: 验证文件类型和大小
FileAPI -> UploadFile: 保存文件到存储系统
activate UploadFile
UploadFile -> Database: 创建UploadFile记录
UploadFile --> FileAPI: 返回文件ID
deactivate UploadFile
FileAPI --> User: 返回上传成功和文件ID
deactivate FileAPI

== 2. 创建数据集文档 ==
User -> DatasetService: POST /datasets/{id}/documents
activate DatasetService
DatasetService -> Database: 创建DatasetDocument记录
note right: 状态设为QUEUED
DatasetService -> IndexingRunner: 触发异步索引任务
note right: 通过Celery队列
DatasetService --> User: 返回文档创建成功
deactivate DatasetService

== 3. 异步文档处理 ==
activate IndexingRunner
IndexingRunner -> Database: 重新查询DatasetDocument
IndexingRunner -> Database: 获取Dataset信息
IndexingRunner -> Database: 获取DatasetProcessRule配置

IndexingRunner -> IndexProcessorFactory: 创建索引处理器
activate IndexProcessorFactory
IndexProcessorFactory -> ParagraphIndexProcessor: 实例化段落索引处理器
activate ParagraphIndexProcessor
IndexProcessorFactory --> IndexingRunner: 返回处理器实例
deactivate IndexProcessorFactory

== 4. 文本提取阶段 ==
IndexingRunner -> ParagraphIndexProcessor: extract(extract_setting, process_rule)
ParagraphIndexProcessor -> ExtractProcessor: 创建提取处理器实例
activate ExtractProcessor

alt ETL_TYPE == "Unstructured"
    ExtractProcessor -> UnstructuredAPI: 发送PDF文件
    activate UnstructuredAPI
    note right: 支持复杂布局、表格、图片解析
    UnstructuredAPI --> ExtractProcessor: 返回结构化文本
    deactivate UnstructuredAPI
else 默认本地处理
    ExtractProcessor -> PdfExtractor: extract_from_file(file_path)
    activate PdfExtractor
    
    PdfExtractor -> Cache: 检查缓存(file_path + modified_time)
    activate Cache
    
    alt 缓存存在
        Cache --> PdfExtractor: 返回缓存的文本
    else 缓存不存在
        PdfExtractor -> PyPdfium2: 解析PDF文件
        activate PyPdfium2
        loop 每一页
            PyPdfium2 -> PyPdfium2: 提取页面文本
        end
        PyPdfium2 --> PdfExtractor: 返回所有页面文本
        deactivate PyPdfium2
        PdfExtractor -> Cache: 存储提取结果到缓存
    end
    deactivate Cache
    
    PdfExtractor --> ExtractProcessor: 返回Document列表
    deactivate PdfExtractor
end

ExtractProcessor --> ParagraphIndexProcessor: 返回提取的Document对象
deactivate ExtractProcessor

ParagraphIndexProcessor --> IndexingRunner: 返回文本文档列表

IndexingRunner -> Database: 更新文档状态为SPLITTING
note right: 设置parsing_completed_at时间戳

== 5. 文本转换和分割 ==
IndexingRunner -> ParagraphIndexProcessor: transform(documents, processing_rule)
ParagraphIndexProcessor -> ParagraphIndexProcessor: 获取文本分割器配置
note right: chunk_size, chunk_overlap, separator

loop 每个文档
    ParagraphIndexProcessor -> ParagraphIndexProcessor: 执行文本分割
    note right: 保持语义完整性
end

ParagraphIndexProcessor --> IndexingRunner: 返回分割后的文档段落

== 6. 段落存储 ==
IndexingRunner -> Database: 批量创建DocumentSegment记录
note right: 保存content, position, word_count等

== 7. 向量化和索引 ==
IndexingRunner -> ParagraphIndexProcessor: load(documents, dataset)

alt 启用关键词索引
    ParagraphIndexProcessor -> ParagraphIndexProcessor: 处理关键词索引
end

loop 每个文档段落
    ParagraphIndexProcessor -> ParagraphIndexProcessor: 生成embedding向量
    note right: 调用配置的embedding模型
    ParagraphIndexProcessor -> VectorDB: 存储向量到向量数据库
    activate VectorDB
    VectorDB -> VectorDB: 构建检索索引
    VectorDB --> ParagraphIndexProcessor: 确认存储成功
    deactivate VectorDB
end

ParagraphIndexProcessor --> IndexingRunner: 索引构建完成

== 8. 完成处理 ==
IndexingRunner -> Database: 更新文档状态为COMPLETED
note right: 设置completed_at时间戳

IndexingRunner -> IndexingRunner: 发送处理完成通知
deactivate ParagraphIndexProcessor
deactivate IndexingRunner

== 9. 查询检索阶段 ==
User -> DatasetService: 查询文档内容
activate DatasetService
DatasetService -> ParagraphIndexProcessor: retrieve(query)
activate ParagraphIndexProcessor
ParagraphIndexProcessor -> VectorDB: 向量相似度搜索
activate VectorDB
VectorDB --> ParagraphIndexProcessor: 返回相关段落
deactivate VectorDB
ParagraphIndexProcessor -> Database: 获取段落详细信息
ParagraphIndexProcessor --> DatasetService: 返回搜索结果
deactivate ParagraphIndexProcessor
DatasetService --> User: 返回查询结果
deactivate DatasetService

== 异常处理 ==
note over IndexingRunner, Database
**异常处理机制**:
- DocumentIsPausedError: 文档暂停处理
- ProviderTokenNotInitError: 模型配置错误  
- ObjectDeletedError: 文档已删除
- 其他异常: 更新状态为ERROR，记录错误信息
end note

== 第三方集成说明 ==
note over ExtractProcessor, UnstructuredAPI
**支持的第三方服务**:
- Unstructured API: 高级PDF解析
- Firecrawl: 网页内容提取
- Jina Reader: 多模态处理
- 自定义ETL接口扩展

**配置参数**:
- ETL_TYPE: 选择处理引擎
- UNSTRUCTURED_API_URL/KEY: API配置
end note

@enduml