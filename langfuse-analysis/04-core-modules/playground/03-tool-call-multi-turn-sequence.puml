@startuml Tool Call Multi-Turn Conversation

title Playground å·¥å…·è°ƒç”¨å¤šè½®å¯¹è¯æµç¨‹

actor "ç”¨æˆ·\n(User)" as User
participant "Playground\nUI" as UI
participant "Messages\nEditor" as Editor
participant "Playground\nContext" as Context
participant "API\nHandler" as API
participant "OpenAI\nAPI" as OpenAI

== é…ç½®å·¥å…· ==

User -> UI: æ‰“å¼€ "Tools" é¢æ¿
activate UI

UI -> UI: æ˜¾ç¤ºå·¥å…·é…ç½®ç•Œé¢

User -> UI: ç‚¹å‡» "Add Tool"
deactivate UI

UI -> Context: addTool()
activate Context

Context -> Context: åˆ›å»ºæ–°å·¥å…·\nnewTool = {\n  id: uuid(),\n  name: "",\n  description: "",\n  parameters: {\n    type: "object",\n    properties: {},\n    required: []\n  }\n}

Context -> Context: setTools([...tools, newTool])
deactivate Context

UI <-- Context: å·¥å…·åˆ—è¡¨æ›´æ–°

User <-- UI: æ˜¾ç¤ºç©ºç™½å·¥å…·è¡¨å•

User -> UI: å¡«å†™å·¥å…·å®šä¹‰ï¼š\n- Name: "get_weather"\n- Description: "Get weather for a location"\n- Parameters: {\n    location: string (required),\n    unit: "celsius" | "fahrenheit"\n  }
activate UI

UI -> Context: updateTool(toolId, updates)
activate Context

Context -> Context: setTools(\n  tools.map(t => \n    t.id === toolId \n      ? { ...t, ...updates } \n      : t\n  )\n)

note right of Context
  å·¥å…·å®šä¹‰ï¼š
  {
    id: "tool-123",
    name: "get_weather",
    description: "Get weather for a location",
    parameters: {
      type: "object",
      properties: {
        location: {
          type: "string",
          description: "City name"
        },
        unit: {
          type: "string",
          enum: ["celsius", "fahrenheit"],
          default: "celsius"
        }
      },
      required: ["location"]
    }
  }
end note

Context -> Context: ä¿å­˜åˆ° cache\nlocalStorage.setItem(cacheKey, cache)
deactivate Context

UI <-- Context: å·¥å…·é…ç½®å®Œæˆ
deactivate UI

User <-- UI: æ˜¾ç¤ºå·¥å…·é…ç½®

== ç¬¬ä¸€è½®ï¼šç”¨æˆ·è¯¢é—® ==

User -> Editor: è¾“å…¥æ¶ˆæ¯ï¼š\n"What's the weather in San Francisco?"
activate Editor

Editor -> Context: updateMessage(messageId, {\n  content: "What's the weather..."\n})
activate Context

Context -> Context: setMessages(updatedMessages)

Context -> Context: ä¿å­˜åˆ° cache
deactivate Context
deactivate Editor

User -> UI: ç‚¹å‡» "Run" æŒ‰é’®
activate UI

UI -> Context: handleSubmit(streaming=true)
activate Context

Context -> Context: setIsStreaming(true)

Context -> Context: ç¼–è¯‘æ¶ˆæ¯

Context -> API: POST /api/chatCompletion
activate API

note right of API
  Request Body:
  {
    messages: [
      {
        type: "system",
        role: "system",
        content: "You are a helpful assistant."
      },
      {
        type: "user",
        role: "user",
        content: "What's the weather in San Francisco?"
      }
    ],
    modelParams: {
      provider: "openai",
      model: "gpt-4-turbo"
    },
    tools: [
      {
        name: "get_weather",
        description: "Get weather for a location",
        parameters: {...}
      }
    ],
    streaming: false
  }
end note

API -> API: éªŒè¯å’Œæˆæƒ

API -> OpenAI: POST /v1/chat/completions
activate OpenAI

note right of OpenAI
  OpenAI Request:
  {
    model: "gpt-4-turbo",
    messages: [...],
    tools: [
      {
        type: "function",
        function: {
          name: "get_weather",
          description: "Get weather...",
          parameters: {...}
        }
      }
    ],
    tool_choice: "auto"
  }
end note

OpenAI -> OpenAI: LLM å†³å®šè°ƒç”¨å·¥å…·

OpenAI --> API: Response with tool_calls
deactivate OpenAI

note right of API
  Response:
  {
    choices: [{
      message: {
        role: "assistant",
        tool_calls: [{
          id: "call_abc123",
          type: "function",
          function: {
            name: "get_weather",
            arguments: '{"location":"San Francisco","unit":"fahrenheit"}'
          }
        }]
      }
    }]
  }
end note

API --> Context: è¿”å› tool calls
deactivate API

Context -> Context: è§£æ tool calls\nconst toolCalls = response.toolCalls

Context -> Context: æ·»åŠ  assistant-tool-call æ¶ˆæ¯\nconst assistantMsg = {\n  id: uuid(),\n  type: "assistant-tool-call",\n  role: "assistant",\n  toolCalls: [\n    {\n      id: "call_abc123",\n      name: "get_weather",\n      arguments: '{"location":"San Francisco","unit":"fahrenheit"}'\n    }\n  ]\n}

Context -> Context: setMessages([...messages, assistantMsg])

Context -> Context: ä¸ºæ¯ä¸ª tool call æ·»åŠ \nç©ºçš„ tool-result æ¶ˆæ¯

loop æ¯ä¸ª tool call

  Context -> Context: const toolResultMsg = {\n  id: uuid(),\n  type: "tool-result",\n  role: "tool",\n  toolCallId: "call_abc123",\n  result: "", // ç”¨æˆ·å¡«å†™\n  _originalRole: "get_weather" // ç”¨äºä¿®å¤\n}

  Context -> Context: setMessages([...messages, toolResultMsg])

end

Context -> Context: setOutputToolCalls(toolCalls)

Context -> Context: setIsStreaming(false)

Context -> Context: ä¿å­˜åˆ° cache
deactivate Context

UI <-- Context: æ‰§è¡Œå®Œæˆ

deactivate UI

User <-- UI: æ˜¾ç¤º tool call æ¶ˆæ¯

note right of UI
  UI æ˜¾ç¤ºï¼š
  
  [Assistant Tool Call]
  ğŸ“ get_weather
  Arguments:
  {
    "location": "San Francisco",
    "unit": "fahrenheit"
  }
  
  [Tool Result] âš ï¸ å¾…å¡«å†™
  tool_call_id: call_abc123
  Result: [ç©ºç™½è¾“å…¥æ¡†]
end note

== ç¬¬äºŒè½®ï¼šå¡«å†™å·¥å…·ç»“æœ ==

User -> Editor: åœ¨ tool result æ¶ˆæ¯æ¡†ä¸­å¡«å†™ï¼š\n"72Â°F, Sunny, Light breeze"
activate Editor

Editor -> Context: updateMessage(toolResultMessageId, {\n  result: "72Â°F, Sunny, Light breeze"\n})
activate Context

Context -> Context: setMessages(updatedMessages)

Context -> Context: ä¿å­˜åˆ° cache
deactivate Context
deactivate Editor

note right of Context
  å½“å‰æ¶ˆæ¯åˆ—è¡¨ï¼š
  1. [system] "You are..."
  2. [user] "What's the weather..."
  3. [assistant-tool-call] toolCalls: [...]
  4. [tool-result] result: "72Â°F, Sunny..."
end note

User -> UI: å†æ¬¡ç‚¹å‡» "Run" æŒ‰é’®\nï¼ˆç»§ç»­å¯¹è¯ï¼‰
activate UI

UI -> Context: handleSubmit(streaming=true)
activate Context

Context -> Context: ç¼–è¯‘æ¶ˆæ¯\nï¼ˆåŒ…å« tool resultï¼‰

Context -> Context: ä¿®å¤ tool_call_id\nï¼ˆå¦‚æœä¸ºç©ºï¼‰

note right of Context
  ID ä¿®å¤é€»è¾‘ï¼ˆchatCompletionHandlerï¼‰ï¼š
  
  for each tool-result message:
    if toolCallId is empty:
      1. åå‘éå† assistant-tool-call æ¶ˆæ¯
      2. æŸ¥æ‰¾ toolCall.name === msg._originalRole
      3. å¤åˆ¶åŒ¹é…çš„ toolCall.id
      4. å¡«å…… toolCallId
  
  è¿™è§£å†³äº† LangGraph ç­‰æ¡†æ¶
  ä¸æä¾› tool_call_id çš„é—®é¢˜
  
  ä»£ç ç‰‡æ®µï¼š
  const matchingToolCall = prevMsg.toolCalls.find(
    tc => tc.name === msg._originalRole
  )
end note

Context -> API: POST /api/chatCompletion
activate API

note right of API
  Request Body:
  {
    messages: [
      {type: "system", role: "system", content: "..."},
      {type: "user", role: "user", content: "What's..."},
      {
        type: "assistant-tool-call",
        role: "assistant",
        tool_calls: [{
          id: "call_abc123",
          name: "get_weather",
          arguments: '{"location":"San Francisco",...}'
        }]
      },
      {
        type: "tool-result",
        role: "tool",
        tool_call_id: "call_abc123",
        result: "72Â°F, Sunny, Light breeze"
      }
    ],
    tools: [...],
    streaming: true
  }
end note

API -> API: è½¬æ¢ä¸º OpenAI æ ¼å¼

note right of API
  OpenAI æ¶ˆæ¯æ ¼å¼ï¼š
  [
    {role: "system", content: "..."},
    {role: "user", content: "What's..."},
    {
      role: "assistant",
      tool_calls: [{
        id: "call_abc123",
        type: "function",
        function: {
          name: "get_weather",
          arguments: '{"location":"San Francisco",...}'
        }
      }]
    },
    {
      role: "tool",
      tool_call_id: "call_abc123",
      content: "72Â°F, Sunny, Light breeze"
    }
  ]
end note

API -> OpenAI: POST /v1/chat/completions\n(stream=true)
activate OpenAI

OpenAI -> OpenAI: LLM å¤„ç† tool result\nç”Ÿæˆè‡ªç„¶è¯­è¨€å“åº”

OpenAI --> API: æµå¼å“åº”å¼€å§‹
deactivate OpenAI

API --> Context: StreamingTextResponse
deactivate API

loop æ¥æ”¶æµå¼æ•°æ®

  Context -> Context: æ¥æ”¶ chunk
  Context -> Context: ç´¯ç§¯è¾“å‡º
  
  Context -> UI: æ›´æ–° output çŠ¶æ€
  activate UI
  
  UI -> User: å®æ—¶æ˜¾ç¤ºè¾“å‡º
  deactivate UI

end

Context -> Context: æµå¼å“åº”å®Œæˆ

note right of Context
  æœ€ç»ˆè¾“å‡ºï¼š
  "The current weather in San Francisco 
  is 72Â°F and sunny with a light breeze. 
  It's a beautiful day!"
end note

Context -> Context: setIsStreaming(false)

Context -> Context: ä¿å­˜åˆ° cache
deactivate Context

UI <-- Context: æ‰§è¡Œå®Œæˆ

deactivate UI

User <-- UI: æ˜¾ç¤ºæœ€ç»ˆå“åº”

note right of UI
  æ¶ˆæ¯å†å²ï¼š
  
  [System]
  You are a helpful assistant.
  
  [User]
  What's the weather in San Francisco?
  
  [Assistant Tool Call]
  ğŸ“ get_weather(location="San Francisco", unit="fahrenheit")
  
  [Tool Result]
  tool_call_id: call_abc123
  Result: 72Â°F, Sunny, Light breeze
  
  [Assistant]
  The current weather in San Francisco is 72Â°F 
  and sunny with a light breeze. It's a beautiful day!
end note

== ç¬¬ä¸‰è½®ï¼šç»§ç»­å¯¹è¯ï¼ˆå¯é€‰ï¼‰==

User -> Editor: æ·»åŠ æ–°çš„ user æ¶ˆæ¯ï¼š\n"Should I bring an umbrella?"
activate Editor

Editor -> Context: addMessage({\n  type: "user",\n  role: "user",\n  content: "Should I bring an umbrella?"\n})
activate Context
deactivate Context
deactivate Editor

User -> UI: ç‚¹å‡» "Run"
activate UI

UI -> Context: handleSubmit(streaming=true)
activate Context

note right of Context
  æ¶ˆæ¯åˆ—è¡¨åŒ…å«å®Œæ•´å†å²ï¼š
  - system message
  - user query 1
  - assistant tool call
  - tool result
  - assistant response
  - user query 2 (æ–°)
end note

Context -> API: POST /api/chatCompletion\nï¼ˆåŒ…å«å®Œæ•´å†å²ï¼‰
activate API

API -> OpenAI: POST /v1/chat/completions
activate OpenAI

OpenAI -> OpenAI: åŸºäºå†å²ä¸Šä¸‹æ–‡\nï¼ˆåŒ…æ‹¬ä¹‹å‰çš„å¤©æ°”ä¿¡æ¯ï¼‰\nç”Ÿæˆå“åº”

OpenAI --> API: æµå¼å“åº”
deactivate OpenAI

API --> Context: StreamingTextResponse
deactivate API

Context -> Context: æ¥æ”¶æµå¼è¾“å‡º

note right of Context
  è¾“å‡ºï¼š
  "No, you don't need an umbrella! 
  The weather is sunny, so you should 
  be fine without one."
end note

Context -> Context: setIsStreaming(false)
deactivate Context

UI <-- Context: å®Œæˆ
deactivate UI

User <-- UI: æ˜¾ç¤ºå“åº”

note right of User
  å¤šè½®å¯¹è¯å®Œæˆï¼
  
  LLM è®°ä½äº†ï¼š
  - å¤©æ°”æ˜¯æ™´å¤©
  - æ¸©åº¦ 72Â°F
  - æœ‰å¾®é£
  
  åŸºäºè¿™äº›ä¿¡æ¯å›ç­”äº†
  æ˜¯å¦éœ€è¦é›¨ä¼çš„é—®é¢˜
end note

@enduml
