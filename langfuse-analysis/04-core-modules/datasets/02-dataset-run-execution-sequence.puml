@startuml
!theme plain
skinparam backgroundColor #FFFFFF
skinparam sequenceArrowColor #1976D2
skinparam sequenceActorBorderColor #426450ff
skinparam sequenceParticipantBorderColor #6C757D
skinparam SequenceParticipantBorderThickness 2
skinparam sequenceLifeLineBorderColor #9bd0f5ff
skinparam noteBackgroundColor #FFF3E0
skinparam noteBorderColor #F57C00
skinparam style strictuml
skinparam Padding 6
skinparam ParticipantPadding 30

title Dataset Run 执行流程（SDK）

actor "应用代码" as App
participant "Langfuse SDK" as SDK
participant "Public API\n(/api/public)" as API
participant "Auth Middleware" as Auth
participant "tRPC Router\n(datasets)" as Router
participant "Dataset Service" as Service
participant "Prisma ORM" as Prisma
database "PostgreSQL" as PG
database "ClickHouse" as CH

== 步骤 1: 创建 Dataset Run ==

App -> SDK: const run = langfuse.createDatasetRun({\n  datasetId: "ds-123",\n  name: "gpt-4-baseline-2024",\n  description: "GPT-4 baseline evaluation",\n  metadata: {\n    model: "gpt-4",\n    temperature: 0.7,\n    promptVersion: "v2"\n  }\n})
activate SDK

SDK -> API: POST /api/public/dataset-runs\n{\n  datasetId,\n  name,\n  description,\n  metadata\n}
activate API

API -> Auth: verifyApiKey(publicKey)
activate Auth
Auth -> PG: 查询 api_keys
activate PG
PG --> Auth: api_key record
deactivate PG
Auth --> API: { projectId, scope }
deactivate Auth

API -> Router: datasets.createRun
activate Router

Router -> Prisma: create({\n  data: {\n    id: uuid(),\n    projectId,\n    datasetId,\n    name,\n    description,\n    metadata\n  }\n})
activate Prisma

Prisma -> PG: INSERT INTO dataset_runs\n(\n  id, project_id, dataset_id,\n  name, description, metadata,\n  created_at, updated_at\n)\nVALUES (...)
activate PG

note right of PG
  唯一性约束:
  UNIQUE (dataset_id, project_id, name)
  同一 dataset 下 run name 不能重复
end note

PG --> Prisma: run record
deactivate PG

Prisma --> Router: created run
deactivate Prisma

Router --> API: run
deactivate Router

API --> SDK: 200 OK\n{\n  id: "run-456",\n  datasetId,\n  name,\n  metadata\n}
deactivate API

SDK --> App: DatasetRun 对象
deactivate SDK

== 步骤 2: 获取 Dataset Items ==

App -> SDK: const items = await langfuse.getDatasetItems(\n  "ds-123"\n)
activate SDK

SDK -> API: GET /api/public/dataset-items\n?datasetId=ds-123
activate API

API -> Auth: verifyApiKey()
activate Auth
Auth --> API: authenticated
deactivate Auth

API -> Router: datasets.baseDatasetItemByDatasetId
activate Router

Router -> Prisma: findMany({\n  where: {\n    datasetId: "ds-123",\n    validTo: null,        // 当前版本\n    isDeleted: false\n  },\n  orderBy: { createdAt: "desc" }\n})
activate Prisma

Prisma -> PG: SELECT * FROM dataset_items\nWHERE dataset_id = ?\n  AND valid_to IS NULL\n  AND is_deleted = false\nORDER BY created_at DESC
activate PG

note right of PG
  Temporal Table 查询:
  - valid_to IS NULL: 当前版本
  - is_deleted = false: 未删除
end note

PG --> Prisma: items (50 items)
deactivate PG

Prisma --> Router: dataset items
deactivate Prisma

Router --> API: items
deactivate Router

API --> SDK: 200 OK\n[\n  {\n    id: "item-001",\n    input: { userName: "Alice" },\n    expectedOutput: { greeting: "Hello Alice!" },\n    metadata: { difficulty: "easy" }\n  },\n  ...\n]
deactivate API

SDK --> App: DatasetItem[]
deactivate SDK

== 步骤 3: 对每个 Item 执行推理 ==

loop for each item in items

  App -> App: 执行模型推理

  App -> SDK: const trace = langfuse.trace({\n  name: "dataset-run-item",\n  input: item.input,\n  metadata: {\n    datasetItemId: item.id,\n    datasetRunId: run.id\n  }\n})
  activate SDK
  
  note right of App
    Trace metadata 记录关联:
    - datasetItemId: 关联到 dataset item
    - datasetRunId: 关联到 dataset run
  end note
  
  SDK -> SDK: 创建 local trace 对象
  
  App -> App: const response = await callLLM({\n  model: "gpt-4",\n  temperature: 0.7,\n  prompt: item.input\n})
  
  note right of App
    调用 LLM:
    - 可以是 OpenAI, Anthropic 等
    - 使用 run metadata 中的配置
  end note
  
  App -> SDK: trace.generation({\n  name: "main-generation",\n  model: "gpt-4",\n  input: item.input,\n  output: response\n})
  
  SDK -> SDK: 添加 generation observation
  
  App -> SDK: trace.update({\n  output: response\n})
  
  SDK -> SDK: 更新 trace output
  
  deactivate SDK

end

note right of App
  此时所有 traces 已创建
  但还未上传到 Langfuse
end note

== 步骤 4: 刷新 SDK（上传 Traces） ==

App -> SDK: await langfuse.flushAsync()
activate SDK

SDK -> API: POST /api/public/ingestion\n{\n  batch: [\n    { type: "trace-create", body: {...} },\n    { type: "observation-create", body: {...} },\n    ...\n  ]\n}
activate API

note right of SDK
  批量上传:
  - 所有 traces 和 observations
  - 一次请求提交
end note

API -> Auth: verifyApiKey()
activate Auth
Auth --> API: authenticated
deactivate Auth

API -> Router: ingestion.batch
activate Router

Router -> PG: BEGIN TRANSACTION
activate PG

Router -> PG: INSERT INTO traces (...)\nVALUES (...)
note right of Router
  插入所有 traces
end note

Router -> PG: INSERT INTO observations (...)\nVALUES (...)
note right of Router
  插入所有 observations
end note

Router -> CH: INSERT INTO traces_rmt (...)\nVALUES (...)
activate CH
note right of Router
  ClickHouse 存储性能指标
end note
CH --> Router: inserted
deactivate CH

Router -> PG: COMMIT TRANSACTION
PG --> Router: committed
deactivate PG

Router --> API: ingestion complete
deactivate Router

API --> SDK: 200 OK
deactivate API

SDK --> App: flush complete
deactivate SDK

== 步骤 5: 关联 Traces 到 Run Items ==

loop for each item in items

  App -> SDK: await langfuse.createDatasetRunItem({\n  runId: run.id,\n  datasetItemId: item.id,\n  traceId: traces[item.id].id\n})
  activate SDK
  
  SDK -> API: POST /api/public/dataset-run-items\n{\n  runId,\n  datasetItemId,\n  traceId\n}
  activate API
  
  API -> Auth: verifyApiKey()
  activate Auth
  Auth --> API: authenticated
  deactivate Auth
  
  API -> Router: datasets.createRunItem
  activate Router
  
  Router -> Prisma: create({\n  data: {\n    id: uuid(),\n    projectId,\n    datasetRunId: run.id,\n    datasetItemId: item.id,\n    traceId: trace.id\n  }\n})
  activate Prisma
  
  Prisma -> PG: INSERT INTO dataset_run_items\n(\n  id, project_id,\n  dataset_run_id,\n  dataset_item_id,\n  trace_id\n)\nVALUES (...)
  activate PG
  PG --> Prisma: run item record
  deactivate PG
  
  Prisma --> Router: created
  deactivate Prisma
  
  note right of Router
    同时也写入 ClickHouse:
    - 提取 trace 的性能指标
    - latency, cost 等
  end note
  
  Router -> CH: INSERT INTO dataset_run_items_rmt\n(...) VALUES (...)
  activate CH
  CH --> Router: inserted
  deactivate CH
  
  Router --> API: run item created
  deactivate Router
  
  API --> SDK: 200 OK
  deactivate API
  
  SDK --> App: success
  deactivate SDK

end

== 步骤 6: 评分（可选） ==

loop for each item in items

  App -> App: const score = evaluateResponse(\n  response,\n  item.expectedOutput\n)
  
  App -> SDK: trace.score({\n  name: "correctness",\n  value: score,\n  comment: "Exact match check"\n})
  activate SDK
  
  SDK -> API: POST /api/public/scores\n{\n  traceId,\n  name,\n  value,\n  comment\n}
  activate API
  
  API -> Router: scores.create
  activate Router
  
  Router -> PG: INSERT INTO scores (...)\nVALUES (...)
  activate PG
  PG --> Router: score record
  deactivate PG
  
  Router --> API: score created
  deactivate Router
  
  API --> SDK: 200 OK
  deactivate API
  
  SDK --> App: success
  deactivate SDK

end

== 完成 ==

App -> App: console.log("Run complete!")

note right of App
  Run 执行完成:
  - 50 个 items 已评估
  - 所有 traces 已上传
  - run items 已关联
  - scores 已记录
  
  可在 UI 中查看结果:
  - 聚合指标（avg latency, cost）
  - 逐项对比
  - Score 分布
end note

@enduml
