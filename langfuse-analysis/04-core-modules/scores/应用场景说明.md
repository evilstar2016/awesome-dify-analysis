# Scores 模块应用场景说明

## 概述

Scores 模块是 Langfuse 中用于**评估和监控 LLM 应用质量**的核心系统，提供多维度、多来源的评分能力，支持从实时自动评估到离线人工审核的完整质量管理流程。

### 核心能力

| 能力 | 说明 |
|-----|------|
| **多来源评分** | ANNOTATION（人工）、API（自动）、EVAL（批量）、FEEDBACK（用户） |
| **多类型支持** | NUMERIC（数值）、CATEGORICAL（分类）、BOOLEAN（布尔） |
| **配置管理** | 统一评分标准，支持范围约束、类别验证 |
| **聚合分析** | 自动分组统计，生成质量报告 |
| **审计追踪** | 完整记录评分历史，支持溯源 |

---

## 应用场景一：智能客服质量监控

### 场景描述

某电商公司的 AI 客服系统每天处理 10,000+ 用户咨询，需要建立多维度质量监控体系：
- **实时监控**：自动检测语气、情感、响应长度
- **用户反馈**：收集"有帮助"/"无帮助"反馈
- **人工审核**：质量团队抽样评审（5% 覆盖率）

### 评分体系设计

| 评分维度 | 数据类型 | 来源 | 频率 |
|---------|---------|------|------|
| response_quality | NUMERIC (1-5) | ANNOTATION | 抽样 5% |
| tone | CATEGORICAL | API | 100% |
| solved | BOOLEAN | FEEDBACK | 用户触发 |
| response_length | NUMERIC (1-5) | API | 100% |

### 工作流程

```plantuml
@startuml
!theme plain
skinparam backgroundColor #FFFFFF
skinparam sequenceArrowColor #1976D2
skinparam sequenceActorBorderColor #426450ff
skinparam sequenceParticipantBorderColor #6C757D
skinparam SequenceParticipantBorderThickness 2
skinparam sequenceLifeLineBorderColor #9bd0f5ff
skinparam noteBackgroundColor #FFF3E0
skinparam noteBorderColor #F57C00
skinparam style strictuml
skinparam Padding 6
skinparam ParticipantPadding 30

title 智能客服质量监控流程

actor "用户" as User
participant "AI 客服" as Chatbot
participant "LLM\n(GPT-4)" as LLM
participant "评分系统\n(Scores)" as Scores
participant "质量团队" as QA
database "Langfuse" as DB

User -> Chatbot: 发起咨询\n"如何退货？"
activate Chatbot

Chatbot -> LLM: 生成回答
activate LLM
LLM --> Chatbot: 返回回答内容
deactivate LLM

Chatbot -> DB: 创建 Trace\n记录对话

== 自动评分（实时） ==

Chatbot -> Scores: API 评分：语气分析
activate Scores
Scores -> Scores: 分析语气\n(professional/friendly/rude)
Scores -> DB: 保存评分\ntone-API-CATEGORICAL
deactivate Scores

Chatbot -> Scores: API 评分：响应长度
activate Scores
Scores -> Scores: 计算字数\n评估简洁性
Scores -> DB: 保存评分\nresponse_length-API-NUMERIC
deactivate Scores

Chatbot --> User: 返回回答

== 用户反馈 ==

User -> Chatbot: 点击"有帮助"按钮
Chatbot -> Scores: FEEDBACK 评分
activate Scores
Scores -> DB: 保存评分\nsolved-FEEDBACK-BOOLEAN
deactivate Scores

== 人工审核（抽样 5%） ==

QA -> DB: 查询待审核对话
DB --> QA: 返回对话列表

QA -> QA: 阅读对话内容\n评估质量

QA -> Scores: ANNOTATION 评分\nresponse_quality: 4/5\n评论："回答准确但缺少退货链接"
activate Scores
Scores -> Scores: 验证配置\n检查范围 1-5
Scores -> DB: 保存评分\nresponse_quality-ANNOTATION-NUMERIC
Scores -> DB: 记录审计日志
deactivate Scores

== 聚合分析 ==

QA -> Scores: 查询今日质量报告
activate Scores
Scores -> DB: 获取所有评分
DB --> Scores: 返回评分数据
Scores -> Scores: aggregateScores()\n按 name-source-dataType 分组
Scores --> QA: 返回聚合结果\n- 平均质量：4.5/5\n- 正面语气：67%\n- 问题解决率：85%
deactivate Scores

@enduml
```

### 聚合分析视图

```plantuml
@startuml
!theme plain

title 评分聚合分析架构

package "原始评分数据" {
  component "response_quality\nANNOTATION\nNUMERIC" as RQ1 #LightBlue
  component "response_quality\nANNOTATION\nNUMERIC" as RQ2 #LightBlue
  component "response_quality\nANNOTATION\nNUMERIC" as RQ3 #LightBlue
  
  component "tone\nAPI\nCATEGORICAL" as T1 #LightGreen
  component "tone\nAPI\nCATEGORICAL" as T2 #LightGreen
  component "tone\nAPI\nCATEGORICAL" as T3 #LightGreen
  
  component "solved\nFEEDBACK\nBOOLEAN" as S1 #LightYellow
  component "solved\nFEEDBACK\nBOOLEAN" as S2 #LightYellow
}

package "聚合引擎" {
  component "aggregateScores()" as Agg #Orange
  note right of Agg
    1. 按 name-source-dataType 分组
    2. NUMERIC → 计算平均值
    3. CATEGORICAL → 统计分布
    4. BOOLEAN → 计数统计
  end note
}

package "聚合结果" {
  card "response_quality-ANNOTATION-NUMERIC" as AGG1 #LightBlue {
    component "平均值: 4.5" as Avg1
    component "值列表: [4.5, 4.0, 5.0]" as Val1
  }
  
  card "tone-API-CATEGORICAL" as AGG2 #LightGreen {
    component "分布统计:" as Dist
    component "professional: 2次" as D1
    component "friendly: 1次" as D2
  }
  
  card "solved-FEEDBACK-BOOLEAN" as AGG3 #LightYellow {
    component "True: 85%" as B1
    component "False: 15%" as B2
  }
}

RQ1 --> Agg
RQ2 --> Agg
RQ3 --> Agg
T1 --> Agg
T2 --> Agg
T3 --> Agg
S1 --> Agg
S2 --> Agg

Agg --> AGG1
Agg --> AGG2
Agg --> AGG3

@enduml
```

### 业务价值

- **质量可视化**：实时仪表盘展示服务质量趋势
- **问题定位**：快速识别低质量对话，针对性改进
- **绩效考核**：量化客服团队和 AI 系统表现
- **用户洞察**：分析用户满意度与问题类型关联

---

## 应用场景二：RAG 系统准确性评估

### 场景描述

法律咨询 RAG 系统需要验证答案的准确性和可靠性：
- **自动检测**：引用准确性、相关性评分
- **专家审核**：律师团队审核关键法律问题
- **用户验证**：收集用户对答案有用性的反馈

### 评分体系设计

| 评分维度 | 数据类型 | 来源 | 验证标准 |
|---------|---------|------|---------|
| citation_accuracy | NUMERIC (0-100) | API | 自动检测引用是否存在 |
| legal_correctness | CATEGORICAL | ANNOTATION | 律师专家评审 |
| helpfulness | NUMERIC (1-5) | FEEDBACK | 用户主观评价 |
| relevance | NUMERIC (0-100) | API | 向量相似度检测 |

### 配置管理流程

```plantuml
@startuml
!theme plain
skinparam backgroundColor #FFFFFF
skinparam sequenceArrowColor #1976D2
skinparam sequenceActorBorderColor #426450ff
skinparam sequenceParticipantBorderColor #6C757D
skinparam SequenceParticipantBorderThickness 2
skinparam sequenceLifeLineBorderColor #9bd0f5ff
skinparam noteBackgroundColor #FFF3E0
skinparam noteBorderColor #F57C00
skinparam style strictuml
skinparam Padding 6
skinparam ParticipantPadding 30

title 评分配置管理流程

actor "系统管理员" as Admin
participant "Config\nManagement" as Config
database "Prisma\n(PostgreSQL)" as DB
participant "验证引擎" as Validator

== 创建配置 ==

Admin -> Config: 创建配置\nlegal_correctness
activate Config

Config -> Config: 构建配置对象\n- 名称：legal_correctness\n- 类型：CATEGORICAL\n- 类别：correct/partially_correct/incorrect

Config -> Validator: 验证配置格式
activate Validator
Validator -> Validator: 检查必填字段\n验证数据类型\n验证类别定义
Validator --> Config: ✅ 验证通过
deactivate Validator

Config -> DB: 保存配置
DB --> Config: 返回配置 ID

Config -> DB: 记录审计日志\naction: create
Config --> Admin: 返回配置详情

deactivate Config

== 创建评分（应用配置） ==

actor "律师" as Lawyer
participant "Annotation\nScoring" as Scoring

Lawyer -> Scoring: 创建标注评分\nlegal_correctness: "correct"
activate Scoring

Scoring -> DB: 查询配置\nid: cfg_legal_review
DB --> Scoring: 返回配置详情

Scoring -> Validator: 验证评分\nvalidateConfigAgainstBody()
activate Validator

Validator -> Validator: 步骤 1：数据类型匹配\nCATEGORICAL == CATEGORICAL ✅

Validator -> Validator: 步骤 2：配置未归档\nisArchived: false ✅

Validator -> Validator: 步骤 3：名称匹配\nlegal_correctness == legal_correctness ✅

Validator -> Validator: 步骤 4：提取评分值\nstringValue: "correct"

Validator -> Validator: 步骤 5：类别验证\n"correct" in categories ✅

Validator --> Scoring: ✅ 验证通过
deactivate Validator

Scoring -> DB: 保存评分到 ClickHouse
Scoring -> DB: 记录审计日志
Scoring --> Lawyer: 评分创建成功

deactivate Scoring

== 配置归档 ==

Admin -> Config: 归档配置\nisArchived: true
activate Config
Config -> DB: 更新配置状态
Config -> DB: 记录审计日志\naction: update
Config --> Admin: 归档成功
deactivate Config

Lawyer -> Scoring: 尝试使用归档配置创建评分
activate Scoring
Scoring -> DB: 查询配置
DB --> Scoring: 返回配置\nisArchived: true

Scoring -> Validator: 验证评分
activate Validator
Validator -> Validator: 步骤 2：检查归档状态\nisArchived: true ❌
Validator --> Scoring: ❌ 抛出异常\n"Config is archived"
deactivate Validator

Scoring --> Lawyer: ⚠️ 错误提示\n"配置已归档，请恢复或使用新配置"
deactivate Scoring

@enduml
```

### 多来源评分集成

```plantuml
@startuml
!theme plain
skinparam backgroundColor #FFFFFF
skinparam sequenceArrowColor #1976D2
skinparam sequenceActorBorderColor #426450ff
skinparam sequenceParticipantBorderColor #6C757D
skinparam SequenceParticipantBorderThickness 2
skinparam sequenceLifeLineBorderColor #9bd0f5ff
skinparam noteBackgroundColor #FFF3E0
skinparam noteBorderColor #F57C00
skinparam style strictuml
skinparam Padding 6
skinparam ParticipantPadding 30

title RAG 系统多来源评分集成

actor "用户" as User
participant "RAG 系统" as RAG
participant "向量数据库" as VectorDB
participant "LLM" as LLM
participant "评分系统" as Scores
actor "律师" as Expert
database "Langfuse" as DB

User -> RAG: 提问\n"劳动合同解除的法律依据？"
activate RAG

== 检索与生成 ==

RAG -> VectorDB: 检索相关法条
VectorDB --> RAG: 返回 Top-5 片段

RAG -> RAG: 计算相关性分数

RAG -> LLM: 生成答案\n（包含法条引用）
LLM --> RAG: 返回答案

RAG -> DB: 创建 Trace\n记录完整过程

== 自动评分（API） ==

RAG -> Scores: API 评分：相关性
note right
  相关性 = 平均向量相似度 × 100
  值：87
end note
activate Scores
Scores -> DB: 保存评分\nrelevance-API-NUMERIC: 87
deactivate Scores

RAG -> Scores: API 评分：引用准确性
note right
  检测所有引用是否在检索结果中
  准确率：100%
end note
activate Scores
Scores -> DB: 保存评分\ncitation_accuracy-API-NUMERIC: 100
deactivate Scores

RAG --> User: 返回答案

== 用户反馈（FEEDBACK） ==

User -> User: 阅读答案

User -> RAG: 评价"有帮助"
RAG -> Scores: FEEDBACK 评分
activate Scores
Scores -> DB: 保存评分\nhelpfulness-FEEDBACK-NUMERIC: 5
deactivate Scores

== 专家审核（ANNOTATION） ==

note over Expert
  高风险法律问题
  触发人工审核
end note

Expert -> DB: 查询待审核问题
DB --> Expert: 返回问题列表

Expert -> Expert: 阅读答案与引用\n验证法律准确性

Expert -> Scores: ANNOTATION 评分
note right
  legal_correctness: "correct"
  评论："引用《劳动合同法》第 39 条，准确"
  configId: cfg_legal_review
end note

activate Scores

Scores -> Scores: 验证配置\n- 检查类别有效性\n- 确认配置未归档

Scores -> DB: 保存评分\nlegal_correctness-ANNOTATION-CATEGORICAL

Scores -> DB: 记录审计日志\nauthor: expert_lawyer_id

Scores --> Expert: 评分完成
deactivate Scores

== 质量报告生成 ==

RAG -> Scores: 生成每日质量报告
activate Scores

Scores -> DB: 查询所有评分
DB --> Scores: 返回评分数据

Scores -> Scores: aggregateScores()\n聚合统计

Scores --> RAG: 返回报告
note right
  - 平均相关性：87 分
  - 引用准确率：95%
  - 用户满意度：4.5/5
  - 法律准确性：90% correct
end note

deactivate Scores

@enduml
```

### 业务价值

- **准确性保障**：专家审核确保法律答案可靠性
- **持续优化**：通过评分数据识别改进点
- **风险控制**：高风险问题强制人工审核
- **信任建立**：展示引用来源和准确率

---

## 应用场景三：多模型 A/B 测试

### 场景描述

技术团队需要比较 GPT-4 和 Claude-3.5 在代码生成任务中的表现：
- **自动化测试**：语法检查、单元测试通过率
- **开发者评审**：代码质量、可读性评分
- **性能对比**：生成速度、token 消耗

### 测试架构

```plantuml
@startuml
!theme plain

title A/B 测试架构

package "测试执行" {
  component "测试任务队列\n(100 个编程任务)" as Queue #LightBlue
}

package "模型 A 组" {
  component "GPT-4" as ModelA #LightGreen
  component "Trace A\n(50 次调用)" as TraceA
}

package "模型 B 组" {
  component "Claude-3.5" as ModelB #LightCoral
  component "Trace B\n(50 次调用)" as TraceB
}

package "自动评分" {
  component "语法检查器" as Syntax #Orange
  component "单元测试执行器" as Test #Orange
  component "性能分析器" as Perf #Orange
}

package "人工评分" {
  actor "开发者团队" as Dev
}

package "评分存储" {
  database "Scores 数据库" as ScoresDB
  card "模型 A 评分" as ScoresA
  card "模型 B 评分" as ScoresB
}

package "聚合分析" {
  component "aggregateScores()" as Agg #Gold
  component "统计对比" as Stats
}

Queue --> ModelA: 50%
Queue --> ModelB: 50%

ModelA --> TraceA
ModelB --> TraceB

TraceA --> Syntax
TraceA --> Test
TraceA --> Perf
TraceA --> Dev

TraceB --> Syntax
TraceB --> Test
TraceB --> Perf
TraceB --> Dev

Syntax --> ScoresDB: API 评分
Test --> ScoresDB: API 评分
Perf --> ScoresDB: API 评分
Dev --> ScoresDB: ANNOTATION 评分

ScoresDB --> ScoresA: 按模型过滤
ScoresDB --> ScoresB: 按模型过滤

ScoresA --> Agg
ScoresB --> Agg

Agg --> Stats: 生成对比报告

@enduml
```

### 评分对比流程

```plantuml
@startuml
!theme plain
skinparam backgroundColor #FFFFFF
skinparam sequenceArrowColor #1976D2
skinparam sequenceActorBorderColor #426450ff
skinparam sequenceParticipantBorderColor #6C757D
skinparam SequenceParticipantBorderThickness 2
skinparam sequenceLifeLineBorderColor #9bd0f5ff
skinparam noteBackgroundColor #FFF3E0
skinparam noteBorderColor #F57C00
skinparam style strictuml
skinparam Padding 6
skinparam ParticipantPadding 30

title 多模型评分对比分析流程

participant "测试控制器" as Controller
participant "GPT-4" as GPT4
participant "Claude-3.5" as Claude
participant "自动评分" as AutoScore
participant "开发者" as Dev
participant "聚合引擎" as Agg
database "Langfuse" as DB

== 并行测试执行 ==

loop 50 次任务
  Controller -> GPT4: 生成代码\ntask_id: 1-50
  activate GPT4
  GPT4 -> DB: 创建 Trace\nmetadata.model: "gpt-4"
  GPT4 --> Controller: 返回代码
  deactivate GPT4
  
  Controller -> Claude: 生成代码\ntask_id: 1-50
  activate Claude
  Claude -> DB: 创建 Trace\nmetadata.model: "claude-3.5"
  Claude --> Controller: 返回代码
  deactivate Claude
end

== 自动评分（API） ==

Controller -> AutoScore: 批量评分\n100 个 Trace

activate AutoScore

loop 每个 Trace
  AutoScore -> AutoScore: 语法检查
  AutoScore -> DB: 保存评分\nsyntax_correctness-API-BOOLEAN
  
  AutoScore -> AutoScore: 运行单元测试
  AutoScore -> DB: 保存评分\ntest_pass_rate-API-NUMERIC
  
  AutoScore -> AutoScore: 性能分析
  AutoScore -> DB: 保存评分\ngeneration_time-API-NUMERIC
end

AutoScore --> Controller: 自动评分完成
deactivate AutoScore

== 人工评分（ANNOTATION） ==

Dev -> DB: 查询待评审代码\n按模型随机抽样 20%
DB --> Dev: 返回 20 个 Trace

loop 每个 Trace
  Dev -> Dev: 阅读代码\n评估质量和可读性
  
  Dev -> DB: ANNOTATION 评分\ncode_quality: 8/10\nreadability: 7/10
  
  Dev -> DB: 记录审计日志
end

Dev --> Controller: 人工评分完成

== 聚合分析 ==

Controller -> Agg: 请求对比报告
activate Agg

Agg -> DB: 查询 GPT-4 评分\nfilter: metadata.model = "gpt-4"
DB --> Agg: 返回 50 组评分数据

Agg -> Agg: aggregateScores(gpt4Scores)
note right
  GPT-4 聚合结果：
  - 语法正确率: 98%
  - 平均测试通过率: 85
  - 平均代码质量: 8.2
  - 平均生成时间: 3.5s
end note

Agg -> DB: 查询 Claude-3.5 评分\nfilter: metadata.model = "claude-3.5"
DB --> Agg: 返回 50 组评分数据

Agg -> Agg: aggregateScores(claudeScores)
note right
  Claude-3.5 聚合结果：
  - 语法正确率: 100%
  - 平均测试通过率: 88
  - 平均代码质量: 8.5
  - 平均生成时间: 2.8s
end note

Agg -> Agg: 统计显著性检验\nt-test, p-value 计算

Agg --> Controller: 返回对比报告
note right
  **结论：Claude-3.5 在所有指标上优于 GPT-4**
  - 语法：+2% (p < 0.05)
  - 测试：+3 分 (p < 0.01)
  - 质量：+0.3 分 (p < 0.05)
  - 速度：快 20% (p < 0.001)
  
  **推荐：切换到 Claude-3.5**
end note

deactivate Agg

@enduml
```

### 业务价值

- **数据驱动决策**：量化对比模型性能
- **成本优化**：选择性价比最优模型
- **持续改进**：定期测试新模型版本
- **风险降低**：验证模型切换影响

---

## 应用场景四：用户反馈闭环

### 场景描述

产品团队希望建立用户反馈驱动的改进闭环：
- **即时反馈**：👍/👎 按钮收集满意度
- **详细评价**：用户可选择性提供详细反馈
- **问题分类**：自动识别不满意原因
- **改进跟踪**：监控改进措施效果

### 反馈收集流程

```plantuml
@startuml
!theme plain
skinparam backgroundColor #FFFFFF
skinparam sequenceArrowColor #1976D2
skinparam sequenceActorBorderColor #426450ff
skinparam sequenceParticipantBorderColor #6C757D
skinparam SequenceParticipantBorderThickness 2
skinparam sequenceLifeLineBorderColor #9bd0f5ff
skinparam noteBackgroundColor #FFF3E0
skinparam noteBorderColor #F57C00
skinparam style strictuml
skinparam Padding 6
skinparam ParticipantPadding 30

title 用户反馈收集与分析闭环

actor "用户" as User
participant "应用界面" as UI
participant "Langfuse SDK" as SDK
database "ClickHouse" as CH
participant "分析引擎" as Analytics
actor "产品团队" as Product

== 用户交互 ==

User -> UI: 使用 AI 功能\n(问答/生成/翻译等)
UI -> SDK: 创建 Trace\n记录交互
SDK -> CH: 保存 Trace 数据

UI --> User: 展示 AI 回答

== 即时反馈 ==

UI -> User: 显示反馈按钮\n👍 有帮助 | 👎 无帮助

alt 正面反馈
  User -> UI: 点击 👍
  UI -> SDK: 创建 FEEDBACK 评分
  SDK -> CH: 保存评分\nhelpful-FEEDBACK-BOOLEAN: True
  UI --> User: 感谢反馈！
else 负面反馈
  User -> UI: 点击 👎
  UI -> UI: 展开详细反馈表单
  UI -> User: 请选择问题类型：\n□ 答案不准确\n□ 答案不相关\n□ 响应太慢\n□ 格式有问题
  
  User -> UI: 选择"答案不准确"\n（可选）添加评论："引用的法条过时了"
  
  UI -> SDK: 创建 FEEDBACK 评分（1）\nhelpful: False
  SDK -> CH: 保存评分
  
  UI -> SDK: 创建 FEEDBACK 评分（2）\nissue_type: "inaccurate"
  SDK -> CH: 保存评分
  
  UI -> SDK: 添加评论到 Trace
  SDK -> CH: 更新 Trace metadata
  
  UI --> User: 感谢反馈！我们会改进
end

== 自动分析 ==

Analytics -> CH: 定时查询负面反馈\n(每小时)
CH --> Analytics: 返回 helpful=False 的 Trace

loop 每个负面反馈
  Analytics -> Analytics: 提取问题类型\n统计出现频率
  
  Analytics -> Analytics: 聚合分析\naggregateScores()
  note right
    问题分布：
    - 答案不准确: 45%
    - 答案不相关: 30%
    - 响应太慢: 15%
    - 格式问题: 10%
  end note
end

== 产品团队响应 ==

Analytics -> Product: 推送每日报告\n高亮关键问题
activate Product

Product -> Product: 分析问题根因
note right
  "答案不准确" 高发原因：
  1. RAG 检索到过期文档
  2. 模型幻觉生成错误信息
  
  改进计划：
  - 更新知识库（本周）
  - 增加引用验证（下周）
end note

Product -> Product: 实施改进措施

Product -> Analytics: 标记改进措施\ntag: "kb_update_2025_12"

deactivate Product

== 效果验证 ==

Analytics -> CH: 查询改进后的反馈\nfilter: timestamp > '2025-12-24'\nfilter: tag = "kb_update_2025_12"

CH --> Analytics: 返回新评分数据

Analytics -> Analytics: 对比分析
note right
  改进前：
  - 有帮助率: 72%
  - 不准确投诉: 45%
  
  改进后：
  - 有帮助率: 85% ⬆️ +13%
  - 不准确投诉: 18% ⬇️ -27%
  
  ✅ 改进措施有效
end note

Analytics -> Product: 推送效果报告
Product -> Product: 确认改进成功\n进入下一轮优化

@enduml
```

### 业务价值

- **快速响应**：及时发现用户痛点
- **问题优先级**：数据驱动资源分配
- **效果量化**：验证改进措施效果
- **用户参与**：增强用户归属感

---

## 评分来源对比

```plantuml
@startuml
!theme plain

title 四种评分来源对比

rectangle "**ANNOTATION** 人工标注" as ANN #LightBlue {
  card "特点" as ANN_F
  card "成本" as ANN_C
  card "准确性" as ANN_A
  card "场景" as ANN_S
}

rectangle "**API** 自动评分" as API #LightGreen {
  card "特点" as API_F
  card "成本" as API_C
  card "准确性" as API_A
  card "场景" as API_S
}

rectangle "**EVAL** 批量评估" as EVAL #LightCoral {
  card "特点" as EVAL_F
  card "成本" as EVAL_C
  card "准确性" as EVAL_A
  card "场景" as EVAL_S
}

rectangle "**FEEDBACK** 用户反馈" as FEED #LightYellow {
  card "特点" as FEED_F
  card "成本" as FEED_C
  card "准确性" as FEED_A
  card "场景" as FEED_S
}

note right of ANN_F
  事后人工评审
  需要专业知识
  可提供详细评论
end note

note right of ANN_C
  高 (人力成本)
end note

note right of ANN_A
  ⭐⭐⭐⭐⭐ (最准确)
end note

note right of ANN_S
  Ground Truth 构建
  训练数据标注
  法律/医疗等专业领域
end note

note right of API_F
  实时自动执行
  可编程规则
  100% 覆盖
end note

note right of API_C
  低 (计算成本)
end note

note right of API_A
  ⭐⭐⭐ (规则准确)
end note

note right of API_S
  语法检查
  格式验证
  性能监控
end note

note right of EVAL_F
  离线批量处理
  使用 LLM-as-Judge
  可重复执行
end note

note right of EVAL_C
  中 (API 调用成本)
end note

note right of EVAL_A
  ⭐⭐⭐⭐ (模型准确)
end note

note right of EVAL_S
  模型对比测试
  回归测试
  历史数据分析
end note

note right of FEED_F
  用户主动触发
  真实使用反馈
  可能有偏差
end note

note right of FEED_C
  无 (用户自愿)
end note

note right of FEED_A
  ⭐⭐⭐ (主观评价)
end note

note right of FEED_S
  满意度调查
  A/B 测试
  产品迭代
end note

@enduml
```

---

## 数据流架构

```plantuml
@startuml
!theme plain

title Scores 模块完整数据流架构

package "数据采集层" {
  [UI 界面] as UI
  [API 服务] as API_SVC
  [批量任务] as Batch
  [标注平台] as Annotation
}

package "评分层" {
  [FEEDBACK 评分] as FEED #LightYellow
  [API 评分] as API #LightGreen
  [EVAL 评分] as EVAL #LightCoral
  [ANNOTATION 评分] as ANN #LightBlue
}

package "配置管理层" {
  database "ScoreConfig\n(Prisma)" as Config
  [Config Management] as ConfigMgmt
  [验证引擎] as Validator
}

package "存储层" {
  database "ClickHouse\n(评分数据)" as CH
  database "PostgreSQL\n(配置/审计)" as PG
}

package "聚合层" {
  [aggregateScores()] as Agg
  [分组引擎] as Group
  [统计计算] as Calc
}

package "应用层" {
  [仪表盘] as Dashboard
  [质量报告] as Report
  [告警系统] as Alert
  [数据导出] as Export
}

UI --> FEED
API_SVC --> API
Batch --> EVAL
Annotation --> ANN

FEED --> Config: 验证配置
API --> Config: 验证配置
EVAL --> Config: 验证配置
ANN --> ConfigMgmt: 创建/更新评分

ConfigMgmt --> Validator: 验证合规性
Validator --> Config: 读取配置
Config --> PG: 持久化

FEED --> CH: 保存评分
API --> CH: 保存评分
EVAL --> CH: 保存评分
ANN --> CH: 保存评分
ANN --> PG: 审计日志

CH --> Agg: 原始评分数据
Agg --> Group: 按键分组
Group --> Calc: 计算统计

Calc --> Dashboard: 实时展示
Calc --> Report: 生成报告
Calc --> Alert: 触发告警
Calc --> Export: 数据导出

note right of Agg
  聚合键格式：
  name-source-dataType
  
  示例：
  quality-ANNOTATION-NUMERIC
  tone-API-CATEGORICAL
end note

note right of Validator
  验证规则：
  1. 数据类型匹配
  2. 配置未归档
  3. 名称匹配
  4. 值范围/类别检查
end note

@enduml
```

---

## 关键设计原则

### 1. 多来源融合

通过区分 ANNOTATION、API、EVAL、FEEDBACK 四种来源，支持从自动化到人工审核的完整评估链条。

### 2. 配置驱动

通过 ScoreConfig 统一评分标准，确保：
- 数据类型一致性
- 值范围合法性
- 类别定义规范化

### 3. 灵活聚合

aggregateScores 函数按 `name-source-dataType` 自动分组：
- NUMERIC：计算平均值、最小值、最大值
- CATEGORICAL：统计分布、频次
- BOOLEAN：计数统计（转为 CATEGORICAL 处理）

### 4. 审计追踪

所有评分操作记录审计日志：
- 创建者信息（authorUserId）
- 操作时间（timestamp）
- 配置关联（configId）
- 评论内容（comment）

### 5. 渐进式实施

从简单到复杂的实施路径：
1. **阶段 1**：API 自动评分（语法检查、性能监控）
2. **阶段 2**：用户反馈收集（👍/👎 按钮）
3. **阶段 3**：人工标注平台（专家审核）
4. **阶段 4**：批量评估任务（LLM-as-Judge）

---

## 实施建议

### 快速启动（第 1 周）

1. **创建基础配置**：定义 2-3 个核心评分指标
2. **集成 API 评分**：添加自动化评分逻辑
3. **启用用户反馈**：添加 👍/👎 按钮

### 扩展阶段（第 2-4 周）

1. **建立标注平台**：训练标注团队
2. **配置聚合报告**：搭建可视化仪表盘
3. **优化评分规则**：根据反馈调整配置

### 成熟运营（持续）

1. **定期质量审核**：月度/季度质量回顾
2. **A/B 测试迭代**：持续优化模型和 Prompt
3. **自动化告警**：设置质量阈值告警

---

## 总结

Scores 模块通过**多来源、多类型、配置驱动**的设计，为 LLM 应用提供了完整的质量评估体系。从实时自动监控到离线专家审核，从用户反馈到批量测试，覆盖了质量管理的全生命周期，帮助团队建立数据驱动的持续改进闭环。

