@startuml
!theme plain
skinparam backgroundColor #FFFFFF
skinparam activityBackgroundColor LightBlue
skinparam activityBorderColor Black
skinparam activityDiamondBackgroundColor LightYellow
skinparam activityDiamondBorderColor Black
skinparam noteBackgroundColor LightYellow
skinparam noteBorderColor Orange

title Langfuse 核心数据流程图

|客户端|
start
:发起 API 请求\n(Trace/Observation/Score);

|API 层|
:接收请求;
:验证 API Key;

note right
  查询流程：
  1. 计算 SHA-256 哈希
  2. Redis 缓存查询
  3. 缓存未命中 → 查询 PostgreSQL
  4. 缓存结果
end note

if (API Key 有效?) then (是)
  :提取项目 ID\n和权限范围;
else (否)
  :返回 401 错误;
  stop
endif

|服务层|
partition "数据写入流程" {
  if (请求类型?) then (元数据操作)
    :写入 PostgreSQL;
    note right
      元数据包括：
      - Prompt 创建/更新
      - Dataset 管理
      - Model 配置
      - 用户设置
    end note
    
    :返回成功响应;
    
  elseif (追踪数据) then
    :验证数据格式;
    
    fork
      :写入 PostgreSQL\n(TraceSession 等元数据);
    fork again
      :发送到 Redis 队列\n(ingestionQueue);
    end fork
    
    :返回 202 Accepted;
    
    |Worker 服务|
    :从队列消费任务;
    
    :批量处理数据\n(10,000 条/批);
    
    fork
      :写入 ClickHouse\n(traces 表);
    fork again
      :写入 ClickHouse\n(observations 表);
    fork again
      :写入 ClickHouse\n(scores 表);
    end fork
    
    note right
      ClickHouse 写入特点：
      - 列式存储
      - 批量插入
      - 高压缩率
      - 按月分区
    end note
    
    if (有媒体文件?) then (是)
      :生成 S3 预签名 URL;
      |客户端|
      :直接上传到 S3;
      |Worker 服务|
      :记录媒体关联关系;
    endif
    
    if (触发 Webhook?) then (是)
      :添加到 webhookQueue;
      |Worker 服务|
      :异步发送 Webhook;
    endif
    
    if (触发集成?) then (是)
      fork
        :PostHog 集成队列;
      fork again
        :Mixpanel 集成队列;
      fork again
        :Slack 通知队列;
      end fork
    endif
    
  elseif (评估任务) then
    :创建 JobConfiguration;
    :写入 PostgreSQL;
    
    :添加到 createEvalQueue;
    
    |Worker 服务|
    :扫描符合条件的数据;
    
    :添加评估任务到\nevalExecutionQueue;
    
    :执行 LLM 评估;
    
    :保存评估结果\n(Scores);
    
  elseif (批量导出) then
    :创建 BatchExport 记录;
    :写入 PostgreSQL;
    
    :添加到 batchExport 队列;
    
    |Worker 服务|
    :从 ClickHouse 查询数据;
    
    :生成 CSV/JSON 文件;
    
    :上传到 S3;
    
    :更新 BatchExport 状态;
    
    :生成下载 URL;
  endif
}

|客户端|
:接收响应;

partition "数据查询流程" {
  |客户端|
  :发起查询请求\n(Dashboard/Analytics);
  
  |API 层|
  :验证权限;
  
  |服务层|
  if (查询类型?) then (元数据查询)
    :查询 PostgreSQL;
    note right
      元数据查询包括：
      - 用户信息
      - 项目配置
      - Prompt 列表
      - Dataset 详情
    end note
    
  elseif (追踪数据查询) then
    if (简单查询?) then (是)
      :直接查询 ClickHouse;
    else (复杂聚合)
      if (Redis 缓存存在?) then (是)
        :返回缓存结果;
      else (否)
        :查询 ClickHouse;
        :计算聚合指标;
        :缓存结果 (TTL: 5分钟);
      endif
    endif
    
    note right
      ClickHouse 查询优化：
      - 利用分区裁剪
      - 列式读取
      - 并行查询
      - 索引加速
    end note
    
  elseif (媒体文件) then
    :验证访问权限;
    :生成 S3 预签名 URL;
    |客户端|
    :从 S3 下载文件;
  endif
  
  :返回查询结果;
}

|客户端|
:展示数据;

legend right
数据流特点

1) 读写分离：
  - 元数据：PostgreSQL（读写）
  - 追踪数据：ClickHouse（主要读）+ 异步写入

2) 异步处理：
  - 追踪数据通过队列异步写入
  - 降低 API 响应延迟
  - 提高系统吞吐量

3) 缓存策略：
  - API Key 缓存（24小时）
  - 查询结果缓存（5分钟）
  - 减少数据库压力

4) 批量优化：
  - ClickHouse 批量写入（10K/批）
  - 提高写入性能
  - 减少网络开销

5) 多存储协同：
  - PostgreSQL：元数据和配置
  - ClickHouse：海量追踪数据
  - Redis：缓存和队列
  - S3：大文件存储
endlegend

stop

@enduml
