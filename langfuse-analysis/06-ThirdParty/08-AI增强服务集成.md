# AI增强服务集成

## 1. 集成概述

Langfuse 集成 AI 增强服务来提供额外的智能功能,主要用于文本分词 (Tokenization) 和嵌入 (Embeddings) 处理。

## 2. 支持的服务/产品

| 服务名称 | SDK | 状态 | 优先级 | 用途 |
|---------|-----|------|--------|------|
| **Tiktoken** | `tiktoken` | ✅ 已支持 | ⭐⭐⭐ 核心 | OpenAI Token 计数 |
| **Anthropic Tokenizer** | `@anthropic-ai/tokenizer` | ✅ 已支持 | ⭐⭐⭐ 核心 | Claude Token 计数 |

### 2.1 版本信息

```json
{
  "tiktoken": "^1.0.20",
  "@anthropic-ai/tokenizer": "^0.0.4"
}
```

## 3. Tiktoken 集成 (OpenAI)

### 3.1 用途

- 计算 OpenAI 模型的 Token 使用量
- 预估 LLM 调用成本
- 验证输入是否超过模型限制

### 3.2 使用示例

```typescript
import { get_encoding, encoding_for_model } from "tiktoken";

// 方式 1: 根据模型获取编码器
const encoding = encoding_for_model("gpt-4o");
const tokens = encoding.encode("Hello, world!");
console.log("Token count:", tokens.length);
encoding.free(); // 释放内存

// 方式 2: 使用特定编码
const cl100k = get_encoding("cl100k_base"); // GPT-4, GPT-3.5-turbo
const tokens = cl100k.encode("Hello, world!");
console.log("Token count:", tokens.length);
cl100k.free();
```

### 3.3 在 Langfuse 中的应用

```typescript
// 计算 Trace 的 Token 使用量
export function calculateTokenUsage(observation: {
  model: string;
  input: string;
  output: string;
}) {
  try {
    const encoding = encoding_for_model(observation.model as any);
    
    const inputTokens = encoding.encode(observation.input).length;
    const outputTokens = encoding.encode(observation.output).length;
    
    encoding.free();
    
    return {
      inputTokens,
      outputTokens,
      totalTokens: inputTokens + outputTokens,
    };
  } catch (error) {
    logger.warn("Failed to calculate tokens", { error });
    return null;
  }
}
```

## 4. Anthropic Tokenizer 集成 (Claude)

### 4.1 用途

- 计算 Claude 模型的 Token 使用量
- 成本估算

### 4.2 使用示例

```typescript
import { countTokens } from "@anthropic-ai/tokenizer";

const text = "Hello, world!";
const tokenCount = countTokens(text);
console.log("Token count:", tokenCount);
```

### 4.3 在 Langfuse 中的应用

```typescript
// 针对 Claude 模型的 Token 计数
export function calculateClaudeTokens(text: string): number {
  try {
    return countTokens(text);
  } catch (error) {
    logger.warn("Failed to count Claude tokens", { error });
    return 0;
  }
}
```

## 5. 成本计算

### 5.1 实现示例

```typescript
// 成本计算模型定价
const MODEL_PRICING = {
  "gpt-4o": {
    inputCostPer1kTokens: 0.005,
    outputCostPer1kTokens: 0.015,
  },
  "gpt-3.5-turbo": {
    inputCostPer1kTokens: 0.0015,
    outputCostPer1kTokens: 0.002,
  },
  "claude-3-5-sonnet-20241022": {
    inputCostPer1kTokens: 0.003,
    outputCostPer1kTokens: 0.015,
  },
};

export function calculateCost(params: {
  model: string;
  inputTokens: number;
  outputTokens: number;
}): number {
  const pricing = MODEL_PRICING[params.model];
  if (!pricing) return 0;

  const inputCost = (params.inputTokens / 1000) * pricing.inputCostPer1kTokens;
  const outputCost = (params.outputTokens / 1000) * pricing.outputCostPer1kTokens;

  return inputCost + outputCost;
}
```

## 6. 最佳实践

### 6.1 缓存 Token 计数

```typescript
// 缓存 Token 计数结果
const tokenCache = new Map<string, number>();

export function getCachedTokenCount(text: string): number {
  const cacheKey = hash(text);
  
  if (tokenCache.has(cacheKey)) {
    return tokenCache.get(cacheKey)!;
  }

  const count = calculateTokens(text);
  tokenCache.set(cacheKey, count);
  
  return count;
}
```

### 6.2 内存管理

```typescript
// Tiktoken 编码器需要手动释放
const encoding = get_encoding("cl100k_base");
try {
  const tokens = encoding.encode(text);
  return tokens.length;
} finally {
  encoding.free(); // 重要：释放内存
}
```

---

**更新日期**: 2025-12-17  
**维护者**: Langfuse Engineering Team
