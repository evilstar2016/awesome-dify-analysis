# 对象存储集成

## 1. 集成概述

Langfuse 使用对象存储服务来保存大型文件和二进制数据，包括原始摄取事件、多模态附件（图片、音频、视频）和批量导出文件。通过统一的 StorageService 接口，支持多个对象存储提供商。

### 1.1 设计原则

- **统一接口**: StorageService 抽象层，支持多个提供商
- **工厂模式**: 根据环境配置自动选择合适的存储服务
- **按需加载**: 仅在需要时创建存储客户端
- **预签名 URL**: 使用预签名 URL 实现安全的文件上传和下载

### 1.2 使用场景

- **事件摄取**: 原始 SDK 事件存储到 S3，Worker 异步处理
- **多模态附件**: LLM 输入/输出中的图片、音频等文件
- **批量导出**: 大规模数据导出到对象存储，用户下载
- **备份**: 数据库备份和归档

## 2. 支持的服务/产品

| 服务名称 | SDK | 状态 | 优先级 | 兼容性 | 说明 |
|---------|-----|------|--------|--------|------|
| **AWS S3** | `@aws-sdk/client-s3` | ✅ 已支持 | ⭐⭐⭐ 核心 | S3 API | 标准 S3 服务 |
| **Azure Blob Storage** | `@azure/storage-blob` | ✅ 已支持 | ⭐⭐ 重要 | Azure API | Azure 云存储 |
| **Google Cloud Storage** | `@google-cloud/storage` | ✅ 已支持 | ⭐⭐ 重要 | GCS API | Google 云存储 |
| **Cloudflare R2** | `@aws-sdk/client-s3` | ✅ 已支持 | ⭐⭐ 重要 | S3 兼容 | 零出口费用 |
| **MinIO** | `@aws-sdk/client-s3` | ✅ 已支持 | ⭐ 可选 | S3 兼容 | 自托管 S3 |
| **DigitalOcean Spaces** | `@aws-sdk/client-s3` | ✅ 已支持 | ⭐ 可选 | S3 兼容 | - |

### 2.1 版本信息

```json
{
  "@aws-sdk/client-s3": "^3.675.0",
  "@aws-sdk/lib-storage": "^3.675.0",
  "@aws-sdk/s3-request-presigner": "^3.679.0",
  "@azure/storage-blob": "^12.26.0",
  "@google-cloud/storage": "^7.17.0"
}
```

## 3. 集成方式

### 3.1 架构设计

```
┌─────────────────────────────────────────────────────────┐
│                  Application Layer                       │
│  (Web / Worker / API)                                   │
└───────────────────────┬─────────────────────────────────┘
                        │
                        ▼
┌─────────────────────────────────────────────────────────┐
│           StorageServiceFactory                          │
│  packages/shared/src/server/services/StorageService.ts  │
├─────────────────────────────────────────────────────────┤
│  • 检测环境变量                                          │
│  • 创建合适的 StorageService 实例                        │
└───────────────────────┬─────────────────────────────────┘
                        │
        ┌───────────────┼───────────────┐
        │               │               │
        ▼               ▼               ▼
┌─────────────┐ ┌─────────────┐ ┌─────────────┐
│S3Storage    │ │AzureBlob    │ │GCSStorage   │
│Service      │ │Service      │ │Service      │
└──────┬──────┘ └──────┬──────┘ └──────┬──────┘
       │               │               │
       ▼               ▼               ▼
┌─────────────┐ ┌─────────────┐ ┌─────────────┐
│ AWS S3      │ │ Azure Blob  │ │ Google GCS  │
│ (or S3-     │ │ Storage     │ │             │
│  compatible)│ │             │ │             │
└─────────────┘ └─────────────┘ └─────────────┘
```

### 3.2 统一接口定义

```typescript
// packages/shared/src/server/services/StorageService.ts

export interface StorageService {
  /**
   * 上传文件到对象存储
   */
  uploadFile(params: UploadFile): Promise<string>;
  
  /**
   * 获取预签名下载 URL
   */
  getSignedDownloadUrl(params: {
    fileName: string;
    expiresInSeconds?: number;
  }): Promise<string>;
  
  /**
   * 获取预签名上传 URL (客户端直传)
   */
  getSignedUploadUrl(params: UploadWithSignedUrl): Promise<{
    uploadUrl: string;
    publicUrl: string;
  }>;
  
  /**
   * 删除文件
   */
  deleteFile(fileName: string): Promise<void>;
}

export interface UploadFile {
  fileName: string;
  fileType: string;
  data: Buffer | Uint8Array | Blob | string | Readable;
  expiresInSeconds?: number;
}

export interface UploadWithSignedUrl {
  fileName: string;
  fileType: string;
  expiresInSeconds?: number;
}
```

## 4. 代码实现

### 4.1 核心代码路径

```
packages/shared/src/server/
└── services/
    └── StorageService.ts         # 所有存储服务实现

web/src/server/
└── api/
    └── routers/
        └── media.ts              # 媒体文件 API

worker/src/
├── queues/
│   ├── batchExport/              # 批量导出队列
│   └── ingestionQueue/           # 事件摄取队列
└── services/
    └── S3BatchExportService.ts   # 导出服务
```

### 4.2 S3 存储服务实现

```typescript
// packages/shared/src/server/services/StorageService.ts
import {
  S3Client,
  PutObjectCommand,
  GetObjectCommand,
  DeleteObjectCommand,
} from "@aws-sdk/client-s3";
import { Upload } from "@aws-sdk/lib-storage";
import { getSignedUrl } from "@aws-sdk/s3-request-presigner";

export class S3StorageService implements StorageService {
  private client: S3Client;
  private bucketName: string;
  private endpoint?: string;

  constructor(config: {
    accessKeyId: string;
    secretAccessKey: string;
    bucketName: string;
    region: string;
    endpoint?: string;  // 用于 MinIO / R2
    forcePathStyle?: boolean;  // MinIO 需要
  }) {
    this.bucketName = config.bucketName;
    this.endpoint = config.endpoint;

    this.client = new S3Client({
      region: config.region,
      credentials: {
        accessKeyId: config.accessKeyId,
        secretAccessKey: config.secretAccessKey,
      },
      ...(config.endpoint && { endpoint: config.endpoint }),
      forcePathStyle: config.forcePathStyle ?? false,
    });
  }

  async uploadFile(params: UploadFile): Promise<string> {
    const upload = new Upload({
      client: this.client,
      params: {
        Bucket: this.bucketName,
        Key: params.fileName,
        Body: params.data,
        ContentType: params.fileType,
      },
    });

    await upload.done();

    return this.getPublicUrl(params.fileName);
  }

  async getSignedDownloadUrl(params: {
    fileName: string;
    expiresInSeconds?: number;
  }): Promise<string> {
    const command = new GetObjectCommand({
      Bucket: this.bucketName,
      Key: params.fileName,
    });

    const url = await getSignedUrl(
      this.client,
      command,
      { expiresIn: params.expiresInSeconds ?? 3600 }
    );

    return url;
  }

  async getSignedUploadUrl(params: UploadWithSignedUrl): Promise<{
    uploadUrl: string;
    publicUrl: string;
  }> {
    const command = new PutObjectCommand({
      Bucket: this.bucketName,
      Key: params.fileName,
      ContentType: params.fileType,
    });

    const uploadUrl = await getSignedUrl(
      this.client,
      command,
      { expiresIn: params.expiresInSeconds ?? 3600 }
    );

    const publicUrl = this.getPublicUrl(params.fileName);

    return { uploadUrl, publicUrl };
  }

  async deleteFile(fileName: string): Promise<void> {
    const command = new DeleteObjectCommand({
      Bucket: this.bucketName,
      Key: fileName,
    });

    await this.client.send(command);
  }

  private getPublicUrl(fileName: string): string {
    if (this.endpoint) {
      // MinIO / R2 / 自定义端点
      return `${this.endpoint}/${this.bucketName}/${fileName}`;
    }
    // 标准 S3 URL
    return `https://${this.bucketName}.s3.amazonaws.com/${fileName}`;
  }
}
```

### 4.3 Azure Blob Storage 实现

```typescript
import {
  BlobServiceClient,
  StorageSharedKeyCredential,
  generateBlobSASQueryParameters,
  BlobSASPermissions,
} from "@azure/storage-blob";

export class AzureBlobStorageService implements StorageService {
  private blobServiceClient: BlobServiceClient;
  private containerName: string;
  private accountName: string;
  private accountKey: string;

  constructor(config: {
    connectionString: string;
    containerName: string;
    accountName: string;
    accountKey: string;
  }) {
    this.containerName = config.containerName;
    this.accountName = config.accountName;
    this.accountKey = config.accountKey;

    this.blobServiceClient = BlobServiceClient.fromConnectionString(
      config.connectionString
    );
  }

  async uploadFile(params: UploadFile): Promise<string> {
    const containerClient = this.blobServiceClient.getContainerClient(
      this.containerName
    );
    const blockBlobClient = containerClient.getBlockBlobClient(params.fileName);

    await blockBlobClient.upload(params.data, (params.data as Buffer).length, {
      blobHTTPHeaders: {
        blobContentType: params.fileType,
      },
    });

    return blockBlobClient.url;
  }

  async getSignedDownloadUrl(params: {
    fileName: string;
    expiresInSeconds?: number;
  }): Promise<string> {
    const containerClient = this.blobServiceClient.getContainerClient(
      this.containerName
    );
    const blockBlobClient = containerClient.getBlockBlobClient(params.fileName);

    const expiresOn = new Date();
    expiresOn.setSeconds(
      expiresOn.getSeconds() + (params.expiresInSeconds ?? 3600)
    );

    const sasToken = generateBlobSASQueryParameters(
      {
        containerName: this.containerName,
        blobName: params.fileName,
        permissions: BlobSASPermissions.parse("r"), // Read only
        expiresOn: expiresOn,
      },
      new StorageSharedKeyCredential(this.accountName, this.accountKey)
    ).toString();

    return `${blockBlobClient.url}?${sasToken}`;
  }

  async getSignedUploadUrl(params: UploadWithSignedUrl): Promise<{
    uploadUrl: string;
    publicUrl: string;
  }> {
    const containerClient = this.blobServiceClient.getContainerClient(
      this.containerName
    );
    const blockBlobClient = containerClient.getBlockBlobClient(params.fileName);

    const expiresOn = new Date();
    expiresOn.setSeconds(
      expiresOn.getSeconds() + (params.expiresInSeconds ?? 3600)
    );

    const sasToken = generateBlobSASQueryParameters(
      {
        containerName: this.containerName,
        blobName: params.fileName,
        permissions: BlobSASPermissions.parse("cw"), // Create, Write
        expiresOn: expiresOn,
      },
      new StorageSharedKeyCredential(this.accountName, this.accountKey)
    ).toString();

    const uploadUrl = `${blockBlobClient.url}?${sasToken}`;
    const publicUrl = blockBlobClient.url;

    return { uploadUrl, publicUrl };
  }

  async deleteFile(fileName: string): Promise<void> {
    const containerClient = this.blobServiceClient.getContainerClient(
      this.containerName
    );
    const blockBlobClient = containerClient.getBlockBlobClient(fileName);

    await blockBlobClient.delete();
  }
}
```

### 4.4 Google Cloud Storage 实现

```typescript
import { Storage, Bucket } from "@google-cloud/storage";

export class GoogleCloudStorageService implements StorageService {
  private bucket: Bucket;

  constructor(config: {
    bucketName: string;
    projectId?: string;
    keyFilename?: string;  // Service account key file
    credentials?: any;     // Service account credentials object
  }) {
    const storage = new Storage({
      projectId: config.projectId,
      keyFilename: config.keyFilename,
      credentials: config.credentials,
    });

    this.bucket = storage.bucket(config.bucketName);
  }

  async uploadFile(params: UploadFile): Promise<string> {
    const file = this.bucket.file(params.fileName);

    await file.save(params.data as Buffer, {
      contentType: params.fileType,
      metadata: {
        contentType: params.fileType,
      },
    });

    return `gs://${this.bucket.name}/${params.fileName}`;
  }

  async getSignedDownloadUrl(params: {
    fileName: string;
    expiresInSeconds?: number;
  }): Promise<string> {
    const file = this.bucket.file(params.fileName);

    const [url] = await file.getSignedUrl({
      action: "read",
      expires: Date.now() + (params.expiresInSeconds ?? 3600) * 1000,
    });

    return url;
  }

  async getSignedUploadUrl(params: UploadWithSignedUrl): Promise<{
    uploadUrl: string;
    publicUrl: string;
  }> {
    const file = this.bucket.file(params.fileName);

    const [uploadUrl] = await file.getSignedUrl({
      action: "write",
      expires: Date.now() + (params.expiresInSeconds ?? 3600) * 1000,
      contentType: params.fileType,
    });

    const publicUrl = `https://storage.googleapis.com/${this.bucket.name}/${params.fileName}`;

    return { uploadUrl, publicUrl };
  }

  async deleteFile(fileName: string): Promise<void> {
    const file = this.bucket.file(fileName);
    await file.delete();
  }
}
```

### 4.5 StorageServiceFactory

```typescript
export class StorageServiceFactory {
  static create(): StorageService | null {
    // Azure Blob Storage
    if (env.AZURE_STORAGE_CONNECTION_STRING) {
      return new AzureBlobStorageService({
        connectionString: env.AZURE_STORAGE_CONNECTION_STRING,
        containerName: env.LANGFUSE_AZURE_BLOB_CONTAINER_NAME,
        accountName: env.AZURE_STORAGE_ACCOUNT_NAME,
        accountKey: env.AZURE_STORAGE_ACCOUNT_KEY,
      });
    }

    // Google Cloud Storage
    if (env.LANGFUSE_GCS_BUCKET_NAME) {
      return new GoogleCloudStorageService({
        bucketName: env.LANGFUSE_GCS_BUCKET_NAME,
        projectId: env.GCP_PROJECT_ID,
        keyFilename: env.GCS_CREDENTIALS_PATH,
      });
    }

    // S3 / S3-compatible (R2, MinIO, etc.)
    if (env.LANGFUSE_S3_EVENT_UPLOAD_BUCKET) {
      return new S3StorageService({
        accessKeyId: env.LANGFUSE_S3_EVENT_UPLOAD_ACCESS_KEY_ID,
        secretAccessKey: env.LANGFUSE_S3_EVENT_UPLOAD_SECRET_ACCESS_KEY,
        bucketName: env.LANGFUSE_S3_EVENT_UPLOAD_BUCKET,
        region: env.LANGFUSE_S3_EVENT_UPLOAD_REGION,
        endpoint: env.LANGFUSE_S3_EVENT_UPLOAD_ENDPOINT,  // 可选
        forcePathStyle: env.LANGFUSE_S3_EVENT_UPLOAD_FORCE_PATH_STYLE === "true",
      });
    }

    // 没有配置存储服务
    return null;
  }
}
```

## 5. 配置示例

### 5.1 AWS S3 配置

```bash
# 标准 S3
LANGFUSE_S3_EVENT_UPLOAD_BUCKET="langfuse-events"
LANGFUSE_S3_EVENT_UPLOAD_REGION="us-east-1"
LANGFUSE_S3_EVENT_UPLOAD_ACCESS_KEY_ID="AKIA..."
LANGFUSE_S3_EVENT_UPLOAD_SECRET_ACCESS_KEY="..."

# 可选: 自定义端点 (留空使用默认 S3)
LANGFUSE_S3_EVENT_UPLOAD_ENDPOINT=""
LANGFUSE_S3_EVENT_UPLOAD_FORCE_PATH_STYLE="false"
```

### 5.2 Cloudflare R2 配置

```bash
# R2 兼容 S3 API
LANGFUSE_S3_EVENT_UPLOAD_BUCKET="langfuse-events"
LANGFUSE_S3_EVENT_UPLOAD_REGION="auto"  # R2 自动
LANGFUSE_S3_EVENT_UPLOAD_ACCESS_KEY_ID="..."
LANGFUSE_S3_EVENT_UPLOAD_SECRET_ACCESS_KEY="..."
LANGFUSE_S3_EVENT_UPLOAD_ENDPOINT="https://<account-id>.r2.cloudflarestorage.com"
LANGFUSE_S3_EVENT_UPLOAD_FORCE_PATH_STYLE="false"
```

### 5.3 MinIO 配置

```bash
# 自托管 MinIO
LANGFUSE_S3_EVENT_UPLOAD_BUCKET="langfuse"
LANGFUSE_S3_EVENT_UPLOAD_REGION="us-east-1"  # MinIO 忽略
LANGFUSE_S3_EVENT_UPLOAD_ACCESS_KEY_ID="minioadmin"
LANGFUSE_S3_EVENT_UPLOAD_SECRET_ACCESS_KEY="minioadmin"
LANGFUSE_S3_EVENT_UPLOAD_ENDPOINT="http://localhost:9000"
LANGFUSE_S3_EVENT_UPLOAD_FORCE_PATH_STYLE="true"  # MinIO 需要
```

### 5.4 Azure Blob Storage 配置

```bash
AZURE_STORAGE_CONNECTION_STRING="DefaultEndpointsProtocol=https;AccountName=...;AccountKey=...;EndpointSuffix=core.windows.net"
LANGFUSE_AZURE_BLOB_CONTAINER_NAME="langfuse-events"
AZURE_STORAGE_ACCOUNT_NAME="langfuseaccount"
AZURE_STORAGE_ACCOUNT_KEY="..."
```

### 5.5 Google Cloud Storage 配置

```bash
# 使用服务账号密钥文件
LANGFUSE_GCS_BUCKET_NAME="langfuse-events"
GCP_PROJECT_ID="my-project-123"
GCS_CREDENTIALS_PATH="/path/to/service-account-key.json"

# 或使用 Application Default Credentials (ADC)
LANGFUSE_GCS_BUCKET_NAME="langfuse-events"
GCP_PROJECT_ID="my-project-123"
# 不需要 GCS_CREDENTIALS_PATH，使用默认凭证
```

## 6. 使用示例

### 6.1 上传文件

```typescript
import { StorageServiceFactory } from "@langfuse/shared/src/server/services/StorageService";

const storage = StorageServiceFactory.create();

if (storage) {
  const url = await storage.uploadFile({
    fileName: `events/${projectId}/${eventId}.json`,
    fileType: "application/json",
    data: Buffer.from(JSON.stringify(eventData)),
  });

  console.log("File uploaded:", url);
}
```

### 6.2 生成预签名上传 URL (客户端直传)

```typescript
// tRPC API
export const mediaRouter = createTRPCRouter({
  getUploadUrl: protectedProjectProcedure
    .input(
      z.object({
        fileName: z.string(),
        fileType: z.string(),
      })
    )
    .mutation(async ({ input, ctx }) => {
      const storage = StorageServiceFactory.create();
      if (!storage) {
        throw new Error("Storage service not configured");
      }

      const { uploadUrl, publicUrl } = await storage.getSignedUploadUrl({
        fileName: `media/${ctx.session.project.id}/${input.fileName}`,
        fileType: input.fileType,
        expiresInSeconds: 3600, // 1 hour
      });

      return { uploadUrl, publicUrl };
    }),
});

// 客户端使用
const { uploadUrl, publicUrl } = await trpc.media.getUploadUrl.mutate({
  fileName: "image.png",
  fileType: "image/png",
});

// 使用 uploadUrl 直接上传到对象存储
await fetch(uploadUrl, {
  method: "PUT",
  body: file,
  headers: {
    "Content-Type": "image/png",
  },
});

// 保存 publicUrl 到数据库
```

### 6.3 生成预签名下载 URL

```typescript
const storage = StorageServiceFactory.create();

if (storage) {
  const downloadUrl = await storage.getSignedDownloadUrl({
    fileName: `exports/${projectId}/export.csv`,
    expiresInSeconds: 7200, // 2 hours
  });

  // 通过 Email 发送给用户
  await sendEmail({
    to: user.email,
    subject: "Your export is ready",
    body: `Download link: ${downloadUrl}`,
  });
}
```

### 6.4 批量导出到 S3

```typescript
// worker/src/services/S3BatchExportService.ts
export class S3BatchExportService {
  async exportToS3(params: {
    projectId: string;
    query: string;
    format: "csv" | "json";
  }) {
    const storage = StorageServiceFactory.create();
    if (!storage) {
      throw new Error("Storage not configured");
    }

    // 执行查询
    const data = await executeQuery(params.query);

    // 格式化数据
    const formatted = params.format === "csv" 
      ? convertToCSV(data) 
      : JSON.stringify(data);

    // 上传到 S3
    const fileName = `exports/${params.projectId}/${Date.now()}.${params.format}`;
    const url = await storage.uploadFile({
      fileName,
      fileType: params.format === "csv" ? "text/csv" : "application/json",
      data: Buffer.from(formatted),
    });

    // 生成下载链接
    const downloadUrl = await storage.getSignedDownloadUrl({
      fileName,
      expiresInSeconds: 86400 * 7, // 7 days
    });

    return { url, downloadUrl };
  }
}
```

## 7. 最佳实践

### 7.1 文件命名

```typescript
// 使用有组织的路径结构
const fileName = `${category}/${projectId}/${timestamp}_${uuid}.${ext}`;

// 示例
// events/proj-123/20231215_abc123.json
// media/proj-456/images/def456.png
// exports/proj-789/20231215_export.csv
```

### 7.2 成本优化

1. **生命周期策略**
   ```typescript
   // S3 生命周期规则 (在 AWS 控制台配置)
   {
     "Rules": [{
       "Id": "DeleteOldEvents",
       "Status": "Enabled",
       "Prefix": "events/",
       "Expiration": {
         "Days": 90  // 90 天后删除
       }
     }, {
       "Id": "ArchiveOldExports",
       "Status": "Enabled",
       "Prefix": "exports/",
       "Transitions": [{
         "Days": 30,
         "StorageClass": "GLACIER"  // 30 天后归档
       }]
     }]
   }
   ```

2. **压缩**
   ```typescript
   import zlib from "zlib";
   
   const compressed = zlib.gzipSync(Buffer.from(data));
   await storage.uploadFile({
     fileName: "events/data.json.gz",
     fileType: "application/gzip",
     data: compressed,
   });
   ```

### 7.3 安全

1. **访问控制**
   - 使用 IAM 角色而非固定凭证 (云环境)
   - 设置 Bucket 策略限制访问
   - 使用预签名 URL 而非公开文件

2. **加密**
   ```typescript
   // S3 服务端加密 (SSE)
   await s3.putObject({
     Bucket: bucketName,
     Key: fileName,
     Body: data,
     ServerSideEncryption: "AES256", // or "aws:kms"
   });
   ```

### 7.4 性能

1. **并发上传**
   ```typescript
   import pLimit from "p-limit";
   
   const limit = pLimit(5); // 限制并发数
   const uploads = files.map(file =>
     limit(() => storage.uploadFile(file))
   );
   const results = await Promise.all(uploads);
   ```

2. **分块上传** (大文件)
   ```typescript
   // AWS SDK 的 Upload 类已内置分块上传
   const upload = new Upload({
     client: s3Client,
     params: {
       Bucket: bucket,
       Key: key,
       Body: largeFile,
     },
     partSize: 5 * 1024 * 1024, // 5MB per part
     queueSize: 4, // 并发上传 4 个分块
   });
   
   await upload.done();
   ```

## 8. 故障排查

### 8.1 常见错误

**NoSuchBucket**
```
The specified bucket does not exist
```
- 检查 Bucket 名称拼写
- 确认 Bucket 已创建

**Access Denied**
```
Access Denied
```
- 检查 IAM 权限
- 验证 Access Key 是否正确
- 确认 Bucket 策略

**InvalidAccessKeyId**
```
The AWS Access Key Id you provided does not exist in our records
```
- 检查环境变量配置
- 验证 Access Key 有效性

**SignatureDoesNotMatch**
```
The request signature we calculated does not match the signature you provided
```
- 检查 Secret Access Key
- 确认时区设置正确

### 8.2 调试

```typescript
import { logger } from "@langfuse/shared/src/server/logger";

try {
  await storage.uploadFile(params);
} catch (error) {
  logger.error("Storage upload failed", {
    error: error.message,
    fileName: params.fileName,
    bucket: bucketName,
    endpoint: endpoint,
  });
  throw error;
}
```

## 9. 监控

### 9.1 关键指标

- **上传成功率**: 监控失败的上传请求
- **响应时间**: 预签名 URL 生成时间
- **存储成本**: 按 Bucket 和前缀监控存储使用
- **请求数**: API 调用次数

### 9.2 告警

```typescript
// 上传失败告警
if (uploadFailureRate > 0.05) {
  alert("High storage upload failure rate");
}

// 存储使用告警
if (storageUsageGB > 1000) {
  alert("High storage usage, consider cleanup");
}
```

## 10. 相关资源

- **AWS S3 文档**: https://docs.aws.amazon.com/s3/
- **Azure Blob Storage 文档**: https://docs.microsoft.com/azure/storage/blobs/
- **Google Cloud Storage 文档**: https://cloud.google.com/storage/docs
- **Cloudflare R2 文档**: https://developers.cloudflare.com/r2/
- **MinIO 文档**: https://min.io/docs/

---

**更新日期**: 2025-12-17  
**维护者**: Langfuse Engineering Team
